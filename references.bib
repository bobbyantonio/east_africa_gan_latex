
@article{chantry_opportunities_2021,
	title = {Opportunities and challenges for machine learning in weather and climate modelling: {Hard}, medium and soft {AI}},
	volume = {379},
	issn = {1364503X},
	doi = {10.1098/rsta.2020.0083},
	abstract = {In September 2019, a workshop was held to highlight the growing area of applying machine learning techniques to improve weather and climate prediction. In this introductory piece, we outline the motivations, opportunities and challenges ahead in this exciting avenue of research. This article is part of the theme issue 'Machine learning for weather and climate modelling'.},
	number = {2194},
	journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Chantry, Matthew and Christensen, Hannah and Dueben, Peter and Palmer, Tim},
	month = apr,
	year = {2021},
	pmid = {33583261},
	note = {Publisher: Royal Society Publishing},
	keywords = {climate modelling, machine learning, weather prediction},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/CBXQEERD/rsta.2020.0083.pdf:application/pdf},
}

@article{price_increasing_2022,
	title = {Increasing the accuracy and resolution of precipitation forecasts using deep generative models},
	volume = {151},
	doi = {https://doi.org/10.48550/arXiv.2203.12297},
	abstract = {Accurately forecasting extreme rainfall is notoriously difficult, but is also ever more crucial for society as climate change increases the frequency of such extremes. Global numerical weather prediction models often fail to capture extremes, and are produced at too low a resolution to be actionable, while regional, high-resolution models are hugely expensive both in computation and labour. In this paper we explore the use of deep generative models to simultaneously correct and downscale (super-resolve) global ensemble forecasts over the Continental US. Specifically, using fine-grained radar observations as our ground truth, we train a conditional Generative Adversarial Network-coined CorrectorGAN-via a custom training procedure and augmented loss function, to produce ensembles of high-resolution, bias-corrected forecasts based on coarse, global precipitation forecasts in addition to other relevant meteorological fields. Our model outperforms an interpolation baseline, as well as super-resolution-only and CNN-based uni-variate methods, and approaches the performance of an operational regional high-resolution model across an array of established probabilistic metrics. Crucially, Cor-rectorGAN, once trained, produces predictions in seconds on a single machine. These results raise exciting questions about the necessity of regional models, and whether data-driven downscaling and correction methods can be transferred to data-poor regions that},
	journal = {Proceedings of the 25th International Conference on Artificial Intelligence and Statistics (AISTATS)},
	author = {Price, Ilan and Rasp, Stephan},
	year = {2022},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/2WJY34NK/price22a.pdf:application/pdf},
}

@article{schwartz_medium-range_2019,
	title = {Medium-range convection-allowing ensemble forecasts with a variable-resolution global model},
	volume = {147},
	issn = {15200493},
	doi = {10.1175/MWR-D-18-0452.1},
	abstract = {Two sets of global, 132-h (5.5-day), 10-member ensemble forecasts were produced with the Model for Prediction Across Scales (MPAS) for 35 cases in April and May 2017. One MPAS ensemble had a quasi-uniform 15-km mesh while the other employed a variable-resolution mesh with 3-km cell spacing over the conterminous United States (CONUS) that smoothly relaxed to 15 km over the rest of the globe. Precipitation forecasts from both MPAS ensembles were objectively verified over the central and eastern CONUS to assess the potential benefits of configuring MPAS with a 3-km mesh refinement region for medium-range forecasts. In addition, forecasts from NCEP’s operational Global Ensemble Forecast System were evaluated and served as a baseline against which to compare the experimental MPAS ensembles. The 3-km MPAS ensemble most faithfully reproduced the observed diurnal cycle of precipitation throughout the 132-h forecasts and had superior precipitation skill and reliability over the first 48 h. However, after 48 h, the three ensembles had more similar spread, reliability, and skill, and differences between probabilistic precipitation forecasts derived from the 3- and 15-km MPAS ensembles were typically statistically insignificant. Nonetheless, despite fewer benefits of increased resolution for spatial placement after 48 h, 3-km ensemble members explicitly provided potentially valuable guidance regarding convective mode throughout the 132-h forecasts while the other ensembles did not. Collectively, these results suggest both strengths and limitations of medium-range high-resolution ensemble forecasts and reveal pathways for future investigations to improve understanding of high-resolution global ensembles with variable-resolution meshes.},
	number = {8},
	journal = {Monthly Weather Review},
	author = {Schwartz, Craig S.},
	year = {2019},
	note = {Publisher: American Meteorological Society},
	pages = {2997--3023},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/4AMWBKPC/1520-0493-mwr-d-18-0452.1.pdf:application/pdf},
}

@article{cafaro_convection-permitting_2021,
	title = {Do convection-permitting ensembles lead to more skillful short-range probabilistic rainfall forecasts over tropical east africa?},
	volume = {36},
	issn = {15200434},
	doi = {10.1175/WAF-D-20-0172.1},
	abstract = {Convection-permitting ensemble prediction systems (CP-ENS) have been implemented in the midlatitudes for weather forecasting time scales over the past decade, enabled by the increase in computational resources. Recently, efforts are being made to study the benefits of CP-ENS for tropical regions. This study examines CP-ENS forecasts produced by the Met Office over tropical East Africa, for 24 cases in the period April–May 2019. The CP-ENS, an ensemble with parameterized convection (Glob-ENS), and their deterministic counterparts are evaluated against rainfall estimates derived from satellite observations (GPM-IMERG). The CP configurations have the best representation of the diurnal cycle, although heavy rainfall amounts are overestimated compared to observations. Pairwise comparisons between the different configurations reveal that the CP-ENS is generally the most skillful forecast for both 3-and 24-h accumulations of heavy rainfall (97th percentile), followed by the CP deterministic forecast. More precisely, probabilistic forecasts of heavy rainfall, verified using a neighborhood approach, show that the CP-ENS is skillful at scales greater than 100 km, significantly better than the Glob-ENS, although not as good as found in the midlatitudes. Skill decreases with lead time and varies diurnally, especially for CP forecasts. The CP-ENS is underspread both in terms of forecasting the locations of heavy rainfall and in terms of domain-averaged rainfall. This study demonstrates potential benefits in using CP-ENS for operational forecasting of heavy rainfall over tropical Africa and gives specific suggestions for further research and development, including probabilistic forecast guidance.},
	number = {2},
	journal = {Weather and Forecasting},
	author = {Cafaro, Carlo and Woodhams, Beth J. and Stein, Thorwald H.M. and Birch, Cathryn E. and Webster, Stuart and Bain, Caroline L. and Hartley, Andrew and Clarke, Samantha and Ferrett, Samantha and Hill, Peter},
	month = apr,
	year = {2021},
	note = {Publisher: American Meteorological Society},
	keywords = {Ensembles, Forecast verification/skill, Model comparison, Probabilistic Quantitative Precipitation Forecasting (PQPF)},
	pages = {697--716},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/XHSFZVAH/[15200434 - Weather and Forecasting] Do Convection-Permitting Ensembles Lead to More Skillful Short-Range Probabilistic Rainfall Forecasts over Tropical East Africa_ (1).pdf:application/pdf},
}

@article{slater_hybrid_2023,
	title = {Hybrid forecasting: blending climate predictions with {AI} models},
	volume = {27},
	issn = {1607-7938},
	url = {https://hess.copernicus.org/articles/27/1865/2023/},
	doi = {10.5194/hess-27-1865-2023},
	abstract = {{\textless}p{\textgreater}{\textless}![CDATA[Abstract. Hybrid hydroclimatic forecasting systems employ data-driven (statistical or machine learning) methods to harness and integrate a broad variety of predictions from dynamical, physics-based models – such as numerical weather prediction, climate, land, hydrology, and Earth system models – into a final prediction product. They are recognized as a promising way of enhancing the prediction skill of meteorological and hydroclimatic variables and events, including rainfall, temperature, streamflow, floods, droughts, tropical cyclones, or atmospheric rivers. Hybrid forecasting methods are now receiving growing attention due to advances in weather and climate prediction systems at subseasonal to decadal scales, a better appreciation of the strengths of AI, and expanding access to computational resources and methods. Such systems are attractive because they may avoid the need to run a computationally expensive offline land model, can minimize the effect of biases that exist within dynamical outputs, benefit from the strengths of machine learning, and can learn from large datasets, while combining different sources of predictability with varying time horizons. Here we review recent developments in hybrid hydroclimatic forecasting and outline key challenges and opportunities for further research. These include obtaining physically explainable results, assimilating human influences from novel data sources, integrating new ensemble techniques to improve predictive skill, creating seamless prediction schemes that merge short to long lead times, incorporating initial land surface and ocean/ice conditions, acknowledging spatial variability in landscape and atmospheric forcing, and increasing the operational uptake of hybrid prediction schemes.]]{\textgreater}{\textless}/p{\textgreater}},
	number = {9},
	journal = {Hydrology and Earth System Sciences},
	author = {Slater, Louise J. and Arnal, Louise and Boucher, Marie-Amélie and Chang, Annie Y.-Y. and Moulds, Simon and Murphy, Conor and Nearing, Grey and Shalev, Guy and Shen, Chaopeng and Speight, Linda and Villarini, Gabriele and Wilby, Robert L. and Wood, Andrew and Zappa, Massimiliano},
	month = may,
	year = {2023},
	pages = {1865--1889},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/4QSFFYLR/hess-27-1865-2023.pdf:application/pdf},
}

@article{pulkkinen_pysteps_2019,
	title = {Pysteps: an open-source {Python} library for probabilistic precipitation nowcasting (v1.0)},
	volume = {12},
	issn = {1991-9603},
	doi = {10.5194/gmd-12-4185-2019},
	abstract = {{\textless}p{\textgreater}Abstract. Pysteps is an open-source and community-driven Python library for probabilistic precipitation nowcasting, that is, very-short-range forecasting (0–6 h). The aim of pysteps is to serve two different needs. The first is to provide a modular and well-documented framework for researchers interested in developing new methods for nowcasting and stochastic space–time simulation of precipitation. The second aim is to offer a highly configurable and easily accessible platform for practitioners ranging from weather forecasters to hydrologists. In this sense, pysteps has the potential to become an important component for integrated early warning systems for severe weather. The pysteps library supports various input/output file formats and implements several optical flow methods as well as advanced stochastic generators to produce ensemble nowcasts. In addition, it includes tools for visualizing and post-processing the nowcasts and methods for deterministic, probabilistic and neighborhood forecast verification. The pysteps library is described and its potential is demonstrated using radar composite images from Finland, Switzerland, the United States and Australia. Finally, scientific experiments are carried out to help the reader to understand the pysteps framework and sensitivity to model parameters.{\textless}/p{\textgreater}},
	number = {10},
	journal = {Geoscientific Model Development},
	author = {Pulkkinen, Seppo and Nerini, Daniele and Pérez Hortal, Andrés A. and Velasco-Forero, Carlos and Seed, Alan and Germann, Urs and Foresti, Loris},
	month = oct,
	year = {2019},
	pages = {4185--4219},
}

@article{cannon_bias_2015,
	title = {Bias correction of {GCM} precipitation by quantile mapping: {How} well do methods preserve changes in quantiles and extremes?},
	volume = {28},
	issn = {08948755},
	doi = {10.1175/JCLI-D-14-00754.1},
	abstract = {Quantile mapping bias correction algorithms are commonly used to correct systematic distributional biases in precipitation outputs from climate models. Although they are effective at removing historical biases relative to observations, it has been found that quantile mapping can artificially corrupt future model-projected trends. Previous studies on the modification of precipitation trends by quantile mapping have focused on mean quantities, with less attention paid to extremes. This article investigates the extent to which quantile mapping algorithms modify global climate model (GCM) trends in mean precipitation and precipitation extremes indices. First, a bias correction algorithm, quantile delta mapping (QDM), that explicitly preserves relative changes in precipitation quantiles is presented. QDM is compared on synthetic data with detrended quantile mapping (DQM), which is designed to preserve trends in the mean, and with standard quantile mapping (QM). Next, methods are applied to phase 5 of the Coupled Model Intercomparison Project (CMIP5) daily precipitation projections over Canada. Performance is assessed based on precipitation extremes indices and results from a generalized extreme value analysis applied to annual precipitation maxima. QM can inflate the magnitude of relative trends in precipitation extremes with respect to the raw GCM, often substantially, as compared to DQM and especially QDM. The degree of corruption in the GCM trends by QM is particularly large for changes in long period return values. By the 2080s, relative changes in excess of +500\% with respect to historical conditions are noted at some locations for 20-yr return values, with maximum changes by DQM and QDM nearing +240\% and +140\%, respectively, whereas raw GCM changes are never projected to exceed +120\%.},
	number = {17},
	journal = {Journal of Climate},
	author = {Cannon, Alex J. and Sobie, Stephen R. and Murdock, Trevor Q.},
	year = {2015},
	note = {Publisher: American Meteorological Society},
	keywords = {Bias, Climate models, Extreme events, Precipitation, Statistical techniques, Trends},
	pages = {6938--6959},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/XR8K2FN5/1520-0442-jcli-d-14-00754.1 (1).pdf:application/pdf},
}

@article{wilks_comparison_2006,
	title = {Comparison of ensemble-{MOS} methods in the {Lorenz} '96 setting},
	volume = {13},
	issn = {14698080},
	doi = {10.1017/S1350482706002192},
	abstract = {A suite of methods that have been proposed for statistical post-processing of ensemble forecasts based on historical verification data (i.e. ensemble-MOS methods) are compared with each other, and with direct probability estimates using ensemble relative frequencies, in the idealised Lorenz '96 setting. The three most promising methods are logistic regressions predicting probabilities associated with selected quantiles, ensemble dressing (a kernel density estimation approach), and linear regressions with non-constant prediction errors that depend on the ensemble variance.},
	number = {3},
	journal = {Meteorological Applications},
	author = {Wilks, D. S.},
	year = {2006},
	note = {Publisher: Cambridge University Press},
	keywords = {Ensemble dressing, Ensemble forecasting, Logistic regression},
	pages = {243--256},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/8ZK285DN/comparison-of-ensemble-mos-methods-in-the-lorenz-96-setting.pdf:application/pdf},
}

@techreport{mudelsee_estimating_2003,
	title = {Estimating {Pearson}'s {Correlation} {Coefficient} {With} {Bootstrap} {Confidence} {Interval} {From} {Serially} {Dependent} {Time} {Series} 1},
	abstract = {Pearson's correlation coefficient, r xy , is often used when measuring the influence of one time-dependent variable on another in bivariate climate time series. Thereby, positive serial dependence (persis-tence) and unknown data distributions impose a challenge for obtaining accurate confidence intervals for r xy. This is met by the presented approach, employing the nonparametric stationary bootstrap with an average block length proportional to the maximum estimated persistence time of the data. A Monte Carlo experiment reveals that this method can produce accurate (in terms of coverage) confidence intervals (of type bias-corrected and accelerated). However, since persistence reduces the number of independent observations, substantially more data points are required for achieving an accuracy comparable to a situation without persistence. The experiment further shows that neglecting serial dependence may lead to serious coverage errors. The presented method proves robust with respect to distributional shape (lognormal/normal) and time spacing (uneven/even). The method is used to confirm that a previous finding of a correlation between solar activity and Indian Ocean monsoon strength in early Holocene is valid. A further result is that the correlation between sunspot number and cosmogenic 10 Be concentration vanishes after approximately 1870.},
	author = {Mudelsee, Manfred},
	year = {2003},
	note = {Publication Title: Mathematical Geology
Volume: 35
Issue: 6},
	keywords = {BCa method, irregular sampling interval, Monte Carlo simulation, persistence, sun-climate relationship},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/7TRMEAUJ/B_MATG.0000002982.52104.02.pdf:application/pdf},
}

@article{bechtold_simulation_2004,
	title = {The simulation of the diurnal cycle of convective precipitation over land in a global model},
	volume = {130 C},
	issn = {00359009},
	doi = {10.1256/qj.03.103},
	abstract = {In the context of the European Cloud Systems project, the problem of the simulation of the diurnal cycle of convective precipitation over land is addressed with the aid of cloud-resolving (CRM) and single-column (SCM) model simulations of an idealized midlatitude case for which observations of large-scale and surface forcing are available. The CRM results are compared to different versions of the European Centre for Medium-Range Weather Forecasts (ECMWF) convection schemes using different convective trigger procedures and convective closures. In the CRM, maximum rainfall intensity occurs at 15 h (local time). In this idealized midlatitude case, most schemes do not reproduce the afternoon precipitation peak, as (i) they cannot reproduce the gradual growth (typically over 3 hours) of the deep convective cloud layer and (ii) they produce a diurnal cycle of precipitation that is in phase with the diurnal cycle of the convective available potential energy (CAPE) and the convective inhibition (CIN), consistent with the parcel theory and CAPE closure used in the bulk mass-flux scheme. The scheme that links the triggering to the large-scale vertical velocity gets the maximum precipitation at the right time, but this may be artificial as the vertical velocity is enforced in the single-column context. The study is then extended to the global scale using ensembles of 72-hour global forecasts at resolution T511 (40 km), and long-range single 40-day forecasts at resolution T159 (125 km) with the ECMWF general-circulation model. The focus is on tropical South America and Africa where the diurnal cycle is most pronounced. The forecasts are evaluated against analyses and observed radiosonde data, as well as observed surface and satellite-derived rainfall rates. The ECMWF model version with improved convective trigger produces the smallest biases overall. It also shifts the rainfall maximum to 12 h compared to 9.5 h in the original version. In contrast to the SCM, the vertical-velocity-dependent trigger does not further improve the phase of the diurnal cycle. However, further work is necessary to match the observed 15 h precipitation peak. © Royal Meteorological Society, 2004.},
	number = {604},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Bechtold, Peter and Chaboureau, J. P. and Beljaars, A. and Betts, A. K. and Köhler, M. and Miller, M. and Redelsperger, J. L.},
	month = oct,
	year = {2004},
	keywords = {General-circulation models},
	pages = {3119--3137},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/GDBFZJTP/Quart J Royal Meteoro Soc - October 2004 Part C - Bechtold - The simulation of the diurnal cycle of convective.pdf:application/pdf},
}

@article{maraun_statistical_2019,
	title = {Statistical downscaling skill under present climate conditions: {A} synthesis of the {VALUE} perfect predictor experiment},
	volume = {39},
	issn = {10970088},
	doi = {10.1002/joc.5877},
	abstract = {VALUE is a network that developed a framework to evaluate statistical downscaling methods including model output statistics such as simple bias correction and quantile mapping; perfect prognosis methods such as regression models and analog methods; and weather generators. The first experiment addresses the downscaling performance in present climate with perfect predictors. This paper presents a synthesis of the VALUE special issue, with a focus on the results of this first experiment. This paper presents a synthesis of the results. Model output statistics performs mostly well, but requires predictors at a resolution close to the target one. Perfect prog performance depends crucially on model structure and predictor choice. Weather generators perform in principle well for all aspects that can be expressed by the available model structure. Inter-annual variability is underrepresented by both perfect prog and weather generator approaches. Spatial variability is poorly represented by almost all participating methods (inherited by model output statistics from the driving model, not represented by the perfect prog and weather generator methods). Further studies are required to systematically assess (a) the role of predictor choice for perfect prog; (b) the performance of spatial weather generators, to study the performance based on GCM predictors; (c) downscaling skill in simulated future climates; and (d) the credibility of simulated predictors in a future climate.},
	number = {9},
	journal = {International Journal of Climatology},
	author = {Maraun, Douglas and Widmann, Martin and Gutiérrez, José M.},
	month = jul,
	year = {2019},
	note = {Publisher: John Wiley and Sons Ltd},
	keywords = {★, bias correction, evaluation, regional climate, statistical downscaling, validation},
	pages = {3692--3703},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/JYNQICGY/Maraun et al 2019 Statistical downscaling skill under present climate conditions - A synthesis of the VALUE perfect predictor experiment.pdf:application/pdf},
}

@article{feng_global_2021,
	title = {A {Global} {High}-{Resolution} {Mesoscale} {Convective} {System} {Database} {Using} {Satellite}-{Derived} {Cloud} {Tops}, {Surface} {Precipitation}, and {Tracking}},
	volume = {126},
	issn = {21698996},
	doi = {10.1029/2020JD034202},
	abstract = {A new methodology is developed to construct a global (60°S–60°N) long-term (2000–2019) high-resolution (∼10-km h) mesoscale convective system (MCS) database by tracking MCS jointly using geostationary satellite infrared brightness temperature (Tb) and precipitation feature (PF) characteristics from the Integrated Multi-satellitE Retrievals for GPM precipitation data sets. Independent validation shows that the satellite-based MCS data set is able to reproduce important MCS statistics derived from ground-based radar network observations in the United States and China. We show that by carefully considering key PF characteristics in addition to Tb signatures, the new method significantly improves upon previous Tb-only methods in detecting MCSs in the midlatitudes for all seasons. Results show that MCSs account for over 50\% of annual total rainfall across most of the tropical belt and in selected regions of the midlatitudes, with a strong seasonality over many regions of the globe. The tracking database allows Lagrangian aspects such as MCS lifetime and translational speed and direction to be analyzed. The longest-lived MCSs preferentially occur over the subtropical oceans. The land MCSs have higher cloud-tops associated with more intense convection, and oceanic MCSs have much higher rainfall production. While MCSs are observed in many regions of the globe, there are fundamental differences in their dynamic and thermodynamic structures that warrant a better understanding of processes that control their evolution. This global database provides significant opportunities for observational and modeling studies of MCSs, their characteristics, and roles in regional and global water and energy cycles, as well as their hydrologic and other impacts.},
	number = {8},
	journal = {Journal of Geophysical Research: Atmospheres},
	author = {Feng, Zhe and Leung, L. Ruby and Liu, Nana and Wang, Jingyu and Houze, Robert A. and Li, Jianfeng and Hardin, Joseph C. and Chen, Dandan and Guo, Jianping},
	month = apr,
	year = {2021},
	note = {Publisher: Blackwell Publishing Ltd},
	keywords = {convective clouds, global climatology, mesoscale convection, precipitation, satellite observations, storm tracking},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/63AUJEG9/JGR Atmospheres - 2021 - Feng - A Global High‐Resolution Mesoscale Convective System Database Using Satellite‐Derived Cloud.pdf:application/pdf},
}

@article{glawion_spategan_nodate,
	title = {{spateGAN}: {Spatio}-{Temporal} {Downscaling} of {Rainfall} {Fields} using {acGAN} {Approach}},
	doi = {https://doi.org/10.22541/essoar.167690003.33629126/v1},
	author = {Glawion, Luca},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/HW69FAY8/625190 (1).pdf:application/pdf},
}

@article{ben_bouallegue_spatial_2014,
	title = {Spatial techniques applied to precipitation ensemble forecasts: {From} verification results to probabilistic products},
	volume = {21},
	issn = {14698080},
	doi = {10.1002/met.1435},
	abstract = {Spatial techniques have been developed to quantify the performance of a system beyond the classical point-to-point comparison with observations. Including spatial neighbourhood information in the verification process, the quality of a forecast can be better characterized. Guidance for the interpretation of deterministic forecasts can also be delivered. This paper investigates the application of spatial techniques to ensemble forecasts. The aim is to assess ensemble forecast skills better and to provide improved guidance to the forecasters in the form of refined probabilistic products. Two spatial techniques are applied to precipitation forecasts derived from an ensemble system at the convective scale (COSMO-DE-EPS). The first technique is a smoothing method which enlarges the ensemble sample size by neighbouring forecasts. The resulting forecasts are called fuzzy probabilistic forecasts. The second method is an upscaling procedure which modifies the reference area of the probabilities. Fuzzy and upscaled probabilistic forecasts are assessed over a 3month period covering summer2011. The impact of smoothing and upscaling is investigated for a range of neighbourhood sizes and spatial scales respectively. Based on the verification results, recommendations are drawn how to use these techniques in optimally presenting COSMO-DE-EPS probabilistic products to forecasters who issue weather warnings.},
	number = {4},
	journal = {Meteorological Applications},
	author = {Ben Bouallègue, Zied and Theis, Susanne E.},
	month = oct,
	year = {2014},
	note = {Publisher: John Wiley and Sons Ltd},
	keywords = {Convection-permitting, Guidance, Neighbourhood, Predictability},
	pages = {922--929},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/BMTZF5W7/Meteorological Applications - 2013 - Ben Bouall gue - Spatial techniques applied to precipitation ensemble forecasts  from.pdf:application/pdf},
}

@article{wang_image_2004,
	title = {Image quality assessment: {From} error visibility to structural similarity},
	volume = {13},
	issn = {10577149},
	doi = {10.1109/TIP.2003.819861},
	abstract = {Objective methods for assessing perceptual image quality traditionally attempted to quantify the visibility of errors (differences) between a distorted image and a reference image using a variety of known properties of the human visual system. Under the assumption that human visual perception is highly adapted for extracting structural information from a scene, we introduce an alternative complementary framework for quality assessment based on the degradation of structural information. As a specific example of this concept, we develop a Structural Similarity Index and demonstrate its promise through a set of intuitive examples, as well as comparison to both subjective ratings and state-of-the-art objective methods on a database of images compressed with JPEG and JPEG2000.},
	number = {4},
	journal = {IEEE Transactions on Image Processing},
	author = {Wang, Zhou and Bovik, Alan Conrad and Sheikh, Hamid Rahim and Simoncelli, Eero P.},
	month = apr,
	year = {2004},
	pmid = {15376593},
	keywords = {Error sensitivity, Human visual system (HVS), Image coding, Image quality assessment, JPEG, JPEG2000, Perceptual quality, Structural information, Structural similarity (SSIM)},
	pages = {600--612},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/M9DX369A/Image_quality_assessment_from_error_visibility_to_structural_similarity.pdf:application/pdf},
}

@inproceedings{ebert_fuzzy_2008,
	title = {Fuzzy verification of high-resolution gridded forecasts: {A} review and proposed framework},
	volume = {15},
	doi = {10.1002/met.25},
	abstract = {High-resolution forecasts from numerical models can look quite realistic and provide the forecaster with very useful guidance. However, when verified using traditional metrics they often score quite poorly because of the difficulty of predicting an exact match to the observations at high resolution. 'Fuzzy' verification rewards closeness by relaxing the requirement for exact matches between forecasts and observations. The key to the fuzzy approach is the use of a spatial window or neighbourhood surrounding the forecast and/or observed points. The treatment of the data within the window may include averaging (upscaling), thresholding, or generation of a PDF, depending on the particular fuzzy method used and its implicit decision model concerning what makes a good forecast. The size of the neighbourhood can be varied to provide verification results at multiple scales, thus allowing the user to determine at which scales the forecast has useful skill. This article describes a framework for fuzzy verification that incorporates several fuzzy verification methods. It is demonstrated on a high-resolution precipitation forecast from the United Kingdom (UK) and the results interpreted to show the additional information that can be gleaned from this approach. Copyright © 2008 Royal Meteorological Society.},
	booktitle = {Meteorological {Applications}},
	publisher = {John Wiley and Sons Ltd},
	author = {Ebert, Elizabeth E.},
	year = {2008},
	note = {Issue: 1
ISSN: 14698080},
	keywords = {Fuzzy, High-resolution forecast, Verification},
	pages = {51--64},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/I8W6G8Y5/Meteorological Applications - 2008 - Ebert - Fuzzy verification of high‐resolution gridded forecasts  a review and proposed.pdf:application/pdf},
}

@article{wang_mean_2009,
	title = {Mean squared error: {Lot} it or leave it? {A} new look at signal fidelity measures},
	volume = {26},
	issn = {10535888},
	doi = {10.1109/MSP.2008.930649},
	number = {1},
	journal = {IEEE Signal Processing Magazine},
	author = {Wang, Zhou and Bovik, Alan C.},
	year = {2009},
	note = {Publisher: Institute of Electrical and Electronics Engineers Inc.},
	keywords = {Distortion, Distortion measurement, Noise, Pixel, Pollution measurement, PSNR, Visualization},
	pages = {98--117},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/N24SFPET/Mean_squared_error_Love_it_or_leave_it_A_new_look_at_Signal_Fidelity_Measures.pdf:application/pdf},
}

@article{dosselmann_comprehensive_2011,
	title = {A comprehensive assessment of the structural similarity index},
	volume = {5},
	issn = {18631711},
	doi = {10.1007/s11760-009-0144-1},
	abstract = {In recent years the structural similarity index has become an accepted standard among image quality metrics. Made up of three components, this technique assesses the visual impact of changes in image luminance, contrast, and structure. Applications of the index include image enhancement, video quality monitoring, and image encoding. As its status continues to rise, however, so do questions about its performance. In this paper, it is shown, both empirically and analytically, that the index is directly related to the conventional, and often unreliable, mean squared error. In the first evaluation, the two metrics are statistically compared with one another. Then, in the second, a pair of functions that algebraically connects the two is derived. These results suggest a much closer relationship between the structural similarity index and mean squared error. © 2009 Springer-Verlag London Limited.},
	number = {1},
	journal = {Signal, Image and Video Processing},
	author = {Dosselmann, Richard and Yang, Xue Dong},
	month = mar,
	year = {2011},
	note = {Publisher: Springer London},
	keywords = {Image quality metric, Mean squared error, MSE, SSIM, Structural similarity index},
	pages = {81--91},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/CL5NHS7Q/s11760-009-0144-1.pdf:application/pdf},
}

@article{brunet_mathematical_2012,
	title = {On the mathematical properties of the structural similarity index},
	volume = {21},
	issn = {10577149},
	doi = {10.1109/TIP.2011.2173206},
	abstract = {Since its introduction in 2004, the structural similarity (SSIM) index has gained widespread popularity as a tool to assess the quality of images and to evaluate the performance of image processing algorithms and systems. There has been also a growing interest of using SSIM as an objective function in optimization problems in a variety of image processing applications. One major issue that could strongly impede the progress of such efforts is the lack of understanding of the mathematical properties of the SSIM measure. For example, some highly desirable properties such as convexity and triangular inequality that are possessed by the mean squared error may not hold. In this paper, we first construct a series of normalized and generalized (vector-valued) metrics based on the important ingredients of SSIM. We then show that such modified measures are valid distance metrics and have many useful properties, among which the most significant ones include quasi-convexity, a region of convexity around the minimizer, and distance preservation under orthogonal or unitary transformations. The groundwork laid here extends the potentials of SSIM in both theoretical development and practical applications. © 2011 IEEE.},
	number = {4},
	journal = {IEEE Transactions on Image Processing},
	author = {Brunet, Dominique and Vrscay, Edward R. and Wang, Zhou},
	month = apr,
	year = {2012},
	pmid = {22042163},
	keywords = {Cone metrics, normalized metrics, perceptually optimized algorithms and methods, quality metrics and assessment tools, quasi-convexity and convexity, structural similarity (SSIM) index},
	pages = {1488--1495},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/YCXBETVH/TIP_SSIM_MathProperties.pdf:application/pdf},
}

@article{taillardat_calibrated_2016,
	title = {Calibrated ensemble forecasts using quantile regression forests and ensemble model output statistics},
	volume = {144},
	issn = {15200493},
	doi = {10.1175/MWR-D-15-0260.1},
	abstract = {Ensembles used for probabilistic weather forecasting tend to be biased and underdispersive. This paper proposes a statistical method for postprocessing ensembles based on quantile regression forests (QRF), a generalization of random forests for quantile regression. This method does not fit a parametric probability density function (PDF) like in ensemble model output statistics (EMOS) but provides an estimation of desired quantiles. This is a nonparametric approach that eliminates any assumption on the variable subject to calibration. This method can estimate quantiles using not only members of the ensemble but any predictor available including statistics on other variables. The method is applied to the Météo-France 35-member ensemble forecast (PEARP) for surface temperature and wind speed for available lead times from 3 up to 54 h and compared to EMOS. All postprocessed ensembles are much better calibrated than the PEARP raw ensemble and experiments on real data also show that QRF performs better than EMOS, and can bring a real gain for human forecasters compared to EMOS. QRF provides sharp and reliable probabilistic forecasts. At last, classical scoring rules to verify predictive forecasts are completed by the introduction of entropy as a general measure of reliability.},
	number = {6},
	journal = {Monthly Weather Review},
	author = {Taillardat, Maxime and Mestre, Olivier and Zamo, Michaël and Naveau, Philippe},
	month = jun,
	year = {2016},
	note = {Publisher: American Meteorological Society},
	pages = {2375--2393},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/JHQ33F63/1520-0493-mwr-d-15-0260.1.pdf:application/pdf},
}

@article{feng_global_2021-1,
	title = {A {Global} {High}-{Resolution} {Mesoscale} {Convective} {System} {Database} {Using} {Satellite}-{Derived} {Cloud} {Tops}, {Surface} {Precipitation}, and {Tracking}},
	volume = {126},
	issn = {21698996},
	doi = {10.1029/2020JD034202},
	abstract = {A new methodology is developed to construct a global (60°S–60°N) long-term (2000–2019) high-resolution (∼10-km h) mesoscale convective system (MCS) database by tracking MCS jointly using geostationary satellite infrared brightness temperature (Tb) and precipitation feature (PF) characteristics from the Integrated Multi-satellitE Retrievals for GPM precipitation data sets. Independent validation shows that the satellite-based MCS data set is able to reproduce important MCS statistics derived from ground-based radar network observations in the United States and China. We show that by carefully considering key PF characteristics in addition to Tb signatures, the new method significantly improves upon previous Tb-only methods in detecting MCSs in the midlatitudes for all seasons. Results show that MCSs account for over 50\% of annual total rainfall across most of the tropical belt and in selected regions of the midlatitudes, with a strong seasonality over many regions of the globe. The tracking database allows Lagrangian aspects such as MCS lifetime and translational speed and direction to be analyzed. The longest-lived MCSs preferentially occur over the subtropical oceans. The land MCSs have higher cloud-tops associated with more intense convection, and oceanic MCSs have much higher rainfall production. While MCSs are observed in many regions of the globe, there are fundamental differences in their dynamic and thermodynamic structures that warrant a better understanding of processes that control their evolution. This global database provides significant opportunities for observational and modeling studies of MCSs, their characteristics, and roles in regional and global water and energy cycles, as well as their hydrologic and other impacts.},
	number = {8},
	journal = {Journal of Geophysical Research: Atmospheres},
	author = {Feng, Zhe and Leung, L. Ruby and Liu, Nana and Wang, Jingyu and Houze, Robert A. and Li, Jianfeng and Hardin, Joseph C. and Chen, Dandan and Guo, Jianping},
	month = apr,
	year = {2021},
	note = {Publisher: Blackwell Publishing Ltd},
	keywords = {convective clouds, global climatology, mesoscale convection, precipitation, satellite observations, storm tracking},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/TUKEJKDV/JGR Atmospheres - 2021 - Feng - A Global High‐Resolution Mesoscale Convective System Database Using Satellite‐Derived Cloud.pdf:application/pdf},
}

@incollection{christensen_parametrization_2022,
	title = {Parametrization in {Weather} and {Climate} {Models}},
	booktitle = {Oxford {Research} {Encyclopedia} of {Climate} {Science}},
	publisher = {Oxford University Press},
	author = {Christensen, Hannah and Zanna, Laure},
	month = dec,
	year = {2022},
	doi = {10.1093/acrefore/9780190228620.013.826},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/66R5EAML/acrefore-9780190228620-e-826.pdf:application/pdf},
}

@techreport{bechtold_convection_2008,
	title = {Convection {Parametrization}},
	author = {Bechtold, Peter},
	year = {2008},
	note = {Publication Title: ECMWF Seminar on Parametrization of Subgrid Physical Processes},
	pages = {1--4},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/I4N6RAV4/8008-convection-parametrization.pdf:application/pdf},
}

@techreport{bechtold_convection_2008-1,
	title = {Convection {Parametrization}},
	author = {Bechtold, Peter},
	year = {2008},
	note = {Publication Title: ECMWF Seminar on Parametrization of Subgrid Physical Processes},
	pages = {1--4},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/VZD8CFPC/8008-convection-parametrization.pdf:application/pdf},
}

@incollection{christensen_parametrization_2022-1,
	title = {Parametrization in {Weather} and {Climate} {Models}},
	booktitle = {Oxford {Research} {Encyclopedia} of {Climate} {Science}},
	publisher = {Oxford University Press},
	author = {Christensen, Hannah and Zanna, Laure},
	month = dec,
	year = {2022},
	doi = {10.1093/acrefore/9780190228620.013.826},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/K8LQ3TA2/acrefore-9780190228620-e-826.pdf:application/pdf},
}

@article{casati_scale-separation_2022,
	title = {Scale-separation diagnostics and the {Symmetric} {Bounded} {Efficiency} for the inter-comparison of precipitation reanalyses},
	issn = {10970088},
	doi = {10.1002/joc.7975},
	abstract = {The ERA5 global reanalysis has been compared against a high-resolution regional reanalysis (COSMO-REA6) by means of scale-separation diagnostics based on 2d Haar discrete wavelet transforms. The presented method builds upon existing methods and enables the assessment of bias, error and skill for individual spatial scales, separately. A new skill score (evaluated against random chance) and the Symmetric Bounded Efficiency are introduced. These are compared to the Nash-Sutcliffe and the Kling-Gupta Efficiencies, evaluated on different scales, and the benefits of symmetric statistics are illustrated. As expected, the wavelet statistics show that the coarser resolution ERA5 products underestimate small-to-medium scale precipitation compared to COSMO-REA6. The newly introduced skill score shows that the ERA5 control member (EA-HRES), despite its higher variability, exhibits better skill in representing small-to-medium scales with respect to the smoother ensemble members. The Symmetric Bounded Efficiency is suitable for the inter-comparison of reanalyses, since it is invariant with respect to the order of comparison.},
	journal = {International Journal of Climatology},
	author = {Casati, Barbara and Lussana, Cristian and Crespi, Alice},
	month = apr,
	year = {2022},
	note = {Publisher: John Wiley and Sons Ltd},
	keywords = {precipitation, COSMO-REA6, ERA5, scale separation, spatial verification, wavelet},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/KF3GK986/Intl Journal of Climatology - 2022 - Casati - Scale‐separation diagnostics and the Symmetric Bounded Efficiency for the.pdf:application/pdf},
}

@article{duc_spatial-temporal_2013,
	title = {Spatial-temporal fractions verification for high-resolution ensemble forecasts},
	volume = {65},
	issn = {16000870},
	doi = {10.3402/tellusa.v65i0.18171},
	abstract = {Experiments with two ensemble systems of resolutions 10 km (MF10km) and 2 km (MF2km) were designed to examine the value of cloud-resolving ensemble forecast in predicting precipitation on small spatio-temporal scales. Since the verification was performed on short-term precipitation at high resolution, uncertainties from small-scale processes caused the traditional verification methods to be inconsistent with the subjective evaluation. An extended verification method based on the Fractions Skill Score (FSS) was introduced to account for these uncertainties. The main idea is to extend the concept of spatial neighbourhood in FSS to the time and ensemble dimension. The extension was carried out by recognising that even if ensemble forecast is used, small-scale variability still exists in forecasts and influences verification results. In addition to FSS, the neighbourhood concept was also incorporated into reliability diagrams and relative operating characteristics to verify the reliability and resolution of two systems. The extension of FSS in time dimension demonstrates the important role of temporal scales in short-term precipitation verification at small spatial scales. The extension of FSS in ensemble space is called the ensemble FSS, which is a good representative of FSS for ensemble forecast in comparison with the FSS of ensemble mean. The verification results show that MF2km outperforms MF10km in heavy rain forecasts. In contrast, MF10km was slightly better than MF2km in predicting light rains, suggesting that the horizontal resolution of 2 km is not necessarily enough to completely resolve convective cells. © 2013 Le Duc et al.},
	journal = {Tellus, Series A: Dynamic Meteorology and Oceanography},
	author = {Duc, Le and Saito, Kazuo and Seko, Hiromu},
	year = {2013},
	note = {Publisher: Co-Action Publishing},
	keywords = {Fractions skill score, Intensity-scale diagram, Reliability, Resolution, Small-scale variability},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/IMILQNDS/Spatial temporal fractions verification for high resolution ensemble forecasts.pdf:application/pdf},
}

@article{jiang_tsit_2020,
	title = {{TSIT}: {A} {Simple} and {Versatile} {Framework} for {Image}-to-{Image} {Translation}},
	url = {http://arxiv.org/abs/2007.12072},
	abstract = {We introduce a simple and versatile framework for image-to-image translation. We unearth the importance of normalization layers, and provide a carefully designed two-stream generative model with newly proposed feature transformations in a coarse-to-fine fashion. This allows multi-scale semantic structure information and style representation to be effectively captured and fused by the network, permitting our method to scale to various tasks in both unsupervised and supervised settings. No additional constraints (e.g., cycle consistency) are needed, contributing to a very clean and simple method. Multi-modal image synthesis with arbitrary style control is made possible. A systematic study compares the proposed method with several state-of-the-art task-specific baselines, verifying its effectiveness in both perceptual quality and quantitative evaluations.},
	author = {Jiang, Liming and Zhang, Changxu and Huang, Mingyang and Liu, Chunxiao and Shi, Jianping and Loy, Chen Change},
	month = jul,
	year = {2020},
	note = {arXiv: 2007.12072},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/98CR4C4Z/2007.12072.pdf:application/pdf},
}

@article{ebert-uphoff_cira_2021,
	title = {{CIRA} {Guide} to {Custom} {Loss} {Functions} for {Neural} {Networks} in {Environmental} {Sciences} -- {Version} 1},
	url = {http://arxiv.org/abs/2106.09757},
	abstract = {Neural networks are increasingly used in environmental science applications. Furthermore, neural network models are trained by minimizing a loss function, and it is crucial to choose the loss function very carefully for environmental science applications, as it determines what exactly is being optimized. Standard loss functions do not cover all the needs of the environmental sciences, which makes it important for scientists to be able to develop their own custom loss functions so that they can implement many of the classic performance measures already developed in environmental science, including measures developed for spatial model verification. However, there are very few resources available that cover the basics of custom loss function development comprehensively, and to the best of our knowledge none that focus on the needs of environmental scientists. This document seeks to fill this gap by providing a guide on how to write custom loss functions targeted toward environmental science applications. Topics include the basics of writing custom loss functions, common pitfalls, functions to use in loss functions, examples such as fractions skill score as loss function, how to incorporate physical constraints, discrete and soft discretization, and concepts such as focal, robust, and adaptive loss. While examples are currently provided in this guide for Python with Keras and the TensorFlow backend, the basic concepts also apply to other environments, such as Python with PyTorch. Similarly, while the sample loss functions provided here are from meteorology, these are just examples of how to create custom loss functions. Other fields in the environmental sciences have very similar needs for custom loss functions, e.g., for evaluating spatial forecasts effectively, and the concepts discussed here can be applied there as well. All code samples are provided in a GitHub repository.},
	author = {Ebert-Uphoff, Imme and Lagerquist, Ryan and Hilburn, Kyle and Lee, Yoonjin and Haynes, Katherine and Stock, Jason and Kumler, Christina and Stewart, Jebb Q.},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.09757},
	keywords = {★},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/IL522X6K/2106.09757.pdf:application/pdf},
}

@article{authors_gcrf_nodate,
	title = {{GCRF} {African} {SWIFT} and {ForPAc} {SHEAR} {White} {Paper} on the {Potential} of {Operational} {Weather} {Prediction} to {Save} {Lives} and {Improve} {Livelihoods} and {Economies} in {Sub}-{Saharan} {Africa}},
	url = {https://doi.org/10.5518/100/79},
	doi = {10.5518/100/79},
	abstract = {White Rose Research Online URL for this paper: https://eprints.whiterose.ac.uk/181045/ Version: Published Version Monograph: Youds, LH orcid.org/0000-0003-0302-3307, Parker, DJ orcid.org/0000-0003-2335-8198, Adefisan, EA et al. (15 more authors) (2021) GCRF African SWIFT and ForPAc SHEAR White Paper on the Potential of Operational Weather Prediction to Save Lives and Improve Livelihoods and Economies in Sub-Saharan Africa. Report. University of Leeds https://doi.org/10.5518/100/79 eprints@whiterose.ac.uk https://eprints.whiterose.ac.uk/ Reuse This article is distributed under the terms of the Creative Commons Attribution (CC BY) licence. This licence allows you to distribute, remix, tweak, and build upon the work, even commercially, as long as you credit the authors for the original work. More information and the full terms of the licence here: https://creativecommons.org/licenses/ Takedown If you consider content in White Rose Research Online to be in breach of UK law, please notify us by emailing eprints@whiterose.ac.uk including the URL of the record and the reason for the withdrawal request.},
	author = {Authors, Lead and Youds, Lorraine H and Parker Co-authors, Douglas J and Adefisan, Elijah A and Antwi-Agyei, Philip and Bain, Caroline L and L Black, Emily C and Blyth, Alan M and Dougill, Andrew J and Hirons, Linda C and Indasi, Victor S and Lamptey, Benjamin L and Marshall, Fionne and Marsham, John H and M Stein, Thorwald H and Taylor, Christopher M and Todd, Martin C and Visman, Emma L and Woolnough, Steven J},
	keywords = {★},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/Z4ZXNT8J/GCRF_African_SWIFT-ForPAc_White_Paper.pdf:application/pdf},
}

@inproceedings{kim_precipitation_2020,
	title = {Precipitation {Nowcasting} {Using} {Grid}-based {Data} in {South} {Korea} {Region}},
	volume = {2020-November},
	isbn = {978-1-72819-012-9},
	doi = {10.1109/ICDMW51313.2020.00099},
	abstract = {Recently, precipitation nowcasting has gained significant attention. For instance, the demand for precise precipitation nowcasting is significantly increasing in South Korea since the economic damage has been severe in recent days because of frequent and unexpected heavy rainfall. In this paper, we propose a U-Net based deep learning model that predicts from a numerical model and then corrects the data using the U-Net based deep learning model so that it can improve the accuracy of the final prediction. We use two data sets: reanalysis data and LDAPS(Local Data Assimilation and Prediction System) prediction data. Both data sets are grid-based data that covers the whole South Korea region. We first experiment with reanalysis data to identify that our U-Net model can find atmospheric dynamics patterns, even if it is not image data. Next, we use LDAPS prediction data and apply it to the U-Net model. Because LDAPS prediction data is also a prediction, we essentially conduct correcting task for this data. To this aim, a learnable layer is added at the front of the U-Net model and concatenated with the input batch to learn location-specific information. The experiment shows that the U-Net based model can find patterns using reanalysis data. Further, it has the potential to improve the accuracy of LDAPS prediction data. We also find that the learnable layer enhances test accuracy.},
	booktitle = {{IEEE} {International} {Conference} on {Data} {Mining} {Workshops}, {ICDMW}},
	publisher = {IEEE Computer Society},
	author = {Kim, Chang Hwan and Yun, Se Young},
	month = nov,
	year = {2020},
	note = {ISSN: 23759259},
	keywords = {Deep Learning, LDAPS, Numerical Model Correction, Precipitation Nowcasting, U-Net},
	pages = {701--706},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/3F64AAS8/Precipitation_Nowcasting_Using_Grid-based_Data_in_South_Korea_Region (1).pdf:application/pdf},
}

@article{jeong_correcting_2023,
	title = {Correcting rainfall forecasts of a numerical weather prediction model using generative adversarial networks},
	volume = {79},
	issn = {15730484},
	doi = {10.1007/s11227-022-04686-y},
	abstract = {In recent years, the use of deep learning techniques to forecast the weather has increased significantly; however, existing machine learning methods based on observed data are only suitable for very short-term forecasting. Numerical models are more stable for short- and medium-term forecasting, but the results may deviate from the observed data. This study proposes a deep learning method to improve the performance of numerical weather prediction models. In this method, the transformation relationship between the output of the numerical model and the observed data is learned by a generative adversarial network, which is then used to correct the forecasts of the numerical model. Experiments on 9 months of paired numerical model data and observed radar data demonstrate that correction of the forecast data using this method improves prediction performance, especially of heavy rainfall events. The proposed method provides a practical approach to combining conventional numerical weather prediction with data-driven deep learning models.},
	number = {2},
	journal = {Journal of Supercomputing},
	author = {Jeong, Chang Hoo and Yi, Mun Yong},
	month = feb,
	year = {2023},
	note = {Publisher: Springer},
	keywords = {★, Forecasts correction, Generative adversarial network, Numerical weather prediction, Weather research and forecasting model},
	pages = {1289--1317},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/HTHITG9H/s11227-022-04686-y.pdf:application/pdf},
}

@article{jankov_partition_2021,
	title = {Partition of {Forecast} {Error} into {Positional} and {Structural} {Components}},
	volume = {38},
	issn = {18619533},
	doi = {10.1007/s00376-021-0251-7},
	abstract = {Weather manifests in spatiotemporally coherent structures. Weather forecasts hence are affected by both positional and structural or amplitude errors. This has been long recognized by practicing forecasters (cf., e.g., Tropical Cyclone track and intensity errors). Despite the emergence in recent decades of various objective methods for the diagnosis of positional forecast errors, most routine verification or statistical post-processing methods implicitly assume that forecasts have no positional error. The Forecast Error Decomposition (FED) method proposed in this study uses the Field Alignment technique which aligns a gridded forecast with its verifying analysis field. The total error is then partitioned into three orthogonal components: (a) large scale positional, (b) large scale structural, and (c) small scale error variance. The use of FED is demonstrated over a month-long MSLP data set. As expected, positional errors are often characterized by dipole patterns related to the displacement of features, while structural errors appear with single extrema, indicative of magnitude problems. The most important result of this study is that over the test period, more than 50\% of the total mean sea level pressure forecast error variance is associated with large scale positional error. The importance of positional error in forecasts of other variables and over different time periods remain to be explored.},
	number = {6},
	journal = {Advances in Atmospheric Sciences},
	author = {Jankov, Isidora and Gregory, Scott and Ravela, Sai and Toth, Zoltan and Peña, Malaquías},
	month = jun,
	year = {2021},
	note = {Publisher: Science Press},
	keywords = {forecast error, orthogonal decomposition, positional, structural},
	pages = {1012--1019},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/BCP5IAZE/Jankov2021_Article_PartitionOfForecastErrorIntoPo.pdf:application/pdf},
}

@techreport{goos_lncs_nodate,
	title = {{LNCS} 3723 - {Analysis} and {Modelling} of {Faces} and {Gestures}},
	author = {Goos, Gerhard and Hartmanis, Juris and Van, Jan and Board, Leeuwen Editorial and Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M and Mattern, Friedemann and Zurich, Eth and Mitchell, John C and Naor, Moni and Nierstrasz, Oscar and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y and Weikum, Gerhard},
	note = {Publication Title: Lecture Notes in},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/TAZ43E4F/11564386.pdf:application/pdf},
}

@article{zick_quantifying_2020,
	title = {Quantifying extreme precipitation forecasting skill in high-resolution models using spatial patterns: {A} case study of the 2016 and 2018 ellicott city floods},
	volume = {11},
	issn = {20734433},
	doi = {10.3390/atmos11020136},
	abstract = {Recent historic floods in Ellicott City, MD, on 30 July 2016 and 27 May 2018 provide stark examples of the types of floods that are expected to become more frequent due to urbanization and climate change. Given the profound impacts associated with flood disasters, it is crucial to evaluate the capability of state-of-the-art weather models in predicting these hydrometeorological events. This study utilizes an object-based approach to evaluate short range ({\textless}12 h) hourly forecast precipitation from the High-Resolution Rapid Refresh (HRRR) versus observations from the National Centers for Environmental Prediction (NCEP) Stage IV precipitation analysis. For both datasets, a binary precipitation field is delineated using thresholds that span trace to extreme precipitation rates. Next, spatial metrics of area, perimeter, solidity, elongation, and fragmentation, as well as centroid positions for the forecast and observed fields are calculated. A Mann-Whitney fi-test reveals biases (using a confidence level of 90\%) related to the spatial attributes and locations of model forecast precipitation. Results indicate that traditional pixel-based precipitation verification metrics are limited in their ability to quantify and characterize model skill. In contrast, an object-based methodology offers encouraging results in that the HRRR can skillfully predict the extreme precipitation rates that are anticipated with anthropogenic climate change. Yet, there is still room for improvement, since model forecasts of extreme convective rainfall tend to be slightly too numerous and fragmented compared with observations. Lastly, results are sensitive to the HRRR model's representation of synoptic-scale and mesoscale processes. Therefore, detailed surface analyses and an "ingredients-based" approach should remain central to the process of forecasting excessive rainfall.},
	number = {2},
	journal = {Atmosphere},
	author = {Zick, Stephanie E.},
	month = feb,
	year = {2020},
	note = {Publisher: MDPI AG},
	keywords = {Extreme flood, Hydromereorology, Precipitation verification, Spatial analysis},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/MHRXW4SK/Quantifying_Extreme_Precipitation_Forecasting_Skil.pdf:application/pdf},
}

@article{chen_application_2018,
	title = {Application of {Contiguous} {Rain} {Area} ({CRA}) {Methods} to {Tropical} {Cyclone} {Rainfall} {Forecast} {Verification}},
	volume = {5},
	issn = {23335084},
	doi = {10.1029/2018EA000412},
	abstract = {This study demonstrates the useful information that can be derived from contiguous rain area (CRA) evaluation, such as systematic errors in tropical cyclone (TC) rainfall location and components of rainfall error due to incorrect predictions of location, rain volume, and rain pattern. CRA verification uses pattern matching techniques to determine the location error, as well as errors in area, mean and maximum intensity, and spatial pattern. In this study, CRA verification was applied to evaluate Australian Community Climate and Earth System Simulator (ACCESS)-TC, the TC version of ACCESS, daily rainfall forecasts over 15 TCs in the north west Pacific ocean during 2012–2013, by comparing with Tropical Rainfall Measuring Mission (TRMM) 3B42 satellite estimates. The results showed that pattern error was the major contributor to the total TC rainfall forecast error, followed by volume and displacement. ACCESS-TC forecasts tended to predict more rainfall closer to the TC center compared to Tropical Rainfall Measuring Mission (TRMM) 3B42 estimates. This bias occurred for different CRA rainfall thresholds, verification grid resolutions and forecast lead times. Furthermore, rain event verification showed that for short lead time (24 hr) forecasts, overestimation of rain volume was a major problem for ACCESS-TC forecasts, while displacement error was more significant in longer lead time (72 hr) forecasts. Finally, we compared empirical probability distribution functions and radial probability distributions of rainfall in the forecasts and observations to further characterise the rain volume error. This confirmed that ACCESS-TC tended to produce more extreme rain in the locations closer to the TC center (eyewall).},
	number = {11},
	journal = {Earth and Space Science},
	author = {Chen, Yingjun and Ebert, Elizabeth E. and Davidson, Noel E. and Walsh, Kevin J.E.},
	month = nov,
	year = {2018},
	note = {Publisher: Wiley-Blackwell Publishing Ltd},
	keywords = {evaluation, precipitation, spatial verification, hurricane, model forecast, typhoon},
	pages = {736--752},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/ZLT8N9FW/Chen_et_al_CRA-TCrain_ESS2018.pdf:application/pdf},
}

@article{zschenderlein_application_2019,
	title = {Application of an object-based verification method to ensemble forecasts of 10-m wind gusts during winter storms},
	volume = {28},
	issn = {16101227},
	doi = {10.1127/metz/2019/0880},
	abstract = {The object-based method SAL (Structure, Amplitude and Location) was adapted for investigating the errors of forecasts of extreme 10-m wind gusts associated with winter storms in Germany. It has been applied to a statistically downscaled version of the 51 member ECMWF (European Centre for Medium Range Weather Forecasts) operational ensemble forecast. The horizontal resolution of both downscaled data and of the German weather service's operational analysis data used for verification is 7 km. Forecast errors are subdivided in terms of storm intensity, location and extent. After identifying a set of storm events, objects of moderate and intense 10-m wind gusts were identified with a local percentile-based threshold (90th percentile for moderate and 98th percentile for intense gust objects). Depending on the intensity of the storm, the gust objects differ in terms of size, shape and intensity. The characteristics of the ensemble forecasts of 10-m wind gusts can basically be assessed in two different ways. Individual forecast members can be evaluated with respect to the location, intensity and extent of the gust field, and then address the ensemble characteristics by the score distributions. Alternatively, the gust fields' location, intensity and extent can be evaluated by directly using the ensemble mean forecast instead of the individual members. The results of the identified set of storms clearly indicate a high case-to-case variability in the predictability of 10-m wind gusts objects, particularly when focusing on the structure of intense wind gust objects. It is found, that the gust fields' location and overall intensity can be better estimated from the ensemble mean forecast, compared to the individual forecast members. From a forecaster's perspective this means, that a storms' location and intensity can be well estimated by considering the ensemble mean wind forecasts. Considering the structure of the gust objects, results are different. While for longer lead times, there also seems to be a benefit from applying ensemble averaging, at short lead times the ensemble mean forecast performs equally or worse than most of the individual forecast members. The amplitude error is often the smallest component of the three error types. The findings are particularly relevant when deriving warning information, by giving guidance to forecasters when interpreting ensemble forecasts for severe storms.},
	number = {3},
	journal = {Meteorologische Zeitschrift},
	author = {Zschenderlein, Philipp and Pardowitz, Tobias and Ulbrich, Uwe},
	year = {2019},
	note = {Publisher: Gebruder Borntraeger Verlagsbuchhandlung},
	keywords = {Ensemble forecasts, Object-based verification, Spatial verification, Winter storms},
	pages = {203--213},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/3Z4AGE6M/_metz__Application_of_an_object_based_verification_method_to_ensemble_forecasts_of_10_m_wind_gusts_during_winter_storms_90341.pdf:application/pdf},
}

@techreport{davis_object-based_2006,
	title = {Object-{Based} {Verification} of {Precipitation} {Forecasts}. {Part} {I}: {Methodology} and {Application} to {Mesoscale} {Rain} {Areas}},
	abstract = {A recently developed method of defining rain areas for the purpose of verifying precipitation produced by numerical weather prediction models is described. Precipitation objects are defined in both forecasts and observations based on a convolution (smoothing) and thresholding procedure. In an application of the new verification approach, the forecasts produced by the Weather Research and Forecasting (WRF) model are evaluated on a 22-km grid covering the continental United States during July-August 2001. Observed rainfall is derived from the stage-IV product from NCEP on a 4-km grid (averaged to a 22-km grid). It is found that the WRF produces too many large rain areas, and the spatial and temporal distribution of the rain areas reveals regional underestimates of the diurnal cycle in rain-area occurrence frequency. Objects in the two datasets are then matched according to the separation distance of their centroids. Overall, WRF rain errors exhibit no large biases in location, but do suffer from a positive size bias that maximizes during the later afternoon. This coincides with an excessive narrowing of the rainfall intensity range, consistent with the dominance of parameterized convection. Finally, matching ability has a strong dependence on object size and is interpreted as the influence of relatively predictable synoptic-scale systems on the larger areas.},
	author = {Davis, Christopher and Brown, Barbara and Bullock, Randy},
	year = {2006},
	keywords = {★},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/U26VHDA4/1520-0493-mwr3145.1.pdf:application/pdf},
}

@techreport{davis_object-based_2006-1,
	title = {Object-{Based} {Verification} of {Precipitation} {Forecasts}. {Part} {II}: {Application} to {Convective} {Rain} {Systems}},
	abstract = {The authors develop and apply an algorithm to define coherent areas of precipitation, emphasizing mesoscale convection, and compare properties of these areas with observations obtained from NCEP stage-IV precipitation analyses (gauge and radar combined). In Part II, fully explicit 12-36-h forecasts of rainfall from the Weather Research and Forecasting model (WRF) are evaluated. These forecasts are integrated on a 4-km mesh without a cumulus parameterization. Rain areas are defined similarly to Part I, but emphasize more intense, smaller areas. Furthermore, a time-matching algorithm is devised to group spatially and temporally coherent areas into rain systems that approximate mesoscale convective systems. In general, the WRF model produces too many rain areas with length scales of 80 km or greater. Rain systems typically last too long, and are forecast to occur 1-2 h later than observed. The intensity distribution among rain systems in the 4-km forecasts is generally too broad, especially in the late afternoon, in sharp contrast to the intensity distribution obtained on a coarser grid with parameterized convection in Part I. The model exhibits the largest positive size and intensity bias associated with systems over the Midwest and Mississippi Valley regions, but little size bias over the High Plains, Ohio Valley, and the southeast United States. For rain systems lasting 6 h or more, the critical success index for matching forecast and observed rain systems agrees closely with that obtained in a related study using manually determined rain systems.},
	author = {Davis, Christopher and Brown, Barbara and Bullock, Randy},
	year = {2006},
	keywords = {★},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/5CLHTDUT/1520-0493-mwr3146.1.pdf:application/pdf},
}

@article{marzban_three_2009,
	title = {Three spatial verification techniques: {Cluster} analysis, variogram, and optical flow},
	volume = {24},
	issn = {08828156},
	doi = {10.1175/2009WAF2222261.1},
	abstract = {Three spatial verification techniques are applied to three datasets. The datasets consist of a mixture of real and artificial forecasts, and corresponding observations, designed to aid in better understanding the effects of global (i.e., across the entire field) displacement and intensity errors. The three verification techniques, each based on well-known statistical methods, have little in common and, so, present different facets of forecast quality. It is shown that a verification method based on cluster analysis can identify "objects" in a forecast and an observation field, thereby allowing for object-oriented verification in the sense that it considers displacement, missed forecasts, and false alarms. A second method compares the observed and forecast fields, not in terms of the objects within them, but in terms of the covariance structure of the fields, as summarized by their variogram. The last method addresses the agreement between the two fields by inferring the function that maps one to the other. The map-generally called optical flow-provides a (visual) summary of the "difference" between the two fields. A further summary measure of that map is found to yield useful information on the distortion error in the forecasts. © 2009 American Meteorological Society.},
	number = {6},
	journal = {Weather and Forecasting},
	author = {Marzban, Caren and Sandgathe, Scott and Lyons, Hilary and Lederer, Nicholas},
	month = dec,
	year = {2009},
	keywords = {★},
	pages = {1457--1471},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/EJ9CJ8XF/1520-0434-2009waf2222261_1.pdf:application/pdf},
}

@article{wernli_sal_2008,
	title = {{SAL} - {A} novel quality measure for the verification of quantitative precipitation forecasts},
	volume = {136},
	issn = {00270644},
	doi = {10.1175/2008MWR2415.1},
	abstract = {A novel object-based quality measure, which contains three distinct components that consider aspects of the structure (S), amplitude (A), and location (L) of the precipitation field in a prespecified domain (e.g., a river catchment) is introduced for the verification of quantitative precipitation forecasts (QPF). This quality measure is referred to as SAL. The amplitude component A measures the relative deviation of the domain-averaged QPF from observations. Positive values of A indicate an overestimation of total precipitation; negative values indicate an underestimation. For the components S and L, coherent precipitation objects are separately identified in the forecast and observations; however, no matching is performed of the objects in the two datasets. The location component L combines information about the displacement of the predicted (compared to the observed) precipitation field's center of mass and about the error in the weighted-average distance of the precipitation objects from the total field's center of mass. The structure component S is constructed in such a way that positive values occur if precipitation objects are too large and/or too flat, and negative values if the objects are too small and/or too peaked. Perfect QPFs are characterized by zero values for all components of SAL. Examples with both synthetic precipitation fields and real data are shown to illustrate the concept and characteristics of SAL. SAL is applied to 4 yr of daily accumulated QPFs from a global and finer-scale regional model for a German river catchment, and the SAL diagram is introduced as a compact means of visualizing the results. SAL reveals meaningful information about the systematic differences in the performance of the two models. While the median of the S component is close to zero for the regional model, it is strongly positive for the coarser-scale global model. Consideration is given to the strengths and limitations of the novel quality measure and to possible future applications, in particular, for the verification of QPFs from convection-resolving weather prediction models on short time scales. © 2008 American Meteorological Society.},
	number = {11},
	journal = {Monthly Weather Review},
	author = {Wernli, Heini and Paulat, Marcus and Hagen, Martin and Frei, Christoph},
	year = {2008},
	pages = {4470--4487},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/UCSRUBFM/1520-0493-2008mwr2415.1 (1).pdf:application/pdf},
}

@article{zick_anatomy_2022,
	title = {Anatomy of a storm: {A} review of shape analysis research that fuses form and function in weather forecasting and analysis},
	issn = {14770296},
	doi = {10.1177/03091333221133098},
	abstract = {Features in the natural and built environment can be viewed as objects, and an object’s shape provides valuable information about the physical processes that generate those features. Formally, shape is defined as an object’s characteristics independent of rotation, translation, and scale. Shape analysis involves quantification of an object’s form. Shape metrics, or indices, are mathematical quantities that characterize the object’s size and shape. Shape analysis has a rich history in geography and, more specifically, in meteorology and climatology research, with early examples in the identification of comma-shaped clouds in satellite imagery and “hook echoes” in radar reflectivity imagery. At its basis, shape analysis can be characterized as image analysis, which involves processing an image to extract meaningful information. Shape analysis usually involves image segmentation to isolate objects of interest and region analysis to calculate statistical data about these object(s). Current shape analysis research in meteorology and climatology can be split into two broad themes: (1) verification studies to compare model forecasts with observations and (2) process studies that provide information about the dynamical structure of a particular weather or climate phenomenon. In this report, I provide examples of emerging research that uses shape analysis to study tropical cyclones, mesoscale weather phenomena, and atmospheric rivers. Thus far, most of the process studies have been related to TC structure. Future research should also consider innovative approaches to image segmentation, new spatial verification methods for ensemble forecasting products, and more shaped-based process studies in mesoscale meteorology.},
	journal = {Progress in Physical Geography},
	author = {Zick, Stephanie E.},
	month = feb,
	year = {2022},
	note = {Publisher: SAGE Publications Ltd},
	keywords = {Climate, image analysis, object-based, shape analysis, weather},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/682CN3LR/03091333221133098.pdf:application/pdf},
}

@article{gilleland_analyzing_2010,
	title = {Analyzing the image warp forecast verification method on precipitation fields from the {ICP}},
	volume = {25},
	issn = {08828156},
	doi = {10.1175/2010WAF2222365.1},
	abstract = {Image warping for spatial forecast verification is applied to the test cases employed by the Spatial Forecast Verification Intercomparison Project (ICP), which includes both real and contrived cases.A larger set of cases is also used to investigate aggregating results for summarizing forecast performance over a long record of forecasts. The technique handles the geometric and perturbed cases with nearly exact precision, as would be expected. A statistic, dubbed here the IWS for image warp statistic, is proposed for ranking multiple forecasts and tested on the perturbed cases. IWS rankings for perturbed and real test cases are found to be sensible and physically interpretable. A powerful result of this study is that the image warp can be employed using a relatively sparse, preset regular grid without having to first identify features. © 2010 American Meteorological Society.},
	number = {4},
	journal = {Weather and Forecasting},
	author = {Gilleland, Eric and Lindstrom, Johan and Finn, Lindgren},
	month = aug,
	year = {2010},
	keywords = {Precipitation, ★, Forecast verification, Statistical forecasting, Stochastic models},
	pages = {1249--1262},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/6HEF99D9/1520-0434-2010waf2222365_1.pdf:application/pdf},
}

@article{keil_displacement-based_2007,
	title = {A displacement-based error measure applied in a regional ensemble forecasting system},
	volume = {135},
	issn = {00270644},
	doi = {10.1175/MWR3457.1},
	abstract = {Errors in regional forecasts often take the form of phase errors, where a forecasted weather system is displaced in space or time. For such errors, a direct measure of the displacement is likely to be more valuable than traditional measures. A novel forecast quality measure is proposed that is based on a comparison of observed and forecast satellite imagery from the Meteosat-7 geostationary satellite. The measure combines the magnitude of a displacement vector calculated with a pyramid matching algorithm and the local squared difference of observed and morphed forecast brightness temperature fields. Following the description of the method and its application for a simplified case, the measure is applied to regional ensemble forecasts for an episode of prefrontal summertime convection in Bavaria. It is shown that this new method provides a plausible measure of forecast error, which is consistent with a subjective ranking of ensemble members for a sample forecast. The measure is then applied to hourly images over a 36-h forecast period and compared with the bias and equitable threat score. The two conventional measures fail to provide any systematic distinction between different ensemble members, while the new measure identifies ensemble members of differing skill levels with a strong degree of temporal consistency. Using the displacement-based error measure, individual ensemble members are found to compare better with observations than either a short-term deterministic forecast or the ensemble mean throughout the convective period. © 2007 American Meteorological Society.},
	number = {9},
	journal = {Monthly Weather Review},
	author = {Keil, Christian and Craig, George C.},
	month = sep,
	year = {2007},
	pages = {3248--3259},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/GQX2IE5A/1520-0493-mwr3457.1 (2).pdf:application/pdf},
}

@article{gagne_machine_2020,
	title = {Machine {Learning} for {Stochastic} {Parameterization}: {Generative} {Adversarial} {Networks} in the {Lorenz} '96 {Model}},
	volume = {12},
	issn = {19422466},
	doi = {10.1029/2019MS001896},
	abstract = {Stochastic parameterizations account for uncertainty in the representation of unresolved subgrid processes by sampling from the distribution of possible subgrid forcings. Some existing stochastic parameterizations utilize data-driven approaches to characterize uncertainty, but these approaches require significant structural assumptions that can limit their scalability. Machine learning models, including neural networks, are able to represent a wide range of distributions and build optimized mappings between a large number of inputs and subgrid forcings. Recent research on machine learning parameterizations has focused only on deterministic parameterizations. In this study, we develop a stochastic parameterization using the generative adversarial network (GAN) machine learning framework. The GAN stochastic parameterization is trained and evaluated on output from the Lorenz '96 model, which is a common baseline model for evaluating both parameterization and data assimilation techniques. We evaluate different ways of characterizing the input noise for the model and perform model runs with the GAN parameterization at weather and climate time scales. Some of the GAN configurations perform better than a baseline bespoke parameterization at both time scales, and the networks closely reproduce the spatiotemporal correlations and regimes of the Lorenz '96 system. We also find that, in general, those models which produce skillful forecasts are also associated with the best climate simulations.},
	number = {3},
	journal = {Journal of Advances in Modeling Earth Systems},
	author = {Gagne, David John and Christensen, Hannah M. and Subramanian, Aneesh C. and Monahan, Adam H.},
	month = mar,
	year = {2020},
	note = {arXiv: 1909.04711
Publisher: Blackwell Publishing Ltd},
	keywords = {machine learning, weather, climate, generative adversarial networks, lorenz, stochastic parameterization},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/MVGMCLXS/J Adv Model Earth Syst - 2020 - Gagne - Machine Learning for Stochastic Parameterization  Generative Adversarial Networks.pdf:application/pdf},
}

@article{amemiya_application_2023,
	title = {Application of recurrent neural networks to model bias correction: {Idealized} experiments with the {Lorenz}‐96 model},
	issn = {1942-2466},
	doi = {10.1029/2022ms003164},
	abstract = {Systematic biases in numerical weather prediction models cause forecast deviation from reality. While model biases also affect data assimilation and degrade the analysis accuracy, observation information incorporated through data assimilation can provide information for detecting and alleviating such biases. In this study, the application of machine learning to model bias correction is demonstrated, emphasizing the effectiveness of recurrent neural networks. Idealized experiments are performed using the two‐scale coupled Lorenz‐96 model as the true system and single Lorenz‐96 model as the imperfect forecast model, to compare the effectiveness of bias correction methods based on various architectures of neural networks and simple linear regression. The neural networks generally outperformed linear regression, and recurrent neural networks showed the best ability in finding the systematic bias component from the analysis increment data. Bias correction using the recurrent neural networks also gives the most significant improvement in reducing the error growth rate in extended range forecasts. The results suggest that including past time series of the forecast variables improve model bias correction when limited information of the observation is incorporated through data assimilation.},
	journal = {Journal of Advances in Modeling Earth Systems},
	author = {Amemiya, A. and Shlok, M. and Miyoshi, T.},
	month = feb,
	year = {2023},
	note = {Publisher: American Geophysical Union (AGU)},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/N8MIN642/J Adv Model Earth Syst - 2023 - Amemiya - Application of Recurrent Neural Networks to Model Bias Correction  Idealized.pdf:application/pdf},
}

@article{harrison_advancing_2022,
	title = {Advancing early warning capabilities with {CHIRPS}-compatible {NCEP} {GEFS} precipitation forecasts},
	volume = {9},
	issn = {20524463},
	doi = {10.1038/s41597-022-01468-2},
	abstract = {CHIRPS-GEFS is an operational data set that provides daily bias-corrected forecasts for next 1-day to {\textasciitilde}15-day precipitation totals and anomalies at a quasi-global 50-deg N to 50-deg S extent and 0.05-degree resolution. These are based on National Centers for Environmental Prediction (NCEP) Global Ensemble Forecast System version 12 (GEFS v12) precipitation forecasts. CHIRPS-GEFS forecasts are compatible with Climate Hazards center InfraRed Precipitation with Stations (CHIRPS) data, which is actively used for drought monitoring, early warning, and near real-time impact assessments. A rank-based quantile matching procedure is used to transform GEFS v12 “reforecast” and “real-time” forecast ensemble means to CHIRPS spatial-temporal characteristics. Matching distributions to CHIRPS makes forecasts better reflect local climatology at finer spatial resolution and reduces moderate-to-large forecast errors. As shown in this study, having a CHIRPS-compatible version of the latest generation of NCEP GEFS forecasts enables rapid assessment of current forecasts and local historical context. CHIRPS-GEFS effectively bridges the gap between observations and weather predictions, increasing the value of both by connecting monitoring resources (CHIRPS) with interoperable forecasts.},
	number = {1},
	journal = {Scientific Data},
	author = {Harrison, Laura and Landsfeld, Martin and Husak, Greg and Davenport, Frank and Shukla, Shraddhanand and Turner, William and Peterson, Pete and Funk, Chris},
	month = dec,
	year = {2022},
	pmid = {35773449},
	note = {Publisher: Nature Research},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/Q6V58NJC/s41597-022-01468-2.pdf:application/pdf},
}

@techreport{katz_weather_nodate,
	title = {Do {Weather} or {Climate} {Variables} and {Their} {Impacts} {Have} {Heavy}-{Tailed} {Distributions}?},
	url = {http://ulysses.atmos.colostate.edu},
	author = {Katz, Richard W},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/ILUGEXAZ/26949 (1).pdf:application/pdf},
}

@article{clauset_power-law_2007,
	title = {Power-law distributions in empirical data},
	url = {http://arxiv.org/abs/0706.1062},
	doi = {10.1137/070710111},
	abstract = {Power-law distributions occur in many situations of scientific interest and have significant consequences for our understanding of natural and man-made phenomena. Unfortunately, the detection and characterization of power laws is complicated by the large fluctuations that occur in the tail of the distribution -- the part of the distribution representing large but rare events -- and by the difficulty of identifying the range over which power-law behavior holds. Commonly used methods for analyzing power-law data, such as least-squares fitting, can produce substantially inaccurate estimates of parameters for power-law distributions, and even in cases where such methods return accurate answers they are still unsatisfactory because they give no indication of whether the data obey a power law at all. Here we present a principled statistical framework for discerning and quantifying power-law behavior in empirical data. Our approach combines maximum-likelihood fitting methods with goodness-of-fit tests based on the Kolmogorov-Smirnov statistic and likelihood ratios. We evaluate the effectiveness of the approach with tests on synthetic data and give critical comparisons to previous approaches. We also apply the proposed methods to twenty-four real-world data sets from a range of different disciplines, each of which has been conjectured to follow a power-law distribution. In some cases we find these conjectures to be consistent with the data while in others the power law is ruled out.},
	author = {Clauset, Aaron and Shalizi, Cosma Rohilla and Newman, M. E. J.},
	month = jun,
	year = {2007},
	note = {arXiv: 0706.1062},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/4QCQPUT9/0706.1062.pdf:application/pdf},
}

@article{newman_power_2005,
	title = {Power laws, {Pareto} distributions and {Zipf}'s law},
	volume = {46},
	issn = {00107514},
	doi = {10.1080/00107510500052444},
	abstract = {When the probability of measuring a particular value of some quantity varies inversely as a power of that value, the quantity is said to follow a power law, also known variously as Zipf's law or the Pareto distribution. Power laws appear widely in physics, biology, earth and planetary sciences, economics and finance, computer science, demography and the social sciences. For instance, the distributions of the sizes of cities, earthquakes, forest fires, solar flares, moon craters and people's personal fortunes all appear to follow power laws. The origin of power-law behaviour has been a topic of debate in the scientific community for more than a century. Here we review some of the empirical evidence for the existence of power-law forms and the theories proposed to explain them. © 2005 Taylor \& Francis Group Ltd.},
	number = {5},
	journal = {Contemporary Physics},
	author = {Newman, M. E.J.},
	month = sep,
	year = {2005},
	note = {arXiv: cond-mat/0412004},
	pages = {323--351},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/2PM3F56T/Power laws Pareto distributions and Zipf s law.pdf:application/pdf},
}

@article{gabaix_zipfs_1999,
	title = {Zipf's {Law} for {Cities}: {An} {Explanation}},
	volume = {114},
	issn = {0033-5533},
	url = {https://academic.oup.com/qje/article-lookup/doi/10.1162/003355399556133},
	doi = {10.1162/003355399556133},
	number = {3},
	journal = {The Quarterly Journal of Economics},
	author = {Gabaix, X.},
	month = aug,
	year = {1999},
	pages = {739--767},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/KIAFGKHN/Gabaix.pdf:application/pdf},
}

@article{aitchison_zipfs_2016,
	title = {Zipf’s {Law} {Arises} {Naturally} {When} {There} {Are} {Underlying}, {Unobserved} {Variables}},
	volume = {12},
	issn = {15537358},
	doi = {10.1371/journal.pcbi.1005110},
	abstract = {Zipf’s law, which states that the probability of an observation is inversely proportional to its rank, has been observed in many domains. While there are models that explain Zipf’s law in each of them, those explanations are typically domain specific. Recently, methods from statistical physics were used to show that a fairly broad class of models does provide a general explanation of Zipf’s law. This explanation rests on the observation that real world data is often generated from underlying causes, known as latent variables. Those latent variables mix together multiple models that do not obey Zipf’s law, giving a model that does. Here we extend that work both theoretically and empirically. Theoretically, we provide a far simpler and more intuitive explanation of Zipf’s law, which at the same time considerably extends the class of models to which this explanation can apply. Furthermore, we also give methods for verifying whether this explanation applies to a particular dataset. Empirically, these advances allowed us extend this explanation to important classes of data, including word frequencies (the first domain in which Zipf’s law was discovered), data with variable sequence length, and multi-neuron spiking activity.},
	number = {12},
	journal = {PLoS Computational Biology},
	author = {Aitchison, Laurence and Corradi, Nicola and Latham, Peter E.},
	month = dec,
	year = {2016},
	pmid = {27997544},
	note = {Publisher: Public Library of Science},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/Z52PAPKX/zipfs_law.pdf:application/pdf},
}

@article{gabaix_power_2016,
	title = {Power laws in economics: {An} introduction},
	volume = {30},
	issn = {08953309},
	doi = {10.1257/jep.30.1.185},
	abstract = {Many of the insights of economics seem to be qualitative, with many fewer reliable quantitative laws. However a series of power laws in economics do count as true and nontrivial quantitative laws - and they are not only established empirically, but also understood theoretically. I will start by providing several illustrations of empirical power laws having to do with patterns involving cities, firms, and the stock market. I summarize some of the theoretical explanations that have been proposed. I suggest that power laws help us explain many economic phenomena, including aggregate economic fluctuations. I hope to clarify why power laws are so special, and to demonstrate their utility. In conclusion, I list some power-law-related economic enigmas that demand further exploration.},
	number = {1},
	journal = {Journal of Economic Perspectives},
	author = {Gabaix, Xavier},
	month = dec,
	year = {2016},
	note = {Publisher: American Economic Association},
	pages = {185--206},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/T4RKCE8M/jep.30.1.185.pdf:application/pdf},
}

@article{noauthor_csu_todorovic_1970_nodate,
	title = {{CSU}\_Todorovic\_1970},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/HAHRTX4V/CSU_Todorovic_1970.pdf:application/pdf},
}

@article{hansen_three_2020,
	title = {The {Three} {Extreme} {Value} {Distributions}: {An} {Introductory} {Review}},
	volume = {8},
	issn = {2296424X},
	doi = {10.3389/fphy.2020.604053},
	abstract = {The statistical distribution of the largest value drawn from a sample of a given size has only three possible shapes: it is either a Weibull, a Fréchet or a Gumbel extreme value distributions. I describe in this short review how to relate the statistical distribution followed by the numbers in the sample to the associate extreme value distribution followed by the largest value within the sample. Nothing I present here is new. However, from experience, I have found that a simple, short and compact guide on this matter written for the physics community is missing.},
	journal = {Frontiers in Physics},
	author = {Hansen, Alex},
	month = dec,
	year = {2020},
	note = {arXiv: 2009.03711
Publisher: Frontiers Media S.A.},
	keywords = {extreme value statistics, Frechet distribution, Weibull distribution, Gumbel distribution, statistical analysis, Weibull analysis},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/98WTILLA/fphy-08-604053.pdf:application/pdf},
}

@article{davison_models_1990,
	title = {Models for {Exceedances} {Over} {High} {Thresholds}},
	volume = {52},
	doi = {10.1111/j.2517-6161.1990.tb01796.x},
	abstract = {We discuss the analysis of the extremes of data by modelling the sizes and occurrence of exceedances over high thresholds. The natural distribution for such exceedances, the generalized Pareto distribution, is described and its properties elucidated. Estimation and model-checking procedures for univariate and regression data are developed, and the influence of and information contained in the most extreme observations in a sample are studied. Models for seasonality and serial dependence in the point process of exceedances are described. Sets of data on river flows and wave heights are discussed, and an application to the siting of nuclear installations is described.},
	number = {3},
	journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
	author = {Davison, A. C. and Smith, R. L.},
	month = jul,
	year = {1990},
	note = {Publisher: Wiley},
	pages = {393--425},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/U7KQ39F8/Journal of the Royal Statistical Society  Series B  Methodological - 1990 - Davison - Models for Exceedances Over High.pdf:application/pdf},
}

@article{gabaix_power_2009,
	title = {Power {Laws} in {Economics} and {Finance}},
	volume = {1},
	issn = {1941-1383},
	doi = {10.1146/annurev.economics.050708.142940},
	abstract = {A power law (PL) is the form taken by a large number of surprising empirical regularities in economics and finance. This review surveys well-documented empirical PLs regarding income and wealth, the size of cities and firms, stock market returns, trading volume, international trade, and executive pay. It reviews detail-independent theoretical motivations that make sharp predictions concerning the existence and coefficients of PLs, without requiring delicate tuning of model parameters. These theoretical mechanisms include random growth, optimization, and the economics of superstars, coupled with extreme value theory. Some empirical regularities currently lack an appropriate explanation. This article highlights these open areas for future research.},
	number = {1},
	journal = {Annual Review of Economics},
	author = {Gabaix, Xavier},
	month = sep,
	year = {2009},
	note = {Publisher: Annual Reviews},
	pages = {255--294},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/BHJKVQJL/pl-ar.pdf:application/pdf},
}

@techreport{sutton_gibrats_1997,
	title = {Gibrat's {Legacy}},
	author = {Sutton, John},
	year = {1997},
	note = {Publication Title: Source: Journal of Economic Literature
Volume: 35
Issue: 1},
	pages = {40--59},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/VQG53T6I/2729692.pdf:application/pdf},
}

@inproceedings{adrian_twenty_2005,
	title = {Twenty years of particle image velocimetry},
	volume = {39},
	doi = {10.1007/s00348-005-0991-7},
	abstract = {The development of the method of particle image velocimetry (PIV) is traced by describing some of the milestones that have enabled new and/or better measurements to be made. The current status of PIV is summarized, and some goals for future advances are addressed. © Springer-Verlag 2005.},
	booktitle = {Experiments in {Fluids}},
	author = {Adrian, R. J.},
	month = aug,
	year = {2005},
	note = {Issue: 2
ISSN: 07234864},
	pages = {159--169},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/97HAFAIX/s00348-005-0991-7.pdf:application/pdf},
}

@article{pan_two-dimensional_2009,
	title = {Two-dimensional digital image correlation for in-plane displacement and strain measurement: {A} review},
	volume = {20},
	issn = {13616501},
	doi = {10.1088/0957-0233/20/6/062001},
	abstract = {As a practical and effective tool for quantitative in-plane deformation measurement of a planar object surface, two-dimensional digital image correlation (2D DIC) is now widely accepted and commonly used in the field of experimental mechanics. It directly provides full-field displacements to sub-pixel accuracy and full-field strains by comparing the digital images of a test object surface acquired before and after deformation. In this review, methodologies of the 2D DIC technique for displacement field measurement and strain field estimation are systematically reviewed and discussed. Detailed analyses of the measurement accuracy considering the influences of both experimental conditions and algorithm details are provided. Measures for achieving high accuracy deformation measurement using the 2D DIC technique are also recommended. Since microscale and nanoscale deformation measurement can easily be realized by combining the 2D DIC technique with high-spatial- resolution microscopes, the 2D DIC technique should find more applications in broad areas. © 2009 IOP Publishing Ltd.},
	number = {6},
	journal = {Measurement Science and Technology},
	author = {Pan, Bing and Qian, Kemao and Xie, Huimin and Asundi, Anand},
	year = {2009},
	note = {Publisher: Institute of Physics Publishing},
	keywords = {Digital image correlation, Displacement/deformation measurement},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/K5XCV8S8/Pan_2009_Meas._Sci._Technol._20_062001.pdf:application/pdf},
}

@article{palmer_economic_2002,
	title = {The economic value of ensemble forecasts as a tool for risk assessment: {From} days to decades},
	volume = {128},
	issn = {00359009},
	doi = {10.1256/0035900021643593},
	abstract = {Despite the revolutionary development of numerical weather and climate prediction (NWCP) in the second half of the last century, quantitative interaction between model developers and forecast customers has been rather limited. This is apparent in the diverse ways in which weather forecasts are assessed by these two groups: rootmean-square error of 500 hPa height on the one hand; pounds, euros or dollars saved on the other. These differences of approach are changing with the development of ensemble forecasting. Ensemble forecasts provide a qualitative tool for the assessment of weather and climate risk for a range of user applications, and on a range of time-scales, from days to decades. Examples of the commercial application of ensemble forecasting, from electricity generation, ship routeing, pollution modelling, weather-risk finance, disease prediction and crop yield modelling, are shown from all these time-scales. A generic user decision model is described that allows one to assess the potential economic value of numerical weather and climate forecasts for a range of customers. Using this, it is possible to relate analytically, potential economic value to conventional meteorological skill scores. A generalized meteorological measure of forecast skill is proposed which takes the distribution of customers into account. It is suggested that when customers' exposure to weather or climate risk can be quantified, such more generalized measures of skill should be used in assessing the performance of an operational NWCP system.},
	number = {581},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Palmer, T. N.},
	month = apr,
	year = {2002},
	keywords = {Climate change, Cost/loss ratio, Probability forecasting, Seasonal forecasts, User application models},
	pages = {747--774},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/5Z6C9AGQ/Quart J Royal Meteoro Soc - April 2002 Part A - Palmer - The economic value of ensemble forecasts as a tool for risk.pdf:application/pdf},
}

@article{vannitsem_statistical_2021,
	title = {Statistical postprocessing for weather forecasts review, challenges, and avenues in a big data world},
	volume = {102},
	issn = {00030007},
	doi = {10.1175/BAMS-D-19-0308.1},
	abstract = {Statistical postprocessing techniques are nowadays key components of the forecasting suites in many national meteorological services (NMS), with, for most of them, the objective of correcting the impact of different types of errors on the forecasts. The final aim is to provide optimal, automated, seamless forecasts for end users. Many techniques are now flourishing in the statistical, meteorological, climatological, hydrological, and engineering communities. The methods range in complexity from simple bias corrections to very sophisticated distribution-adjusting techniques that incorporate correlations among the prognostic variables. The paper is an attempt to summarize the main activities going on in this area from theoretical developments to operational applications, with a focus on the current challenges and potential avenues in the field. Among these challenges is the shift in NMS toward running ensemble numerical weather prediction (NWP) systems at the kilometer scale that produce very large datasets and require high-density high-quality observations, the necessity to preserve space-time correlation of high-dimensional corrected fields, the need to reduce the impact of model changes affecting the parameters of the corrections, the necessity for techniques to merge different types of forecasts and ensembles with different behaviors, and finally the ability to transfer research on statistical postprocessing to operations. Potential new avenues are also discussed.},
	number = {3},
	journal = {Bulletin of the American Meteorological Society},
	author = {Vannitsem, Stéphane and Bremnes, John Bjørnar and Demaeyer, Jonathan and Evans, Gavin R. and Flowerdew, Jonathan and Hemri, Stephan and Lerch, Sebastian and Roberts, Nigel and Theis, Susanne and Atencia, Aitor and Bouallègue, Zied Ben and Bhend, Jonas and Dabernig, Markus and de Cruz, Lesley and Hieta, Leila and Mestre, Olivier and Moret, Lionel and Plenković, Iris Odak and Schmeits, Maurice and Taillardat, Maxime and van den Bergh, Joris and van Schaeybroeck, Bert and Whan, Kirien and Ylhaisi, Jussi},
	year = {2021},
	note = {arXiv: 2004.06582
Publisher: American Meteorological Society},
	keywords = {Bias, Data science, Model output statistics, Operational forecasting, Probability forecasts/models/distribution, Regression},
	pages = {E681--E699},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/I7RCDSNB/1520-0477-BAMS-D-19-0308.1.pdf:application/pdf},
}

@misc{unicef_more_2022,
	title = {More than twenty million children suffering in the {Horn} of {Africa} as drought intensifies},
	url = {https://www.unicef.org/press-releases/more-twenty-million-children-suffering-horn-africa-drought-intensifies-unicef},
	urldate = {2023-03-06},
	author = {{UNICEF}},
	month = dec,
	year = {2022},
}

@techreport{katz_statistics_nodate,
	title = {Statistics of extremes in hydrology},
	url = {www.elsevier.com/locate/advwatres},
	abstract = {The statistics of extremes have played an important role in engineering practice for water resources design and management. How recent developments in the statistical theory of extreme values can be applied to improve the rigor of hydrologic applications and to make such analyses more physically meaningful is the central theme of this paper. Such methodological developments primarily relate to maximum likelihood estimation in the presence of covariates, in combination with either the block maxima or peaks over threshold approaches. Topics that are treated include trends in hydrologic extremes, with the anticipated intensification of the hydrologic cycle as part of global climate change. In an attempt to link downscaling (i.e., relating large-scale atmosphere-ocean circulation to smaller-scale hydrologic variables) with the statistics of extremes, statistical downscaling of hydrologic extremes is considered. Future challenges are reviewed, such as the development of more rigorous statistical methodology for regional analysis of extremes, as well as the extension of Bayesian methods to more fully quantify uncertainty in extremal estimation. Examples include precipitation and streamflow extremes, as well as economic damage associated with such extreme events, with consideration of trends and dependence on patterns in atmosphere-ocean circulation (e.g., El Ni{\textasciitilde} n no phenomenon).},
	author = {Katz, Richard W and Parlange, Marc B and Naveau, Philippe},
	keywords = {Climate change, Covariates, Maximum likelihood, Statistical downscaling},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/4JEGYFTI/1-s2.0-S0309170802000568-main.pdf:application/pdf},
}

@article{demirdjian_statistical_2018,
	title = {Statistical modeling of extreme precipitation with {TRMM} data},
	volume = {57},
	issn = {15588432},
	doi = {10.1175/JAMC-D-17-0023.1},
	abstract = {This paper improves upon an existing extreme precipitation monitoring system that is based on the Tropical Rainfall Measuring Mission (TRMM) daily product (3B42) using new statistical models. The proposed system utilizes a regional modeling approach in which data from similar locations are pooled to increase the quality of the resulting model parameter estimates to compensate for the short data record. The regional analysis is divided into two stages. First, the region defined by the TRMM measurements is partitioned into approximately 28 000 nonoverlapping clusters using a recursive k-means clustering scheme. Next, a statistical model is used characterize the extreme precipitation events occurring in each cluster. Instead of applying the block maxima approach used in the existing system, in which the generalized extreme value probability distribution is fit to the annual precipitation maxima at each site separately, the present work adopts the peak-over-threshold method of classifying points as extreme if they exceed a prespecified threshold. Theoretical considerations motivate using the point process framework for modeling extremes. The fitted parameters are used to estimate trends and to construct simple and intuitive average recurrence interval (ARI) maps that reveal how rare a particular precipitation event is. This information could be used by policy makers for disaster monitoring and prevention. The new method eliminates much of the noise that was produced by the existing models because of a short data record, producing more reasonable ARI maps when compared with NOAA's long-term Climate Prediction Center ground-based observations. Furthermore, the proposed method can be applied to other extreme climate records.},
	number = {1},
	journal = {Journal of Applied Meteorology and Climatology},
	author = {Demirdjian, Levon and Zhou, Yaping and Huffman, George J.},
	month = jan,
	year = {2018},
	note = {Publisher: American Meteorological Society},
	keywords = {Extreme events, Precipitation, Statistical techniques, Hydrology},
	pages = {15--30},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/EVEKGAYJ/nihms-1502891.pdf:application/pdf},
}

@article{piani_statistical_2010,
	title = {Statistical bias correction for daily precipitation in regional climate models over {Europe}},
	volume = {99},
	issn = {14344483},
	doi = {10.1007/s00704-009-0134-9},
	abstract = {We design, apply, and validate a methodology for correcting climate model output to produce internally consistent fields that have the same statistical intensity distribution as the observations. We refer to this as a statistical bias correction. Validation of the methodology is carried out using daily precipitation fields, defined over Europe, from the ENSEMBLES climate model dataset. The bias correction is calculated using data from 1961 to 1970, without distinguishing between seasons, and applied to seasonal data from 1991 to 2000. This choice of time periods is made to maximize the lag between calibration and validation within the ERA40 reanalysis period. Results show that the method performs unexpectedly well. Not only are the mean and other moments of the intensity distribution improved, as expected, but so are a drought and a heavy precipitation index, which depend on the autocorrelation spectra. Given that the corrections were derived without seasonal distinction and are based solely on intensity distributions, a statistical quantity oblivious of temporal correlations, it is encouraging to find that the improvements are present even when seasons and temporal statistics are considered. This encourages the application of this method to multi-decadal climate projections. © 2009 Springer-Verlag.},
	number = {1-2},
	journal = {Theoretical and Applied Climatology},
	author = {Piani, C. and Haerter, J. O. and Coppola, E.},
	year = {2010},
	note = {Publisher: Springer Wien},
	pages = {187--192},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/N2LVSUAD/s00704-009-0134-9.pdf:application/pdf},
}

@article{wood_long-range_2002,
	title = {Long-range experimental hydrologic forecasting for the eastern {United} {States}},
	volume = {107},
	issn = {01480227},
	doi = {10.1029/2001JD000659},
	abstract = {We explore a strategy for long-range hydrologic forecasting that uses ensemble climate model forecasts as input to a macroscale hydrologic model to produce runoff and streamflow forecasts at spatial and temporal scales appropriate for water management. Monthly ensemble climate model forecasts produced by the National Centers for Environmental Prediction/Climate Prediction Center global spectral model (GSM) are bias corrected, downscaled to 1/8° horizontal resolution, and disaggregated to a daily time step for input to the Variable Infiltration Capacity hydrologic model. Bias correction is effected by evaluating the GSM ensemble forecast variables as percentiles relative to the GSM model climatology and then extracting the percentiles' associated variable values instead from the observed climatology. The monthly meteorological forecasts are then interpolated to the finer hydrologic model scale, at which a daily signal that preserves the forecast anomaly is imposed through resampling of the historic record. With the resulting monthly runoff and streamflow forecasts for the East Coast and Ohio River basin, we evaluate the bias correction and resampling approaches during the southeastern United States drought from May to August 2000 and also for the El Niño conditions of December 1997 to February 1998. For the summer 2000 study period, persistence in anomalous initial hydrologic states predominates in determining the hydrologic forecasts. In contrast, the El Niño-condition hydrologic forecasts derive direction both from the climate model forecast signal and the antecedent land surface state. From a qualitative standpoint the hydrologic forecasting strategy appears successful in translating climate forecast signals to hydrologic variables of interest for water management. Copyright 2002 by the American Geophysical Union.},
	number = {20},
	journal = {Journal of Geophysical Research: Atmospheres},
	author = {Wood, Andrew W. and Maurer, Edwin P. and Kumar, Arun and Lettenmaier, Dennis P.},
	year = {2002},
	note = {Publisher: Blackwell Publishing Ltd},
	keywords = {1833 Hydrology: Hydroclimatology, 1836 Hydrology: Hydrologic budget (1655), 1860 Hydrology: Runoff and streamflow, 1863 Hydrology: Snow and ice (1827), Climate downscaling, Eastern United States, Hydrologic forecast, Seasonal forecast, Streamflow forecast},
	pages = {ACL 6--1--ACL 6--15},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/ACM3KXVE/Journal of Geophysical Research  Atmospheres - 2002 - Wood - Long‐range experimental hydrologic forecasting for the eastern.pdf:application/pdf},
}

@article{amengual_statistical_2012,
	title = {A statistical adjustment of regional climate model outputs to local scales: {Application} to {Platja} de {Palma}, {Spain}},
	volume = {25},
	issn = {08948755},
	doi = {10.1175/JCLI-D-10-05024.1},
	abstract = {Projections of climate change effects for the System of Platja de Palma (SPdP) are derived using a novel statistical technique. Socioeconomic activities developed in this settlement are very closely linked to its climate. Any planning for socioeconomic opportunities in the mid- and long term must take into account the possible effects of climate change. To this aim, daily observed series of minimum and maximum temperatures, precipitation, relative humidity, cloud cover, and wind speed have been analyzed. For the climate projections, daily data generated by an ensemble of regional climate models (RCMs) have been used. To properly use RCM data at local scale, a quantile-quantile adjustment has been applied to the simulated regional projections. The method is based on detecting changes in the cumulative distribution functions between the recent past and successive time slices of the simulated climate and applying these, after calibration, to the recent past (observed) series. Results show an overall improvement in reproducing the present climate baseline when using calibrated series instead of raw RCM outputs, although the correction does not result in such clear improvement when dealing with very extreme rainfalls. Next, the corrected series are analyzed to quantify the climate change signal. Anincrease of the annual means for temperatures together with a decrease for the remaining variables is projected throughout the twenty-first century. Increases in weak and intense daily rainfalls and in high extremes for daily maximum temperature can also be expected. With this information at hand, the experts planning the future of SPdP can respond more effectively to the problem of local adaptation to climate change. © 2012 American Meteorological Society.},
	number = {3},
	journal = {Journal of Climate},
	author = {Amengual, A. and Homar, V. and Romero, R. and Alonso, S. and Ramis, C.},
	month = feb,
	year = {2012},
	keywords = {Climate change, Climatology, Europe, Mediterranean Sea, Societal impacts},
	pages = {939--957},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/5N2IW3ZM/1520-0442-jcli-d-10-05024.1.pdf:application/pdf},
}

@inproceedings{casati_2020_2022,
	title = {The 2020 {International} {Verification} {Methods} {Workshop} {Online}: {Major} {Outcomes} and {Way} {Forward}},
	volume = {103},
	doi = {10.1175/BAMS-D-21-0126.1},
	abstract = {The International Verification Methods Workshop was held online in November 2020 and included sessions on physical error characterization using process diagnostics and error tracking techniques; exploitation of data assimilation techniques in verification practices, e.g., to address representativeness issues and observation uncertainty; spatial verification methods and the Model Evaluation Tools, as unified reference verification software; and meta-verification and best practices for scores computation. The workshop reached out to diverse research communities working in the areas of high-impact weather, subseasonal to seasonal prediction, polar prediction, and sea ice and ocean prediction. This article summarizes the major outcomes of the workshop and outlines future strategic directions for verification research.},
	booktitle = {Bulletin of the {American} {Meteorological} {Society}},
	publisher = {American Meteorological Society},
	author = {Casati, Barbara and Dorninger, Manfred and Coelho, Caio A.S. and Ebert, Elizabeth E. and Marsigli, Chiara and Mittermaier, Marion P. and Gilleland, Eric},
	month = mar,
	year = {2022},
	note = {Issue: 3
ISSN: 15200477},
	keywords = {Forecast verification/skill},
	pages = {E899--E910},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/Y5HTSLGM/1520-0477-BAMS-D-21-0126.1.pdf:application/pdf},
}

@article{noauthor_fundamentals_of_numerical_weather_prediction_----_2_weather_prediction_equations_nodate,
	title = {Fundamentals\_of\_Numerical\_Weather\_Prediction\_----\_(2\_Weather\_prediction\_equations)},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/HEVMJNCH/Fundamentals_of_Numerical_Weather_Prediction_----_(2_Weather_prediction_equations).pdf:application/pdf},
}

@article{woodhams_identifying_2019,
	title = {Identifying key controls on storm formation over the lake {Victoria} basin},
	volume = {147},
	issn = {15200493},
	doi = {10.1175/MWR-D-19-0069.1},
	abstract = {The Lake Victoria region in East Africa is a hot spot for intense convective storms that are responsible forthe deaths of thousands of fishermen each year. The processes responsible for the initiation, development, andpropagation of the storms are poorly understood and forecast skill is limited. Key processes for the life cycle oftwo storms are investigated using Met Office Unified Model convection-permitting simulations with 1.5 kmhorizontal grid spacing. The two cases are analyzed alongside a simulation of a period with no storms to assessthe roles of the lake-land breeze, downslope mountain winds, prevailing large-scale winds, and moistureavailability. While seasonal changes in large-scale moisture availability play a key role in storm development,the lake-land-breeze circulation is a major control on the initiation location, timing, and propagation ofconvection. In the dry season, opposing offshore winds form a bulge of moist air above the lake surfaceovernight that extends from the surface to;1.5 km and may trigger storms in high CAPE/low CIN environments. Such a feature has not been explicitly observed or modeled in previous literature. Storms over landon the preceding day are shown to alter the local atmospheric moisture and circulation to promote stormformation over the lake. The variety of initiation processes and differing characteristics of just two stormsanalyzed here show that the mean diurnal cycle over Lake Victoria alone is inadequate to fully understandstorm formation. Knowledge of daily changes in local-scale moisture variability and circulations are keys forskillful forecasts over the lake.},
	number = {9},
	journal = {Monthly Weather Review},
	author = {Woodhams, Beth J. and Birch, Cathryn E. and Marsham, John H. and Lane, Todd P. and Bain, Caroline L. and Webster, Stuart},
	year = {2019},
	note = {Publisher: American Meteorological Society},
	keywords = {★},
	pages = {3365--3390},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/KIZCVXQD/1520-0493-mwr-d-19-0069.1.pdf:application/pdf},
}

@article{kastner_intercomparison_2006,
	title = {Intercomparison of satellite-based and model-based rainfall analyses},
	volume = {13},
	issn = {14698080},
	doi = {10.1017/S1350482706002246},
	abstract = {Four satellite rain estimations based on microwave (MW), infrared (IR) or combined MW-IR techniques are compared with the BOlogna Limited Area Model (BOLAM) rain forecast for a severe weather event (8-13 November 2001) over the western Mediterranean Sea. Two of the investigated multi-channel MW rainfall algorithms use data from the Tropical Rainfall Measuring Mission (TRMM). The Frequency Difference Algorithm relies on data from the TRMM Microwave Imager (TMI) and the other one combines data from the Precipitation Radar (PR) with those from the nine-channel radiometer TMI, called PR Adjusted TMI Estimations of Rainfall (PATER) algorithm. The pure IR Rain Estimator uses geostationary IR METEOSAT data and the combined Naval Research Laboratory algorithm uses both MW data from low orbiting satellites and IR data from the geostationary orbit. Validation results, computed over a common grid, which is independent of the different field of view sizes of the applied data sets, indicate that there is generally a better performance for heavy rain ({\textgreater} 6 mm h-1) than for light rain ({\textless}1 mm h-1). Both MW algorithms perform rather similarly, although PATER shows some rain detection problems due to thick aerosol loads originating from the desert. The BOLAM model presents a good agreement with the MW and only a minor location error of a heavy rain area was detected. Both IR-based algorithms have problems in identifying the correct rainy areas compared to MW. Overall, the results suggest that there are advantages in combining both techniques - the well-known rain physics of the MW channels with the high temporal resolution of IR algorithms - to retrieve precipitation from satellite data.},
	number = {3},
	journal = {Meteorological Applications},
	author = {Kästner, Martina and Torricella, Francesca and Davolio, Silvio},
	year = {2006},
	note = {Publisher: Cambridge University Press},
	keywords = {BOLAM, Mesoscale model, METEOSAT, Rain retrieval, Satellite},
	pages = {213--223},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/4K3DNY9F/intercomparison-of-satellite-based-and-model-based-rainfall-analyses.pdf:application/pdf},
}

@article{watson_does_2015,
	title = {Does the {ECMWF} {IFS} convection parameterization with stochastic physics correctly reproduce relationships between convection and the large-scale state?},
	volume = {72},
	issn = {15200469},
	doi = {10.1175/JAS-D-14-0252.1},
	abstract = {Important questions concerning parameterization of tropical convection are how should subgrid-scale variability be represented and which large-scale variables should be used in the parameterizations? Here the statistics of observational data in Darwin, Australia, are compared with those of short-term forecasts of convection made by the European Centre for Medium-Range Weather Forecasts Integrated Forecast System. The forecasts use multiplicative-noise stochastic physics (MNSP) that has led to many improvements in weather forecast skill. However, doubts have recently been raised about whether MNSP is consistent with observations of tropical convection. It is shown that the model can reproduce the variability of convection intensity for a given large-scale state, both with and without MNSP. Therefore MNSP is not inconsistent with observations, and much of the modeled variability arises from nonlinearity of the deterministic part of the convection scheme. It is also shown that the model can reproduce the lack of correlation between convection intensity and large-scale CAPE and an entraining CAPE, even though the convection parameterization assumes that deep convection is more intense when the vertical temperature profile is more unstable, with entrainment taken into account. Relationships between convection and large-scale convective inhibition and vertical velocity are also correctly captured.},
	number = {1},
	journal = {Journal of the Atmospheric Sciences},
	author = {Watson, Peter A.G. and Christensen, H. M. and Palmer, T. N.},
	year = {2015},
	note = {Publisher: American Meteorological Society},
	keywords = {Stochastic models, Convective clouds, Convective parameterization, Model evaluation/performance, Numerical weather prediction/forecasting},
	pages = {236--242},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/SENMATX8/1520-0469-jas-d-14-0252.1.pdf:application/pdf},
}

@article{wainwright_eastern_2019,
	title = {‘{Eastern} {African} {Paradox}’ rainfall decline due to shorter not less intense {Long} {Rains}},
	volume = {2},
	issn = {2397-3722},
	url = {https://www.nature.com/articles/s41612-019-0091-7},
	doi = {10.1038/s41612-019-0091-7},
	abstract = {{\textless}p{\textgreater}An observed decline in the Eastern African Long Rains from the 1980s to late 2000s appears contrary to the projected increase under future climate change. This “Eastern African climate paradox” confounds use of climate projections for adaptation planning across Eastern Africa. Here we show the decline corresponds to a later onset and earlier cessation of the long rains, with a similar seasonal maximum in area-averaged daily rainfall. Previous studies have explored the role of remote teleconnections, but those mechanisms do not sufficiently explain the decline or the newly identified change in seasonality. Using a large ensemble of observations, reanalyses and atmospheric simulations, we propose a regional mechanism that explains both the observed decline and the recent partial recovery. A decrease in surface pressure over Arabia and warmer north Arabian Sea is associated with enhanced southerlies and an earlier cessation of the long rains. This is supported by a similar signal in surface pressure in many atmosphere-only models giving lower May rainfall and an earlier cessation. Anomalously warm seas south of Eastern Africa delay the northward movement of the tropical rain-band, giving a later onset. These results are key in understanding the paradox. It is now a priority to establish the balance of mechanisms that have led to these trends, which are partially captured in atmosphere-only simulations.{\textless}/p{\textgreater}},
	number = {1},
	journal = {npj Climate and Atmospheric Science},
	author = {Wainwright, Caroline M. and Marsham, John H. and Keane, Richard J. and Rowell, David P. and Finney, Declan L. and Black, Emily and Allan, Richard P.},
	month = sep,
	year = {2019},
	note = {Publisher: Nature Research},
	pages = {34},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/GKLJH5MI/s41612-019-0091-7.pdf:application/pdf},
}

@inproceedings{karras_style-based_2019,
	title = {A {Style}-{Based} {Generator} {Architecture} for {Generative} {Adversarial} {Networks}},
	booktitle = {Proceedings of the {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Karras, Tero and Laine, Samuli and Aila, Timo},
	month = jun,
	year = {2019},
}

@inproceedings{brown_language_2020,
	title = {Language {Models} are {Few}-{Shot} {Learners}},
	url = {https://commoncrawl.org/the-data/},
	abstract = {We demonstrate that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even becoming competitive with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks. We also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora.},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and Mccandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	year = {2020},
	pages = {1877--1901},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/YIXFR5B8/NeurIPS-2020-language-models-are-few-shot-learners-Paper.pdf:application/pdf},
}

@article{ebert_toward_2009,
	title = {Toward better understanding of the contiguous rain area ({CRA}) method for spatial forecast verification},
	volume = {24},
	issn = {08828156},
	doi = {10.1175/2009WAF2222252.1},
	abstract = {The contiguous rain area (CRA) method for spatial forecast verification is a features-based approach that evaluates the properties of forecast rain systems, namely, their location, size, intensity, and finescale pattern. It is one of many recently developed spatial verification approaches that are being evaluated as part of a Spatial Forecast Verification Methods Intercomparison Project. To better understand the strengths and weaknesses of the CRA method, it has been tested here on a set of idealized geometric and perturbed forecasts with known errors, as well as nine precipitation forecasts from three high-resolution numerical weather prediction models. The CRA method was able to identify the known errors for the geometric forecasts, but only after a modification was introduced to allow nonoverlapping forecast and observed features to be matched. For the perturbed cases in which a radar rain field was spatially translated and amplified to simulate forecast errors, the CRA method also reproduced the known errors except when a high-intensity threshold was used to define the CRA (≫10 mm h21) and a large translation error was imposed ({\textgreater}200 km). The decomposition of total error into displacement, volume, and pattern components reflected the source of the error almost all of the time when a mean squared error formulation was used, but not necessarily when a correlation-based formulation was used. When applied to real forecasts, the CRA method gave similar results when either best-fit criteria, minimization of the mean squared error, or maximization of the correlation coefficient, was chosen for matching forecast and observed features. The diagnosed displacement error was somewhat sensitive to the choice of search distance. Of the many diagnostics produced by this method, the errors in the mean and peak rain rate between the forecast and observed features showed the best correspondence with subjective evaluations of the forecasts, while the spatial correlation coefficient (after matching) did not reflect the subjective judgments. © 2009 American Meteorological Society.},
	number = {5},
	journal = {Weather and Forecasting},
	author = {Ebert, Elizabeth E. and Gallus, William A.},
	month = oct,
	year = {2009},
	pages = {1401--1415},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/YC5DSBHK/1520-0434-2009waf2222252_1.pdf:application/pdf},
}

@article{ebert_verification_2000,
	title = {Verification of precipitation in weather systems: determination of systematic errors},
	volume = {239},
	issn = {00221694},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022169400003437},
	doi = {10.1016/S0022-1694(00)00343-7},
	abstract = {An object-oriented verification procedure is presented for gridded quantitative precipitation forecasts (QPFs). It is carried out within the framework of "contiguous rain areas" (CRAs), whereby a weather system is defined as a region bounded by a user-specified isopleth of precipitation in the union of the forecast and observed rain fields. The horizontal displacement of the forecast is determined by translating the forecast rain field until the total squared difference between the observed and forecast fields is minimized. This allows a decomposition of total error into components due to: (a) location; (b) rain volume and (c) pattern. Results are first presented for a Monte Carlo simulation of 40,000 synthetic CRAs in order to determine the accuracy of the verification procedure when the rain systems are only partially observed due to the presence of domain boundaries. Verification is then carried out for operational 24-h forecasts from the Australian Bureau of Meteorology LAPS numerical weather prediction model over a four-year period. Forty-five percent of all rain events were well forecast by the model, with small location and intensity errors. Location error was generally the dominant source of QPF error, with the directions of most frequent displacement varying by region. Forty-five percent of extreme rainfall events (100 mm d 1) were well forecast, but in this case the model's underestimation of rain intensity was the most frequent source of error.},
	number = {1-4},
	journal = {Journal of Hydrology},
	author = {Ebert, E.E and McBride, J.L},
	month = dec,
	year = {2000},
	keywords = {Precipitation, Australia, Rainfall, Storms},
	pages = {179--202},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/VS6MFTGG/1-s2.0-S0022169400003437-main.pdf:application/pdf},
}

@article{chen_application_2018-1,
	title = {Application of {Contiguous} {Rain} {Area} ({CRA}) {Methods} to {Tropical} {Cyclone} {Rainfall} {Forecast} {Verification}},
	volume = {5},
	issn = {23335084},
	doi = {10.1029/2018EA000412},
	abstract = {This study demonstrates the useful information that can be derived from contiguous rain area (CRA) evaluation, such as systematic errors in tropical cyclone (TC) rainfall location and components of rainfall error due to incorrect predictions of location, rain volume, and rain pattern. CRA verification uses pattern matching techniques to determine the location error, as well as errors in area, mean and maximum intensity, and spatial pattern. In this study, CRA verification was applied to evaluate Australian Community Climate and Earth System Simulator (ACCESS)-TC, the TC version of ACCESS, daily rainfall forecasts over 15 TCs in the north west Pacific ocean during 2012–2013, by comparing with Tropical Rainfall Measuring Mission (TRMM) 3B42 satellite estimates. The results showed that pattern error was the major contributor to the total TC rainfall forecast error, followed by volume and displacement. ACCESS-TC forecasts tended to predict more rainfall closer to the TC center compared to Tropical Rainfall Measuring Mission (TRMM) 3B42 estimates. This bias occurred for different CRA rainfall thresholds, verification grid resolutions and forecast lead times. Furthermore, rain event verification showed that for short lead time (24 hr) forecasts, overestimation of rain volume was a major problem for ACCESS-TC forecasts, while displacement error was more significant in longer lead time (72 hr) forecasts. Finally, we compared empirical probability distribution functions and radial probability distributions of rainfall in the forecasts and observations to further characterise the rain volume error. This confirmed that ACCESS-TC tended to produce more extreme rain in the locations closer to the TC center (eyewall).},
	number = {11},
	journal = {Earth and Space Science},
	author = {Chen, Yingjun and Ebert, Elizabeth E. and Davidson, Noel E. and Walsh, Kevin J.E.},
	month = nov,
	year = {2018},
	note = {Publisher: Wiley-Blackwell Publishing Ltd},
	keywords = {evaluation, precipitation, spatial verification, hurricane, model forecast, typhoon},
	pages = {736--752},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/DI74YZAI/Earth and Space Science - 2018 - Chen - Application of Contiguous Rain Area  CRA  Methods to Tropical Cyclone Rainfall.pdf:application/pdf},
}

@article{kelly_aspects_2007,
	title = {Some {Aspects} of {Measurement} {Error} in {Linear} {Regression} of {Astronomical} {Data}},
	url = {http://arxiv.org/abs/0705.2774},
	doi = {10.1086/519947},
	abstract = {I describe a Bayesian method to account for measurement errors in linear regression of astronomical data. The method allows for heteroscedastic and possibly correlated measurement errors, and intrinsic scatter in the regression relationship. The method is based on deriving a likelihood function for the measured data, and I focus on the case when the intrinsic distribution of the independent variables can be approximated using a mixture of Gaussians. I generalize the method to incorporate multiple independent variables, non-detections, and selection effects (e.g., Malmquist bias). A Gibbs sampler is described for simulating random draws from the probability distribution of the parameters, given the observed data. I use simulation to compare the method with other common estimators. The simulations illustrate that the Gaussian mixture model outperforms other common estimators and can effectively give constraints on the regression parameters, even when the measurement errors dominate the observed scatter, source detection fraction is low, or the intrinsic distribution of the independent variables is not a mixture of Gaussians. I conclude by using this method to fit the X-ray spectral slope as a function of Eddington ratio using a sample of 39 z {\textless} 0.8 radio-quiet quasars. I confirm the correlation seen by other authors between the radio-quiet quasar X-ray spectral slope and the Eddington ratio, where the X-ray spectral slope softens as the Eddington ratio increases.},
	author = {Kelly, Brandon C.},
	month = may,
	year = {2007},
	note = {arXiv: 0705.2774},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/267HWUIQ/0705.2774.pdf:application/pdf},
}

@techreport{grams_use_2006,
	title = {The {Use} of a {Modified} {Ebert}-{McBride} {Technique} to {Evaluate} {Mesoscale} {Model} {QPF} as a {Function} of {Convective} {System} {Morphology} during {IHOP} 2002},
	abstract = {The Ebert-McBride technique (EMT) is an entity-oriented method useful for quantitative precipitation verification. The EMT was modified to optimize its ability to identify contiguous rain areas (CRAs) during the 2002 International H 2 O Project (IHOP). This technique was then used to identify systematic sources of error as a function of observed convective system morphology in three 12-km model simulations run over the IHOP domain: Eta, the fifth-generation Pennsylvania State University-NCAR Mesoscale Model (MM5), and the Weather Research and Forecasting (WRF). The EMT was fine-tuned to optimize the pattern matching of forecasts to observations for the scales of precipitation systems observed during IHOP. To investigate several error measures provided by the EMT, a detailed morphological analysis of observed systems was performed using radar data for all CRAs identified in the IHOP domain. The modified EMT suggests that the Eta Model produced average rain rates, peak rainfall amounts, and total rain volumes that were lower than observed for almost all types of convective systems, likely because of its production of overly smoothed and low-variability quantitative precipitation forecasts. The MM5 and WRF typically produced average rain rates and peak rainfall amounts that were larger than observed in most linear convective systems. However, the rain volume for these models was too low for almost all types of con-vective systems, implying a sizeable underestimate in areal coverage. All three models forecast rainfall too far northwest for linear systems. The results for the WRF and MM5 are consistent with previous observations of mesoscale models run with explicit microphysics and no convective parameterization scheme, suggesting systematic problems with the prediction of mesoscale convective system cold pool dynamics.},
	author = {Grams, Jeremy S and Gallus, Willam A and Koch, Steven E and Wharton, Linda S and Loughe, Andrew and Ebert, Elizabeth E},
	year = {2006},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/66ESSMWC/1520-0434-waf918_1 (1).pdf:application/pdf},
}

@article{sharma_assessment_2019,
	title = {Assessment of {Met} {Office} {Unified} {Model} ({UM}) quantitative precipitation forecasts during the {Indian} summer monsoon: {Contiguous} {Rain} {Area} ({CRA}) approach},
	volume = {128},
	issn = {0973774X},
	doi = {10.1007/s12040-018-1023-3},
	abstract = {The operational medium range rainfall forecasts of the Met Office Unified Model (UM) are evaluated over India using the Contiguous Rainfall Area (CRA) verification technique. In the CRA method, forecast and observed weather systems (defined by a user-specified rain threshold) are objectively matched to estimate location, volume, and pattern errors. In this study, UM rainfall forecasts from nine (2007–2015) Indian monsoon seasons are evaluated against 0. 5 ∘× 0. 5 ∘ IMD–NCMRWF gridded observed rainfall over India (6. 5 ∘- 38. 5 ∘N , 66. 5 ∘- 100. 5 ∘E). The model forecasts show a wet bias due to excessive number of rainy days particularly of low amounts ({\textless}1mmd-1). Verification scores consistently suggest good skill the forecasts at threshold of 10mmd-1, while moderate (poor) skill at thresholds of {\textless}20mmd-1({\textless}40mmd-1). Spatial verification of rainfall forecasts is carried out for 10, 20, 40 and 80mmd-1 CRA thresholds for four sub-regions namely (i) northwest (NW), (ii) southwest (SW), (iii) eastern (E), and (iv) northeast (NE) sub-region. Over the SW sub-region, the forecasts tend to underestimate rain intensity. In the SW region, the forecast events tended to be displaced to the west and southwest of the observed position on an average by about 1 ∘ distance. Over eastern India (E) forecasts of light (heavy) rainfall events, like 10mmd-1 (20 and 40mmd-1) tend to be displaced to the south on an average by about 1 ∘ (southeast by 1 - 2 ∘). In all four regions, the relative contribution to total error due to displacement increases with increasing CRA threshold. These findings can be useful for forecasters and for model developers with regard to the model systematic errors associated with the monsoon rainfall over different parts of India.},
	number = {1},
	journal = {Journal of Earth System Science},
	author = {Sharma, Kuldeep and Ashrit, Raghavendra and Ebert, Elizabeth and Mitra, Ashis and Bhatla, R. and Iyengar, Gopal and Rajagopal, E. N.},
	month = feb,
	year = {2019},
	note = {Publisher: Springer},
	keywords = {CRA, forecast verification, NWP, Unified model},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/9RWN8P8Q/s12040-018-1023-3.pdf:application/pdf},
}

@article{tian_performance_2016,
	title = {Performance metrics, error modeling, and uncertainty quantification},
	volume = {144},
	issn = {15200493},
	doi = {10.1175/MWR-D-15-0087.1},
	abstract = {A common set of statisticalmetrics has been used to summarize the performance of models or measurements- the most widely used ones being bias, mean square error, and linear correlation coefficient. They assume linear, additive, Gaussian errors, and they are interdependent, incomplete, and incapable of directly quantifying uncertainty. The authors demonstrate that these metrics can be directly derived from the parameters of the simple linear errormodel. Since a correct errormodel captures the full error information, it is argued that the specification of a parametric error model should be an alternative to the metrics-based approach. The error-modeling methodology is applicable to both linear and nonlinear errors, while themetrics are onlymeaningful for linear errors. In addition, the error model expresses the error structure more naturally, and directly quantifies uncertainty. This argument is further explained by highlighting the intrinsic connections between the performance metrics, the error model, and the joint distribution between the data and the reference.},
	number = {2},
	journal = {Monthly Weather Review},
	author = {Tian, Yudong and Nearing, Grey S. and Peters-Lidard, Christa D. and Harrison, Kenneth W. and Tang, Ling},
	year = {2016},
	note = {Publisher: American Meteorological Society},
	pages = {607--613},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/Z8HLG6VC/1520-0493-mwr-d-15-0087.1.pdf:application/pdf},
}

@article{livadiotis_fitting_2013,
	title = {Fitting method based on correlation maximization: {Applications} in space physics},
	volume = {118},
	issn = {21699402},
	doi = {10.1002/jgra.50304},
	abstract = {We develop a new fitting method based on the maximization of the correlation between two curves or sets of discreet observations. We show that this correlation maximization fitting method is mathematically well defined under certain conditions. The key element is the sensitivity of the method - a measure of how localized the correlation maximum is. The most important advantage of the method is that it can be applied to disparate data sets that are expected to be correlated but not fitted to each other. The method is valuable in the analysis of space data sets from (1) physically remote sources that may have complicated and hidden causal linkages or (2) physically distinguished quantities that are reasonably connected. The derived possible relations can be examined by testing the correlation between their observational signals or other measurements. Finally, we examine data of density and temperature in the inner heliosheath, inferred from Interstellar Boundary Explorer observations, and show that the globally distributed flux of energetic neutral atoms represents a source plasma under isobaric thermodynamic processes. Key Points Development of the maximum correlation method of 2 sets of discreet observations A systematic way for applying the new method. We provide some examples. We explain why the method can be useful in space physics and geophysics. ©2013. American Geophysical Union. All Rights Reserved.},
	number = {6},
	journal = {Journal of Geophysical Research: Space Physics},
	author = {Livadiotis, G. and McComas, D. J.},
	month = jun,
	year = {2013},
	note = {Publisher: Blackwell Publishing Ltd},
	keywords = {Correlation, Space data analysis},
	pages = {2863--2875},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/RNEYP3KL/JGR Space Physics - 2013 - Livadiotis - Fitting method based on correlation maximization  Applications in space physics.pdf:application/pdf},
}

@article{jankov_partition_2021-1,
	title = {Partition of {Forecast} {Error} into {Positional} and {Structural} {Components}},
	volume = {38},
	issn = {18619533},
	doi = {10.1007/s00376-021-0251-7},
	abstract = {Weather manifests in spatiotemporally coherent structures. Weather forecasts hence are affected by both positional and structural or amplitude errors. This has been long recognized by practicing forecasters (cf., e.g., Tropical Cyclone track and intensity errors). Despite the emergence in recent decades of various objective methods for the diagnosis of positional forecast errors, most routine verification or statistical post-processing methods implicitly assume that forecasts have no positional error. The Forecast Error Decomposition (FED) method proposed in this study uses the Field Alignment technique which aligns a gridded forecast with its verifying analysis field. The total error is then partitioned into three orthogonal components: (a) large scale positional, (b) large scale structural, and (c) small scale error variance. The use of FED is demonstrated over a month-long MSLP data set. As expected, positional errors are often characterized by dipole patterns related to the displacement of features, while structural errors appear with single extrema, indicative of magnitude problems. The most important result of this study is that over the test period, more than 50\% of the total mean sea level pressure forecast error variance is associated with large scale positional error. The importance of positional error in forecasts of other variables and over different time periods remain to be explored.},
	number = {6},
	journal = {Advances in Atmospheric Sciences},
	author = {Jankov, Isidora and Gregory, Scott and Ravela, Sai and Toth, Zoltan and Peña, Malaquías},
	month = jun,
	year = {2021},
	note = {Publisher: Science Press},
	keywords = {forecast error, orthogonal decomposition, positional, structural},
	pages = {1012--1019},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/EYHGXRZV/s00376-021-0251-7.pdf:application/pdf},
}

@article{keil_displacement-based_2007-1,
	title = {A displacement-based error measure applied in a regional ensemble forecasting system},
	volume = {135},
	issn = {00270644},
	doi = {10.1175/MWR3457.1},
	abstract = {Errors in regional forecasts often take the form of phase errors, where a forecasted weather system is displaced in space or time. For such errors, a direct measure of the displacement is likely to be more valuable than traditional measures. A novel forecast quality measure is proposed that is based on a comparison of observed and forecast satellite imagery from the Meteosat-7 geostationary satellite. The measure combines the magnitude of a displacement vector calculated with a pyramid matching algorithm and the local squared difference of observed and morphed forecast brightness temperature fields. Following the description of the method and its application for a simplified case, the measure is applied to regional ensemble forecasts for an episode of prefrontal summertime convection in Bavaria. It is shown that this new method provides a plausible measure of forecast error, which is consistent with a subjective ranking of ensemble members for a sample forecast. The measure is then applied to hourly images over a 36-h forecast period and compared with the bias and equitable threat score. The two conventional measures fail to provide any systematic distinction between different ensemble members, while the new measure identifies ensemble members of differing skill levels with a strong degree of temporal consistency. Using the displacement-based error measure, individual ensemble members are found to compare better with observations than either a short-term deterministic forecast or the ensemble mean throughout the convective period. © 2007 American Meteorological Society.},
	number = {9},
	journal = {Monthly Weather Review},
	author = {Keil, Christian and Craig, George C.},
	month = sep,
	year = {2007},
	pages = {3248--3259},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/W3877N52/1520-0493-mwr3457.1.pdf:application/pdf},
}

@article{gilleland_intercomparison_2009,
	title = {Intercomparison of spatial forecast verification methods},
	volume = {24},
	issn = {08828156},
	doi = {10.1175/2009WAF2222269.1},
	abstract = {Advancements in weather forecast models and their enhanced resolution have led to substantially improved and more realistic-appearing forecasts for some variables. However, traditional verification scores often indicate poor performance because of the increased small-scale variability so that the true quality of the forecasts is not always characterized well. As a result, numerous new methods for verifying these forecasts have been proposed. These new methods can mostly be classified into two overall categories: filtering methods and displacement methods. The filtering methods can be further delineated into neighborhood and scale separation, and the displacement methods can be divided into features based and field deformation. Each method gives considerably more information than the traditional scores, but it is not clear which method(s) should be used for which purpose. Averificationmethods intercomparison project has been established in order to glean a better understanding of the proposed methods in terms of their various characteristics and to determine what verification questions each method addresses. The study is ongoing, and preliminary qualitative results for the different approaches applied to different situations are described here. In particular, the various methods and their basic characteristics, similarities, and differences are described. In addition, several questions are addressed regarding the application of the methods and the information that they provide. These questions include (i) how the method(s) informperformance at different scales; (ii) how the methods provide information on location errors; (iii) whether the methods provide information on intensity errors and distributions; (iv) whether the methods provide information on structure errors; (v) whether the approaches have the ability to provide information about hits, misses, and false alarms; (vi) whether the methods do anything that is counterintuitive; (vii) whether the methods have selectable parameters and how sensitive the results are to parameter selection; (viii) whether the results can be easily aggregated across multiple cases; (ix) whether the methods can identify timing errors; and (x) whether confidence intervals and hypothesis tests can be readily computed. © 2009 American Meteorological Society.},
	number = {5},
	journal = {Weather and Forecasting},
	author = {Gilleland, Eric and Ahijevych, David and Brown, Barbara G. and Casati, Barbara and Ebert, Elizabeth E.},
	month = oct,
	year = {2009},
	pages = {1416--1430},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/2BLWTZHG/1520-0434-2009waf2222269_1.pdf:application/pdf},
}

@techreport{gladney_computer-assisted_1969,
	title = {Computer-{Assisted} {Gas}-{Liquid} {Chromatography}},
	url = {https://pubs.acs.org/sharingguidelines},
	abstract = {RESULTS The reciprocal time computer was tested by applying voltage signals of known input slopes to the voltage interval sensor (Figure 1) to simulate outputs of typical reaction monitor-signal modifier systems. T able I shows the results of measurements of input rates from 5 mV/sec to 20 V/sec. The instrument was calibrated with a 50 mV/sec input rate by adjusting Pi (Figure 3) to give the desired readout. This adjustment is necessary because of component tolerances in the linear sweep generator. The entire range of input rates shown in Table I was measured with only one instrument change. For rates {\textgreater} 1 V/sec, the scaling factor F and integrator input voltage Ein were changed by factors of ten. At the highest rate measured, the actual time interval (At) was 5 msec. With this short At, the time interval to voltage converter output was only 5 mV. Faster rates could be measured by increasing Ein. However, the analog gates used to switch Ein (Figure 3) are only capable of switching up to 5 V. Table II shows results for the determination of phosphate. For this procedure, the input voltage to the reciprocal time computer had a negative slope, and the NAND gates shown in Figure 2 were used. With the 100\% transmittance set at 1.000 V, recorded curves enabled the selection of V{\textbackslash} and AV. Vi was set at 0.975 volt and AV was adjusted to be 25 mV. Because of the slowness of the reaction, Etn was reduced to 50 mV to avoid limiting OAi. Potentiometer Pi (Figure 3) was adjusted to give a direct concentration readout using a phosphate standard of 5 ppm P. At the lowest concentration used, the measurement time At was about 120 sec. The results shown in Tables I and II are typical of many which have been obtained. The reciprocal time computer was constructed using the same digital modules as used in the fixed time readout system described earlier (2). By a simple change of circuit cards and intercard connections, the same basic modules can be used for both variable time and fixed time methods. This allows the user of reaction rate methods to have both automated readout systems readily available for use with different reactions. The use of computers for data acquisition and analysis in gas-liquid chromatography is becoming increasingly widespread. We describe an implementation of computer-assisted chromatography within a general-purpose time-shared laboratory automation system. Particular attention is paid to a method of avoiding timing conflicts at the computer, to an inexpensive method of providing a computer-to-instrument interface , and to an economical method of curve-fitting to resolve overlapping skewed peaks. It is anticipated that many of the methods and some of the computer programs will be directly applicable to various spec-troscopic experiments. The recent implementation in this laboratory of a time-shared laboratory automation system for spectroscopic-type instruments (I) has made possible on-line data collection and computation for a high-sensitivity gas chromatograph. We wish to describe our system which includes two novel features: a simple and inexpensive interface for time-shared communications between an instrument and a remote computer, and a method for the resolution of overlapping skewed peaks, involving a least-squares curve fitting procedure. In Figure 1 is shown a simple calculated curve compared with the observed chromatogram. In general, the methods used to schedule the communications between a process-control computer and several instruments are largely selected by considerations of economy and of the relative requirements of the instruments being connected. The choice of method becomes particularly difficult if the full requirements of the laboratory cannot be anticipated which is usually the case. It is also conceded that an extremely desirable, if not absolutely necessary, feature be that each experiment can be programmed and run inde-(1). M. Gladney, J. Comp. Physics, 2, 255 (1968). Figure 1. A poorly resolved chromatogram of 30-60 °C petroleum ether showing computer fitted peaks pendently. From the point of view of the experiment and experimenter, it is perhaps conceptually simpler if the computer is enslaved to the laboratory instrument. However, at the computer, this arrangement implies not one master, but several, usually with conflicting requirements. There are at least three possible resolutions of the problem: To dedicate a computer or a sub-computer (commonly called a data channel) either permanently or temporarily to each experiment (2). To employ a computer which is so fast relative to the time-sensitive experiments that the unavoidable inter-(2) T.},
	author = {Gladney, M and Dowden, B F and Swalen, J D and Lusebrink, R and Sederholm, C H},
	year = {1969},
	note = {Volume: 13
Issue: 7},
	pages = {65},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/JBLQGX62/ac60276a013.pdf:application/pdf},
}

@techreport{grushka_characterization_1970,
	title = {Characterization of {Exponentially} {Modified} {Gaussian} {Peaks} in {Chromatography} {MOMENT} {ANALYSIS} {The} moments, {Mn}, of {Equation} 1 can be found by employ-ing the {Laplace} (or the {Fourier}) transformation. {Use} is being},
	url = {https://pubs.acs.org/sharingguidelines},
	abstract = {The exponentially modified Gaussian peak has attracted attention recently in computer deconvolution of chromatographic peaks. This peak shape model has some theoretical justification. In this paper, we investigate the behavior of the skew and excess and of the second derivative of that shape in order to examine their utility in the analysis of strongly overlapped chromatographic peaks. The study showed that, indeed, moment as well as slope analysis can be beneficial in characterizing double peaks. In addition, moment analysis of a single peak can indicate the magnitude of extra-column effects. If the time constant of these effects is known, slope analysis might be preferred because of its simplicity, to moment analysis. The problem of strongly overlapped chromatographic peaks can be dealt with by employing statistical moments or slope analysis (1, 2). In the former (/), deviations in the peak shape, as obtained from the skew and excess, between a single peak and a double peak in the form of a single band are used as the indicator of a strongly overlapped system. In the latter (2), deviation in the second derivative behavior, when manipulated appropriately, ascertains the existence of double peaks. In discussing these two methods, the mathematical models which were described were developed mainly because of their computational ease. Although the models were realistic, they were chosen arbitrarily (except for the "kinetic tailing" model). A better theoretical model for the chro-matographic peak shape is thus needed. Exponentially modified Gaussian peaks, that is to say, a Gaussian convoluted with an exponential decay function, seem to fill that need. More than a decade ago, Schmauch (J) as well as Johnson and Stross (4) recognized that instrumental contribution, such as detector dead volume, will modify exponentially the chromatographic peak. Esser (5), in investigating spectrophotometric detectors, reached the same conclusion. Sternberg, in his comprehensive review on extra-column effects (6), shows that various dead volume contributions alter the peak exponentially. He indicates that each particular extra-column effect has a certain time constant associated with it. The magnitude of this time constant determines the extent to which the peak is distorted. More recently, Gladney et al. (7) used the exponentially modified Gaussian in numerical deconvolution techniques. They have shown that experimental peaks can be described reasonably well by this model. The same shape was used by Littlewood and coworkers (8) in their deconvolution method. In addition they have briefly investigated the effect of mixing chambers and have concluded that these affect the skewness of the peak. Me William and Bolton (9) derived the exponentially convoluted Gaussian in their discussion on instrumental peak distortion, and its effect on the resolution. More recently (10) they used this peak model in further discussion on the area recovery of two partially overlapped peaks. With this interest in exponentially modified Gaussians, it seems useful to investigate the theoretical behavior of two strongly overlapped (i.e., resolution {\textgreater}0.5) such peaks. This is particularly so since this peak model has some theoretical and experimental (7,8) justification. The exponentially modified Gaussian peak is defined by the following convolute integral. m = ray/2ir J0 Or, alternatively /(0-{\textasciicircum}exp (t-tB-t'f-' exp 2 1 2 exp T () {\textbackslash}-(2) where Z = [(/-tB)¡a-/ ]1/ /2 in Equation 2, A is the peak amplitude, is the variance of the Gaussian, tR is the center of gravity of the Gaussian, r is the time constant of the exponential modifier (which can be attributed, among others, to extra column contribution) and t' and x are dummy variables of integration. Some of the properties of these expressions were discussed by Gladney et al. (7) and by McWil-liam and Bolton (9). It should be noted that the area of this convolution expression is equal to that of a pure Gaussian and that the maximum of the peak always falls on the Gaussian which is being modified (9). Moreover, the asymmetry of the peak depends on the ratio /. Representative examples of peaks with various / values can be found elsewhere (7-9). Before proceeding to investigate, theoretically, the behavior of the skew and excess, as well as that of the second derivative, of a single and double convoluted peaks, some comments should be made concerning some practical aspects of these analyses. The experimental methodology of obtaining the moments or the derivatives was already discussed by us (1, 2). The experimental accuracies reported are well within the reach of many laboratories, especially when calibration curves are used as standards.},
	author = {Grushka, E and Monecelli, G M and Schmauch, Ibid ; ) L J and Esser, . ; R J E and Sternberg, ; ) J C},
	year = {1970},
	note = {Publication Title: Advances in Chromatography
Volume: 42
Issue: 2},
	pages = {883},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/PFZW7ELR/ac60319a011.pdf:application/pdf},
}

@techreport{grushka_characterization_1970-1,
	title = {Characterization of {Exponentially} {Modified} {Gaussian} {Peaks} in {Chromatography} {MOMENT} {ANALYSIS} {The} moments, {Mn}, of {Equation} 1 can be found by employ-ing the {Laplace} (or the {Fourier}) transformation. {Use} is being},
	url = {https://pubs.acs.org/sharingguidelines},
	abstract = {The exponentially modified Gaussian peak has attracted attention recently in computer deconvolution of chromatographic peaks. This peak shape model has some theoretical justification. In this paper, we investigate the behavior of the skew and excess and of the second derivative of that shape in order to examine their utility in the analysis of strongly overlapped chromatographic peaks. The study showed that, indeed, moment as well as slope analysis can be beneficial in characterizing double peaks. In addition, moment analysis of a single peak can indicate the magnitude of extra-column effects. If the time constant of these effects is known, slope analysis might be preferred because of its simplicity, to moment analysis. The problem of strongly overlapped chromatographic peaks can be dealt with by employing statistical moments or slope analysis (1, 2). In the former (/), deviations in the peak shape, as obtained from the skew and excess, between a single peak and a double peak in the form of a single band are used as the indicator of a strongly overlapped system. In the latter (2), deviation in the second derivative behavior, when manipulated appropriately, ascertains the existence of double peaks. In discussing these two methods, the mathematical models which were described were developed mainly because of their computational ease. Although the models were realistic, they were chosen arbitrarily (except for the "kinetic tailing" model). A better theoretical model for the chro-matographic peak shape is thus needed. Exponentially modified Gaussian peaks, that is to say, a Gaussian convoluted with an exponential decay function, seem to fill that need. More than a decade ago, Schmauch (J) as well as Johnson and Stross (4) recognized that instrumental contribution, such as detector dead volume, will modify exponentially the chromatographic peak. Esser (5), in investigating spectrophotometric detectors, reached the same conclusion. Sternberg, in his comprehensive review on extra-column effects (6), shows that various dead volume contributions alter the peak exponentially. He indicates that each particular extra-column effect has a certain time constant associated with it. The magnitude of this time constant determines the extent to which the peak is distorted. More recently, Gladney et al. (7) used the exponentially modified Gaussian in numerical deconvolution techniques. They have shown that experimental peaks can be described reasonably well by this model. The same shape was used by Littlewood and coworkers (8) in their deconvolution method. In addition they have briefly investigated the effect of mixing chambers and have concluded that these affect the skewness of the peak. Me William and Bolton (9) derived the exponentially convoluted Gaussian in their discussion on instrumental peak distortion, and its effect on the resolution. More recently (10) they used this peak model in further discussion on the area recovery of two partially overlapped peaks. With this interest in exponentially modified Gaussians, it seems useful to investigate the theoretical behavior of two strongly overlapped (i.e., resolution {\textgreater}0.5) such peaks. This is particularly so since this peak model has some theoretical and experimental (7,8) justification. The exponentially modified Gaussian peak is defined by the following convolute integral. m = ray/2ir J0 Or, alternatively /(0-{\textasciicircum}exp (t-tB-t'f-' exp 2 1 2 exp T () {\textbackslash}-(2) where Z = [(/-tB)¡a-/ ]1/ /2 in Equation 2, A is the peak amplitude, is the variance of the Gaussian, tR is the center of gravity of the Gaussian, r is the time constant of the exponential modifier (which can be attributed, among others, to extra column contribution) and t' and x are dummy variables of integration. Some of the properties of these expressions were discussed by Gladney et al. (7) and by McWil-liam and Bolton (9). It should be noted that the area of this convolution expression is equal to that of a pure Gaussian and that the maximum of the peak always falls on the Gaussian which is being modified (9). Moreover, the asymmetry of the peak depends on the ratio /. Representative examples of peaks with various / values can be found elsewhere (7-9). Before proceeding to investigate, theoretically, the behavior of the skew and excess, as well as that of the second derivative, of a single and double convoluted peaks, some comments should be made concerning some practical aspects of these analyses. The experimental methodology of obtaining the moments or the derivatives was already discussed by us (1, 2). The experimental accuracies reported are well within the reach of many laboratories, especially when calibration curves are used as standards.},
	author = {Grushka, E and Monecelli, G M and Schmauch, Ibid ; ) L J and Esser, . ; R J E and Sternberg, ; ) J C},
	year = {1970},
	note = {Publication Title: Advances in Chromatography
Volume: 42
Issue: 2},
	pages = {883},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/7YECHL9D/ac60319a011 (1).pdf:application/pdf},
}

@article{hao_exponential_2016,
	title = {Exponential decay of spatial correlation in driven diffusive system: {A} universal feature of macroscopic homogeneous state},
	volume = {6},
	issn = {20452322},
	doi = {10.1038/srep19652},
	abstract = {Driven diffusive systems have been a paradigm for modelling many physical, chemical, and biological transport processes. In the systems, spatial correlation plays an important role in the emergence of a variety of nonequilibrium phenomena and exhibits rich features such as pronounced oscillations. However, the lack of analytical results of spatial correlation precludes us from fully understanding the effect of spatial correlation on the dynamics of the system. Here we offer precise analytical predictions of the spatial correlation in a typical driven diffusive system, namely facilitated asymmetric exclusion process. We find theoretically that the correlation between two sites decays exponentially as their distance increases, which is in good agreement with numerical simulations. Furthermore, we find the exponential decay is a universal property of macroscopic homogeneous state in a broad class of 1D driven diffusive systems. Our findings deepen the understanding of many nonequilibrium phenomena resulting from spatial correlation in driven diffusive systems.},
	journal = {Scientific Reports},
	author = {Hao, Qing Yi and Jiang, Rui and Hu, Mao Bin and Jia, Bin and Wang, Wen Xu},
	month = jan,
	year = {2016},
	note = {Publisher: Nature Publishing Group},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/RJ5Y4MNB/srep19652.pdf:application/pdf},
}

@article{hoffman_distortion_1995,
	title = {Distortion {Representation} of {Forecast} {Errors}},
	volume = {123},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/10.1175/1520-0493(1995)123<2758:DROFE>2.0.CO;2},
	doi = {10.1175/1520-0493(1995)123<2758:DROFE>2.0.CO;2},
	number = {9},
	journal = {Monthly Weather Review},
	author = {Hoffman, Ross N. and Liu, Zheng and Louis, Jean-Francois and Grassoti, Christopher},
	month = sep,
	year = {1995},
	pages = {2758--2770},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/3QB8EUWI/1520-0493-1520-0493_1995_123_2758_drofe_2_0_co_2.pdf:application/pdf},
}

@article{nachamkin_mesoscale_2004,
	title = {Mesoscale {Verification} {Using} {Meteorological} {Composites}},
	volume = {132},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/10.1175/1520-0493(2004)132<0941:MVUMC>2.0.CO;2},
	doi = {10.1175/1520-0493(2004)132<0941:MVUMC>2.0.CO;2},
	abstract = {Mesoscale models are often used to explicitly predict discrete, highly structured phenomena. Information regarding the ability of the model to predict events as coherent entities is thus a useful statement of performance. Observational constraints are a significant problem, though, as the shape, size, and intensity of any given event are often only partially known. Composite techniques offer an attractive approach because the full deterministic information about any one event need not be known. If enough quasi-random observations of a distribution of events exist, bulk properties of the distributions of forecasts and observations can be estimated. Composites are also useful in that the verification measures are based on conditional samples of events. Sample distributions contingent on event existence in either the forecasts or the observations can be compared to one another. A verification technique in which meteorological events are located and composited on a relative grid centered on each event is described herein. This technique is described and demonstrated by comparing the 27-km Naval Research Laboratory's Coupled Ocean/Atmosphere Mesoscale Prediction System (COAMPS) mistral wind forecasts to the Special Sensor Microwave Imager (SSM/I) observations for a 1-yr period. Diagnostic information regarding the forecast reliability, error type, and error spatial characteristics are derived. Also, statistics from the conditional distributions of both the observed and predicted events are compared. The difference between the two conditional biases (CBD) is found to reveal valuable information regarding the contribution of false alarms and missed forecasts to the forecast errors. The results indicate the mistral is remarkably predictable with high pattern correlations out to 66 h.},
	number = {4},
	journal = {Monthly Weather Review},
	author = {Nachamkin, Jason E.},
	month = apr,
	year = {2004},
	pages = {941--955},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/29RBWIFU/1520-0493-1520-0493_2004_132_0941_mvumc_2.0.co_2.pdf:application/pdf},
}

@article{skok_new_2022,
	title = {A {New} {Spatial} {Distance} {Metric} for {Verification} of {Precipitation}},
	volume = {12},
	issn = {20763417},
	doi = {10.3390/app12084048},
	abstract = {Precipitation is an essential meteorological variable affecting the biosphere and human societies. At the same time, precipitation is notoriously difficult to predict and verify. A new spatial distance metric for verification of precipitation is presented. It is called the Precipitation Smoothing Distance (PSD). The aim was to develop a measure that would provide a good and meaningful approximation of the displacement of precipitation events in the two fields. An estimate of spatial displacement is very appealing for forecast interpretation because it is easy to understand and mimics how humans tend to judge fields by eye. Contrary to most other distance metrics, the new metric does not require thresholding and can thus be used to analyze binary and non-binary fields (e.g., continuous or multi-level). The analysis of idealized situations showed that the new metric provides a meaningful approximation of the displacement. Typically the estimate of displacement provided by PSD was better than the results provided by most other metrics. The measure is also not overly sensitive to noise, its results are directly related to the actual displacements of precipitation events, and the events with a larger magnitude have a bigger influence on the resulting value. The analysis of ECMWF precipitation forecasts over Europe and North Africa confirmed that the new metric provides a meaningful approximation of the.},
	number = {8},
	journal = {Applied Sciences (Switzerland)},
	author = {Skok, Gregor},
	month = apr,
	year = {2022},
	note = {Publisher: MDPI},
	keywords = {precipitation, PSD metric, spatial displacement, verification},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/IC57F2E3/A_New_Spatial_Distance_Metric_for_Verification_of_ (1).pdf:application/pdf},
}

@incollection{wilks_forecast_2019,
	title = {Forecast {Verification}},
	booktitle = {Statistical {Methods} in the {Atmospheric} {Sciences}},
	publisher = {Elsevier},
	author = {Wilks, Daniel S.},
	year = {2019},
	doi = {10.1016/b978-0-12-815823-4.00009-2},
	pages = {369--483},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/ISZIERKX/3-s2.0-B9780128158234000092-main.pdf:application/pdf},
}

@article{casati_new_2004,
	title = {A new intensity-scale approach for the verification of spatial precipitation forecasts},
	volume = {11},
	issn = {13504827},
	doi = {10.1017/S1350482704001239},
	abstract = {A new intensity-scale method for verifying spatial precipitation forecasts is introduced. The technique provides a way of evaluating the forecast skill as a function of precipitation rate intensity and spatial scale of the error. Six selected case studies of the UK Met Office now-casting system NIMROD are used to illustrate the method. The forecasts are assessed using the Mean Squared Error (MSE) skill score of binary images, obtained from the forecasts and analyses by thresholding at different precipitation rate intensities. The skill score is decomposed on different spatial scales using a two-dimensional discrete Haar wavelet decomposition of binary error images. The forecast skill can then be evaluated in terms of precipitation rate intensity and spatial scale. The technique reveals that loss of forecast skill in NIMROD is predominantly due to small spatial scale ({\textless} 40 km) errors of more intense events. The technique is capable of isolating specific intensity-scale errors for individual cases. As an example, in one of the case studies the displacement error of an incorrectly advected storm is well detected by a minimum negative skill score occurring at the 160 km spatial scale for thresholds between 1/2 and 4 mm/h.},
	number = {2},
	journal = {Meteorological Applications},
	author = {Casati, B. and Ross, G. and Stephenson, D. B.},
	year = {2004},
	note = {Publisher: Cambridge University Press},
	pages = {141--154},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/VRLAWNBV/Meteorological Applications - 2006 - Casati - A new intensity‐scale approach for the verification of spatial precipitation.pdf:application/pdf},
}

@article{mishra_sharma_resdeepd_2022,
	title = {{ResDeepD}: {A} residual super-resolution network for deep downscaling of daily precipitation over {India}},
	volume = {1},
	issn = {2634-4602},
	url = {https://www.cambridge.org/core/product/identifier/S2634460222000231/type/journal_article},
	doi = {10.1017/eds.2022.23},
	abstract = {{\textless}p{\textgreater} In the twenty-first century, machine learning and deep learning have been successfully used to find hidden information from coarse-grained data in various domains. In Computer Vision, scientists have used neural networks to identify hidden pixel-level information from low-resolution (LR) image data. This approach of estimating high-resolution (HR) information from LR data is called the super-resolution (SR) approach. This approach has been borrowed by climate scientists to downscale coarse-level measurements of climate variables to obtain their local-scale projections. Climate variables are spatial in nature and can be represented as images where each pixel denotes a grid point where the variables can be measured. We can apply the deep learning-based SR techniques on such “images” for statistical downscaling of such variables. This approach of downscaling can be termed as deep downscaling. In this work, we have tried to make HR projection of the Indian summer monsoon rainfall by using a novel deep residual network called ResDeepD. The aim is to downscale the 1 $^{\textrm{0}}$ × 1 $^{\textrm{0}}$ low LR precipitation data to get the values at 0.25 $^{\textrm{0}}$ × 0.25 $^{\textrm{0}}$ resolution. The proposed model uses a series of skip connections across residual blocks to give better results as compared to the existing models like super-resolution convolutional neural network, DeepSD, and Nest-UNet that have been used previously for this task. We have also examined the model’s performance for downscaling rainfall during some extreme climatic events like cyclonic storms and deep depression and found that the model performs better than the existing models. {\textless}/p{\textgreater}},
	journal = {Environmental Data Science},
	author = {Mishra Sharma, Sumanta Chandra and Mitra, Adway},
	month = nov,
	year = {2022},
	keywords = {★},
	pages = {e19},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/WCJP9FTL/11e1f3fbdd953f305c312c6d6bd5b24d2080.pdf:application/pdf},
}

@article{sha_deep-learning-based_2020,
	title = {Deep-learning-based gridded downscaling of surface meteorological variables in complex terrain. {Part} {II}: {Daily} precipitation},
	volume = {59},
	issn = {15588432},
	doi = {10.1175/JAMC-D-20-0058.1},
	abstract = {Statistical downscaling (SD) derives localized information from larger-scale numerical models. Convolutional neural networks (CNNs) have learning and generalization abilities that can enhance the downscaling of gridded data (Part I of this study experimented with 2-m temperature). In this research, we adapt a semantic-segmentation CNN, called UNet, to the downscaling of daily precipitation in western North America, from the low resolution (LR) of 0.25° to the high resolution (HR) of 4-km grid spacings. We select LR precipitation, HR precipitation climatology, and elevation as inputs; train UNet over the subset of the south-and central-western United States using Parameter–Elevation Regressions on Independent Slopes Model (PRISM) data from 2015 to 2018, and test it independently in all available domains from 2018 to 2019. We proposed an improved version of UNet, which we call Nest-UNet, by adding deep-layer aggregation and nested skip connections. Both the original UNet and Nest-UNet show generalization ability across different regions and outperform the SD baseline (bias-correction spatial disag-gregation), with lower downscaling error and more accurate fine-grained textures. Nest-UNet also shares the highest amount of information with station observations and PRISM, indicating good ability to reduce the uncertainty of HR downscaling targets.},
	number = {12},
	journal = {Journal of Applied Meteorology and Climatology},
	author = {Sha, Yingkai and Gagne, David John and West, Gregory and Stull, Roland},
	month = dec,
	year = {2020},
	note = {Publisher: American Meteorological Society},
	keywords = {Model output statistics, Model evaluation/performance, Deep learning, Error analysis, Interpolation schemes, Neural networks},
	pages = {2075--2092},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/JDMNWB35/1558-8432-jamc-d-20-0058.1.pdf:application/pdf},
}

@incollection{maraun_model_2017,
	title = {Model {Output} {Statistics}},
	abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-α-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 Å for the interface backbone atoms) increased from 21\% with default Glide SP settings to 58\% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63\% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40\% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
	booktitle = {Statistical {Downscaling} and {Bias} {Correction} for {Climate} {Research}},
	publisher = {Cambridge University Press},
	author = {Maraun, Douglas and Widmann, Martin},
	month = dec,
	year = {2017},
	doi = {10.1017/9781107588783.013},
	pages = {170--200},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/RL9LWSIM/model-output-statistics.pdf:application/pdf},
}

@article{maraun_value_2015,
	title = {{VALUE}: {A} framework to validate downscaling approaches for climate change studies},
	volume = {3},
	issn = {23284277},
	doi = {10.1002/2014EF000259},
	abstract = {VALUE is an open European network to validate and compare downscaling methods for climate change research. VALUE aims to foster collaboration and knowledge exchange between climatologists, impact modellers, statisticians, and stakeholders to establish an interdisciplinary downscaling community. A key deliverable of VALUE is the development of a systematic validation framework to enable the assessment and comparison of both dynamical and statistical downscaling methods. In this paper, we present the key ingredients of this framework. VALUE's main approach to validation is user- focused: starting from a specific user problem, a validation tree guides the selection of relevant validation indices and performance measures. Several experiments have been designed to isolate specific points in the downscaling procedure where problems may occur: what is the isolated downscaling skill? How do statistical and dynamical methods compare? How do methods perform at different spatial scales? Do methods fail in representing regional climate change? How is the overall representation of regional climate, including errors inherited from global climate models? The framework will be the basis for a comprehensive community-open downscaling intercomparison study, but is intended also to provide general guidance for other validation studies.},
	number = {1},
	journal = {Earth's Future},
	author = {Maraun, Douglas and Widmann, Martin and Gutiérrez, José M. and Kotlarski, Sven and Chandler, Richard E. and Hertig, Elke and Wibig, Joanna and Huth, Radan and Wilcke, Renate A.I.},
	month = jan,
	year = {2015},
	note = {Publisher: John Wiley and Sons Inc},
	keywords = {Bias Correction, Downscaling, Dynamical Downscaling, Regional Climate Modelling, Statistical Downscaling, Validation},
	pages = {1--14},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/F8AUARYV/Earth s Future - 2014 - Maraun - VALUE  A framework to validate downscaling approaches for climate change studies.pdf:application/pdf},
}

@article{lloyd_quantum_2020,
	title = {Quantum algorithm for nonlinear differential equations},
	url = {http://arxiv.org/abs/2011.06571},
	abstract = {Quantum computers are known to provide an exponential advantage over classical computers for the solution of linear differential equations in high-dimensional spaces. Here, we present a quantum algorithm for the solution of nonlinear differential equations. The quantum algorithm provides an exponential advantage over classical algorithms for solving nonlinear differential equations. Potential applications include the Navier-Stokes equation, plasma hydrodynamics, epidemiology, and more.},
	author = {Lloyd, Seth and De Palma, Giacomo and Gokler, Can and Kiani, Bobak and Liu, Zi-Wen and Marvian, Milad and Tennie, Felix and Palmer, Tim},
	month = nov,
	year = {2020},
	note = {arXiv: 2011.06571},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/6JY5LIZ5/2011.06571.pdf:application/pdf},
}

@article{espeholt_deep_2022,
	title = {Deep learning for twelve hour precipitation forecasts},
	volume = {13},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-022-32483-x},
	doi = {10.1038/s41467-022-32483-x},
	abstract = {{\textless}p{\textgreater}Existing weather forecasting models are based on physics and use supercomputers to evolve the atmosphere into the future. Better physics-based forecasts require improved atmospheric models, which can be difficult to discover and develop, or increasing the resolution underlying the simulation, which can be computationally prohibitive. An emerging class of weather models based on neural networks overcome these limitations by learning the required transformations from data instead of relying on hand-coded physics and by running efficiently in parallel. Here we present a neural network capable of predicting precipitation at a high resolution up to 12 h ahead. The model predicts raw precipitation targets and outperforms for up to 12 h of lead time state-of-the-art physics-based models currently operating in the Continental United States. The results represent a substantial step towards validating the new class of neural weather models.{\textless}/p{\textgreater}},
	number = {1},
	journal = {Nature Communications},
	author = {Espeholt, Lasse and Agrawal, Shreya and Sønderby, Casper and Kumar, Manoj and Heek, Jonathan and Bromberg, Carla and Gazen, Cenk and Carver, Rob and Andrychowicz, Marcin and Hickey, Jason and Bell, Aaron and Kalchbrenner, Nal},
	month = sep,
	year = {2022},
	pages = {5145},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/JNYYJAAQ/s41467-022-32483-x.pdf:application/pdf},
}

@article{rasp_data-driven_2020,
	title = {Data-driven medium-range weather prediction with a {Resnet} pretrained on climate simulations: {A} new model for {WeatherBench}},
	url = {http://arxiv.org/abs/2008.08626},
	doi = {10.1029/2020MS002405},
	abstract = {Numerical weather prediction has traditionally been based on physical models of the atmosphere. Recently, however, the rise of deep learning has created increased interest in purely data-driven medium-range weather forecasting with first studies exploring the feasibility of such an approach. To accelerate progress in this area, the WeatherBench benchmark challenge was defined. Here, we train a deep residual convolutional neural network (Resnet) to predict geopotential, temperature and precipitation at 5.625 degree resolution up to 5 days ahead. To avoid overfitting and improve forecast skill, we pretrain the model using historical climate model output before fine-tuning on reanalysis data. The resulting forecasts outperform previous submissions to WeatherBench and are comparable in skill to a physical baseline at similar resolution. We also analyze how the neural network creates its predictions and find that, with some exceptions, it is compatible with physical reasoning. Finally, we perform scaling experiments to estimate the potential skill of data-driven approaches at higher resolutions.},
	author = {Rasp, Stephan and Thuerey, Nils},
	month = aug,
	year = {2020},
	note = {arXiv: 2008.08626},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/T92I9ZMT/2008.08626.pdf:application/pdf},
}

@article{espeholt_skillful_2021,
	title = {Skillful {Twelve} {Hour} {Precipitation} {Forecasts} using {Large} {Context} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2111.07470},
	abstract = {The problem of forecasting weather has been scientifically studied for centuries due to its high impact on human lives, transportation, food production and energy management, among others. Current operational forecasting models are based on physics and use supercomputers to simulate the atmosphere to make forecasts hours and days in advance. Better physics-based forecasts require improvements in the models themselves, which can be a substantial scientific challenge, as well as improvements in the underlying resolution, which can be computationally prohibitive. An emerging class of weather models based on neural networks represents a paradigm shift in weather forecasting: the models learn the required transformations from data instead of relying on hand-coded physics and are computationally efficient. For neural models, however, each additional hour of lead time poses a substantial challenge as it requires capturing ever larger spatial contexts and increases the uncertainty of the prediction. In this work, we present a neural network that is capable of large-scale precipitation forecasting up to twelve hours ahead and, starting from the same atmospheric state, the model achieves greater skill than the state-of-the-art physics-based models HRRR and HREF that currently operate in the Continental United States. Interpretability analyses reinforce the observation that the model learns to emulate advanced physics principles. These results represent a substantial step towards establishing a new paradigm of efficient forecasting with neural networks.},
	author = {Espeholt, Lasse and Agrawal, Shreya and Sønderby, Casper and Kumar, Manoj and Heek, Jonathan and Bromberg, Carla and Gazen, Cenk and Hickey, Jason and Bell, Aaron and Kalchbrenner, Nal},
	month = nov,
	year = {2021},
	note = {arXiv: 2111.07470},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/DJQ33EW4/2111.07470.pdf:application/pdf},
}

@techreport{wang_incorporating_nodate,
	title = {{INCORPORATING} {SYMMETRY} {INTO} {DEEP} {DYNAMICS} {MODELS} {FOR} {IMPROVED} {GENERALIZATION}},
	url = {https://github.com/Rose-STL-Lab/Equivariant-Net.},
	abstract = {Recent work has shown deep learning can accelerate the prediction of physical dynamics relative to numerical solvers. However, limited physical accuracy and an inability to generalize under distributional shift limits its applicability to the real world. We propose to improve accuracy and generalization by incorporating symmetries into convolutional neural networks. Specifically, we employ a variety of methods each tailored to enforce a different symmetry. Our models are both theoretically and experimentally robust to distributional shift by symmetry group transformations and enjoy favorable sample complexity. We demonstrate the advantage of our approach on a variety of physical dynamics including Rayleigh-Bénard convection and real-world ocean currents and temperatures. Compared with image or text applications, our work is a significant step towards applying equivariant neural networks to high-dimensional systems with complex dynamics. We open-source our simulation, data and code at https://github.com/Rose-STL-Lab/Equivariant-Net.},
	author = {Wang, Rui and Walters, Robin and Yu, Rose},
	keywords = {★},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/X63II4NS/1278_incorporating_symmetry_into_de.pdf:application/pdf},
}

@article{pasaric_comments_2011,
	title = {Comments on "{Applying} a general analytic method for assessing bias sensitivity to bias-adjusted threat and equitable threat scores"},
	volume = {26},
	issn = {08828156},
	doi = {10.1175/2010WAF2222453.1},
	number = {1},
	journal = {Weather and Forecasting},
	author = {Pasarić, Zoran and Juras, Josip},
	month = feb,
	year = {2011},
	keywords = {Bias, ★, Forecast verification, Error analysis, Statistics},
	pages = {122--125},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/668YH7P9/1520-0434-2010waf2222453_1.pdf:application/pdf},
}

@techreport{ling_conditioned_nodate,
	title = {Conditioned {Spatial} {Downscaling} of {Climate} {Variables}},
	url = {https://github.com/evbecker/climate-spatial-downscaling},
	abstract = {Global Climate Models (GCM) play a vital role in assessing the large-scale impacts of climate change. Downscaling methods can translate coarse-resolution climate information from GCM to high-resolution predictions to forecast regional effects. Unfortunately, current downscaling methods struggle to fully take into account spatial relationships among variables, especially at long distances. In this work, we propose an instance-conditional pixel synthesis generative adversarial network (ICPS-GAN), wherein conditioning on spatial information is an explicit way of providing the GAN with previous high-resolution and current low-resolution data, resulting in an enhancement of the general performance. Experimental results on precipitation forecast for US region data outperform both traditional and other learning-based methods when extrapolating in space. The code is available at https://github.com/evbecker/climate-spatial-downscaling},
	author = {Ling, Alex and Hung, Yu and Becker, Evan and Zadouri, Ted and Grover, Aditya},
	keywords = {★},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/2662D76E/104_conditioned_spatial_downscalin.pdf:application/pdf},
}

@inproceedings{roberts_assessing_2008,
	title = {Assessing the spatial and temporal variation in the skill of precipitation forecasts from an {NWP} model},
	volume = {15},
	doi = {10.1002/met.57},
	abstract = {It is becoming increasingly important to be able to verify the spatial accuracy of precipitation forecasts, especially with the advent of high-resolution numerical weather prediction (NWP) models. In this article, the fractions skill score (FSS) approach has been used to perform a scale-selective evaluation of precipitation forecasts during 2003 from the Met Office mesoscale model (12 km grid length). The investigation shows how skill varies with spatial scale, the scales over which the data assimilation (DA) adds most skill, and how the loss of that skill is dependent on both the spatial scale and the rainfall coverage being examined. Although these results come from a specific model, they demonstrate how this verification approach can provide a quantitative assessment of the spatial behaviour of new finer-resolution models and DA techniques. Copyright © 2008 Royal Meteorological Society.},
	booktitle = {Meteorological {Applications}},
	publisher = {John Wiley and Sons Ltd},
	author = {Roberts, Nigel},
	year = {2008},
	note = {Issue: 1
ISSN: 14698080},
	keywords = {Precipitation, Verification, Forecasts, Scale-selective},
	pages = {163--169},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/CWDSBIPA/Meteorological Applications - 2008 - Roberts - Assessing the spatial and temporal variation in the skill of precipitation.pdf:application/pdf},
}

@techreport{sawyer_department_nodate,
	title = {{DEPARTMENT} {OF} {COMMERCE} {WEATHER} {BUREAU} {MONTHLY} {WEATHER} {REVIEW} {VERIFICATION} {OF} {FORECASTS} {EXPRESSED} {IN} {TERMS} {OF} {PROBABILITY}},
	author = {Sawyer, Charles and Reichelderfer, F W and Editor, James E and Caskey, J R and Brie, Glenn W},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/8QQ2ZD9F/1520-0493-1520-0493_1950_078_0001_vofeit_2_0_co_2.pdf:application/pdf},
}

@techreport{noauthor_approximations_nodate,
	title = {Approximations for {Mean} and {Variance} of a {Ratio}},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/EYSSCZTP/ratio.pdf:application/pdf},
}

@article{orskaug_evaluation_2011,
	title = {Evaluation of a dynamic downscaling of precipitation over the {Norwegian} mainland},
	issn = {0280-6495},
	doi = {10.3402/tellusa.v63i4.15859},
	abstract = {In order to assess the potential of regional climate models to be used to project future weather events, a first step is to study the regional model forced by actual weather, or more precisely by reanalysis of weather data. In this paper we investigate how well the Norwegian regional model HIRHAM, forced by ERA-40 reanalysis data, compares to observed precipitation data from the Norwegian Meteorological Institute over Norwegian mainland. This paper aims to show how standard methods of statistical testing may be used to assess dynamic downscaling. Methods considered are the Kolmogorov-Smirnov two-sample test, a Fisher exact test for equality of quantiles, an Extreme Value Theory test, where equality of the 1-yr return levels are tested, and equality of wet-day frequency. All tests are performed seasonally. The regional model is skillful in describing the lower quartile of the precipitation distribution, but underestimates higher levels of precipitation. Our results indicate that the regional model has too many but too small rain events for all seasons.},
	journal = {Tellus A},
	author = {Orskaug, E. and Scheel, I. and Frigessi, A. and Guttorp, P. and Haugen, J. E. and Tveito, O. E. and Haug, O.},
	month = aug,
	year = {2011},
	note = {Publisher: Stockholm University Press},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/5V53TZX5/Evaluation_of_a_dynamic_downscaling_of_precipitati.pdf:application/pdf},
}

@techreport{hamill_hypothesis_1999,
	title = {Hypothesis {Tests} for {Evaluating} {Numerical} {Precipitation} {Forecasts}},
	abstract = {When evaluating differences between competing precipitation forecasts, formal hypothesis testing is rarely performed. This may be due to the difficulty in applying common tests given the spatial correlation of and non-normality of errors. Possible ways around these difficulties are explored here. Two datasets of precipitation forecasts are evaluated, a set of two competing gridded precipitation forecasts from operational weather prediction models and sets of competing probabilistic quantitative precipitation forecasts from model output statistics and from an ensemble of forecasts. For each test, data from each competing forecast are collected into one sample for each case day to avoid problems with spatial correlation. Next, several possible hypothesis test methods are evaluated: the paired t test, the nonparametric Wilcoxon signed-rank test, and two resampling tests. The more involved resampling test methodology is the most appropriate when testing threat scores from nonprobabilistic forecasts. The simpler paired t test or Wilcoxon test is appropriate to use in testing the skill of probabilistic forecasts evaluated with the ranked probability score.},
	author = {Hamill, Thomas M},
	year = {1999},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/66IJU46Y/1520-0434-1520-0434_1999_014_0155_htfenp_2_0_co_2.pdf:application/pdf},
}

@techreport{hinkley_ratio_1969,
	title = {On the {Ratio} of {Two} {Correlated} {Normal} {Random} {Variables}},
	url = {https://www.jstor.org/stable/2334671},
	author = {Hinkley, D V},
	year = {1969},
	note = {Volume: 56
Issue: 3},
	pages = {635--639},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/VXEYGYBT/2334671.pdf:application/pdf},
}

@article{north_assessment_2013,
	title = {An assessment of the {SEEPS} and {SEDI} metrics for the verification of 6h forecast precipitation accumulations},
	volume = {20},
	issn = {14698080},
	doi = {10.1002/met.1405},
	abstract = {An evaluation of the performance of the Stable Equitable Error in Probability Space (SEEPS) and the Symmetric Extremal Dependence Index (SEDI) as monitoring metrics for 6h precipitation forecasts from regional NWP is presented. These scores provide complementary assessments of forecast performance. SEEPS quantifies general performance in the prediction of dry weather and precipitation amount. SEDI focuses on higher threshold events. By using the climatological distribution of precipitation at each location to define thresholds, both scores assess the locally important aspects of the forecast. Both scores can also be aggregated over climatologically diverse regions to obtain an area-mean performance measure. From the perspective of forecast system development, an important aspect of both scores is their resistance to hedging. Each score is calculated for forecasts coming from two model systems, one a 12km regional configuration of the Met Office Unified Model (MetUM), the other is the independent European Centre for Medium-range Weather Forecasts (ECMWF) global model; here interpolated to a 25km grid. Results suggest that SEEPS can be meaningfully applied to 6h accumulations. Diurnal variations in SEEPS highlight timing errors in the development of convection. A decomposition in the contributions to SEEPS highlights the over-prediction of drizzle near midday, and difficulties to predict convection during the evening. SEDI results suggest that performance trends in 90\% percentile events are detectable over a 3year period. However, results do suggest that higher model resolution improves the skill and frequency bias for higher percentile events. © 2013 Royal Meteorological Society and British Crown copyright, the Met Office.},
	number = {2},
	journal = {Meteorological Applications},
	author = {North, Rachel and Trueman, Matthew and Mittermaier, Marion and Rodwell, Mark J.},
	year = {2013},
	note = {Publisher: John Wiley and Sons Ltd},
	keywords = {★, Precipitation verification, SEDI, SEEPS},
	pages = {164--175},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/MQVTVG5K/Meteorological Applications - 2013 - North - An assessment of the SEEPS and SEDI metrics for the verification of 6 h.pdf:application/pdf},
}

@techreport{rodwell_new_2010,
	title = {A {New} {Equitable} {Score} {Suitable} for {Verifying} {Precipitation} in {NWP}},
	url = {http://www.ecmwf.int/publications/},
	abstract = {A new equitable score is developed for monitoring precipitation forecasts and for guiding forecast system development. To accommodate the difficult distribution of precipitation, the score measures error in 'prob-ability space' through use of the climatological cumulative distribution function. For sufficiently skillful forecasting systems, the new score is less sensitive to sampling uncertainty than other established scores. It is therefore called here 'Stable Equitable Error in Probability Space' (SEEPS). Weather is partitioned into three categories: 'dry', 'light precipitation' and 'heavy precipitation'. SEEPS adapts to the climate of the region in question so that it assesses the salient aspects of the local weather, encouraging 'refinement' and 'discrimination' and discouraging 'hedging'. To permit continuous monitoring of a system whose resolution is increasing with time, forecasts are verified against point observations. With some careful choices, observation error and lack of representativeness of model grid-box averages are found to have minimal impact. SEEPS can identify key forecasting errors including the over-prediction of drizzle, failure to predict heavy large-scale precipitation, and incorrectly locating convective cells. Area-averages are calculated taking into account the observation density, so that all sub-regions are treated more equally. A gain of ∼2 days, at lead-times 3-9 days, over the last 14 years is found in extratropical scores of forecasts made at the European Centre for Medium-range Weather Forecasts (ECMWF). This gain is due to system improvements, not the increased amount of data assimilated. SEEPS may also be applicable for verifying other quantities that suffer from difficult spatio-temporal distributions.},
	author = {Rodwell, M J and Richardson, D S and Hewson, T D},
	year = {2010},
	note = {Publication Title: Press in Quart. J. Roy. Meteorol. Soc},
	keywords = {★},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/LDKZJH4Z/11988-new-equitable-score-suitable-verifying-precipitation-nwp.pdf:application/pdf},
}

@article{gandin_equitable_nodate,
	title = {Equitable {Skill} {Scores} for {Categorical} {Forecasts}},
	author = {Gandin, Lev and Murphy, Allan},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/4D5U5NET/1520-0493-1520-0493_1992_120_0361_essfcf_2_0_co_2.pdf:application/pdf},
}

@techreport{singh_short-range_2005,
	title = {Short-range forecasts of global precipitation using deep learning-augmented numerical weather prediction},
	abstract = {Precipitation drives the hydroclimate of Earth and its spatiotemporal changes on a day to day basis have one of the most notable socioeconomic impacts. The success of numerical weather prediction (NWP) is measured by the improvement of forecasts for various physical fields such as temperature and pressure. Large biases however exist in the precipitation predictions. Pure deep learning based approaches lack the advancements acheived by NWP in the past two to three decades. Hybrid methodology using NWP outputs as inputs to the deep learning based refinement tool offer an attractive means taking advantage of both NWP and state of the art deep learning algorithms. Augmenting the output from a well-known NWP model: Coupled Forecast System ver.2 (CFSv2) with deep learning for the first time, we demonstrate a hybrid model capability (DeepNWP) which shows substantial skill improvements for short-range global precipitation at 1-, 2-and 3-days lead time. To achieve this hybridization, we address the sphericity of the global data by using modified DLWP-CS architecture which transforms all the fields to cubed-sphere projection. The dynamical model outputs corresponding to precipitation and surface temperature are ingested to a UNET for predicting the target ground truth precipitation. While the dynamical model CFSv2 shows Tackling Climate Change with Machine Learning: workshop at NeurIPS 2022. a bias in the range of +5 to +7 mm/day over land, the multivariate deep learning model reduces it to-1 to +1 mm/day over global land areas. We validate the results by taking examples from},
	author = {Singh, Manmeet and Sb, Vaisakh and Acharya, Nachiketa and Grover, Aditya and Rao, Suryachandra A and Kumar, Bipin and Yang, Zong-Liang and Niyogi, Dev},
	year = {2005},
	keywords = {★},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/ZXHHE2VB/paper (1).pdf:application/pdf},
}

@techreport{singh_short-range_2005-1,
	title = {Short-range forecasts of global precipitation using deep learning-augmented numerical weather prediction},
	abstract = {Precipitation drives the hydroclimate of Earth and its spatiotemporal changes on a day to day basis have one of the most notable socioeconomic impacts. The success of numerical weather prediction (NWP) is measured by the improvement of forecasts for various physical fields such as temperature and pressure. Large biases however exist in the precipitation predictions. Pure deep learning based approaches lack the advancements acheived by NWP in the past two to three decades. Hybrid methodology using NWP outputs as inputs to the deep learning based refinement tool offer an attractive means taking advantage of both NWP and state of the art deep learning algorithms. Augmenting the output from a well-known NWP model: Coupled Forecast System ver.2 (CFSv2) with deep learning for the first time, we demonstrate a hybrid model capability (DeepNWP) which shows substantial skill improvements for short-range global precipitation at 1-, 2-and 3-days lead time. To achieve this hybridization, we address the sphericity of the global data by using modified DLWP-CS architecture which transforms all the fields to cubed-sphere projection. The dynamical model outputs corresponding to precipitation and surface temperature are ingested to a UNET for predicting the target ground truth precipitation. While the dynamical model CFSv2 shows Tackling Climate Change with Machine Learning: workshop at NeurIPS 2022. a bias in the range of +5 to +7 mm/day over land, the multivariate deep learning model reduces it to-1 to +1 mm/day over global land areas. We validate the results by taking examples from},
	author = {Singh, Manmeet and Sb, Vaisakh and Acharya, Nachiketa and Grover, Aditya and Rao, Suryachandra A and Kumar, Bipin and Yang, Zong-Liang and Niyogi, Dev},
	year = {2005},
	keywords = {★},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/VK4AMNB6/paper (3).pdf:application/pdf},
}

@techreport{graubner_calibration_nodate,
	title = {Calibration of {Large} {Neural} {Weather} {Models}},
	abstract = {Uncertainty quantification of weather forecasts is a necessity for reliably planning for and responding to extreme weather events in a warming world. This motivates the need for well-calibrated ensembles in probabilistic weather forecasting. We present initial results for the calibration of large-scale deep neural weather models for data-driven probabilistic weather forecasting. By explicitly accounting for uncertainties about the forecast's initial condition and model parameters, we generate ensemble forecasts that show promising results on standard diagnostics for probabilistic forecasts. Specifically, we are approaching the Integrated Forecasting System (IFS), the gold standard on probabilistic weather forecasting, on: (i) the spread-error agreement; and (ii) the Continuous Ranked Probability Score (CRPS). Our approach scales to state-of-the-art data-driven weather models, enabling cheap post-hoc calibration of pretrained models with tens of millions of parameters and paving the way towards the next generation of well-calibrated data-driven weather models.},
	author = {Graubner, Andre and Azizzadenesheli, Kamyar and Pathak, Jaideep and Mardani, Morteza and Pritchard, Mike and Kashinath, Karthik},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/CRSV96VQ/paper (4).pdf:application/pdf},
}

@article{dagon_machine_2022,
	title = {Machine {Learning}‐{Based} {Detection} of {Weather} {Fronts} and {Associated} {Extreme} {Precipitation} in {Historical} and {Future} {Climates}},
	volume = {127},
	issn = {2169-897X},
	doi = {10.1029/2022jd037038},
	abstract = {Abstract Extreme precipitation events, including those associated with weather fronts, have wide-ranging impacts across the world. Here we use a deep learning algorithm to identify weather fronts in high resolution Community Earth System Model (CESM) simulations over the contiguous United States (CONUS), and evaluate the results using observational and reanalysis products. We further compare results between CESM simulations using present-day and future climate forcing, to study how these features might change with climate change. We find that detected front frequencies in CESM have seasonally varying spatial patterns and responses to climate change and are found to be associated with modeled changes in large scale circulation such as the jet stream. We also associate the detected fronts with precipitation and find that total and extreme frontal precipitation mostly decreases with climate change, with some seasonal and regional differences. Decreases in Northern Hemisphere summer frontal precipitation are largely driven by changes in the frequency of different front types, especially cold and stationary fronts. On the other hand, Northern Hemisphere winter exhibits some regional increases in frontal precipitation that are largely driven by changes in frontal precipitation intensity. While CONUS mean and extreme precipitation generally increase during all seasons in these climate change simulations, the likelihood of frontal extreme precipitation decreases, demonstrating that extreme precipitation has seasonally varying sources and mechanisms that will continue to evolve with climate change.},
	number = {21},
	journal = {Journal of Geophysical Research: Atmospheres},
	author = {Dagon, Katherine and Truesdale, John and Biard, James C. and Kunkel, Kenneth E. and Meehl, Gerald A. and Molina, Maria J.},
	month = nov,
	year = {2022},
	note = {Publisher: American Geophysical Union (AGU)},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/DIK63GER/JGR Atmospheres - 2022 - Dagon - Machine Learning‐Based Detection of Weather Fronts and Associated Extreme Precipitation in.pdf:application/pdf},
}

@techreport{ioffe_batch_nodate,
	title = {Batch {Normalization}: {Accelerating} {Deep} {Network} {Training} by {Reducing} {Internal} {Covariate} {Shift}},
	abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making nor-malization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a state-of-the-art image classification model, Batch Nor-malization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82\% top-5 test error, exceeding the accuracy of human raters.},
	author = {Ioffe, Sergey and Szegedy, Christian},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/63HXEPGR/ioffe15.pdf:application/pdf},
}

@article{kilavi_extreme_2018,
	title = {Extreme rainfall and flooding over {Central} {Kenya} {Including} {Nairobi} {City} during the long-rains season 2018: {Causes}, predictability, and potential for early warning and actions},
	volume = {9},
	issn = {20734433},
	doi = {10.3390/atmos9120472},
	abstract = {The Long-Rains wet season of March-May (MAM) over Kenya in 2018 was one of the wettest on record. This paper examines the nature, causes, impacts, and predictability of the rainfall events, and considers the implications for flood risk management. The exceptionally high monthly rainfall totals in March and April resulted from several multi-day heavy rainfall episodes, rather than from distinct extreme daily events. Three intra-seasonal rainfall events in particular resulted in extensive flooding with the loss of lives and livelihoods, a significant displacement of people, major disruption to essential services, and damage to infrastructure. The rainfall events appear to be associated with the combined effects of active Madden-Julian Oscillation (MJO) events in MJO phases 2-4, and at shorter timescales, tropical cyclone events over the southwest Indian Ocean. These combine to drive an anomalous westerly low-level circulation over Kenya and the surrounding region, which likely leads to moisture convergence and enhanced convection. We assessed how predictable such events over a range of forecast lead times. Long-lead seasonal forecast products for MAM 2018 showed little indication of an enhanced likelihood of heavy rain over most of Kenya, which is consistent with the low predictability of MAM Long-Rains at seasonal lead times. At shorter lead times of a few weeks, the seasonal and extended-range forecasts provided a clear signal of extreme rainfall, which is likely associated with skill in MJO prediction. Short lead weather forecasts from multiple models also highlighted enhanced risk. The flood response actions during the MAM 2018 events are reviewed. Implications of our results for forecasting and flood preparedness systems include: (i) Potential exists for the integration of sub-seasonal and short-term weather prediction to support flood risk management and preparedness action in Kenya, notwithstanding the particular challenge of forecasting at small scales. (ii) We suggest that forecasting agencies provide greater clarity on the difference in potentially useful forecast lead times between the two wet seasons in Kenya and East Africa. For the MAM Long-Rains, the utility of sub-seasonal to short-term forecasts should be emphasized; while at seasonal timescales, skill is currently low, and there is the challenge of exploiting new research identifying the primary drivers of variability. In contrast, greater seasonal predictability of the Short-Rains in the October-December season means that greater potential exists for early warning and preparedness over longer lead times. (iii) There is a need for well-developed and functional forecast-based action systems for heavy rain and flood risk management in Kenya, especially with the relatively short windows for anticipatory action during MAM.},
	number = {12},
	journal = {Atmosphere},
	author = {Kilavi, Mary and MacLeod, Dave and Ambani, Maurine and Robbins, Joanne and Dankers, Rutger and Graham, Richard and Helen, Titley and Salih, Abubakr A.M. and Todd, Martin C.},
	month = nov,
	year = {2018},
	note = {Publisher: MDPI AG},
	keywords = {Predictability, East Africa, Extreme rainfall, Flood, Forecast based action, Forecasting, Kenya, Long-Rains, MJO, S2S, Seasonal sub-seasonal variability},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/LDPW7XXU/atmosphere-09-00472-v2.pdf:application/pdf},
}

@techreport{yik_exploring_nodate,
	title = {Exploring {Randomly} {Wired} {Neural} {Networks} for {Climate} {Model} {Emulation}},
	abstract = {Exploring the climate impacts of various anthropogenic emissions scenarios is key to making informed decisions for climate change mitigation and adaptation. State-of-the-art Earth system models can provide detailed insight into these impacts, but have a large associated computational cost on a per-scenario basis. This large computational burden has driven recent interest in developing cheap machine learning models for the task of climate model emulation. In this manuscript, we explore the efficacy of randomly wired neural networks for this task. We describe how they can be constructed and compare them to their standard feedforward counterparts using the ClimateBench dataset. Specifically, we replace the dense layers in multilayer perceptrons, convolutional neural networks, and convolutional long short-term memory networks with randomly wired ones and assess the impact on model performance for models with 1 million and 10 million parameters. We find average performance improvements of 4.2\% across model complexities and prediction tasks, with substantial performance improvements of up to 16.4\% in some cases. Furthermore, we find no significant difference in prediction speed between networks with standard feedforward dense layers and those with randomly wired layers. These findings indicate that randomly wired neural networks may be suitable direct replacements for traditional dense layers in many standard models.},
	author = {Yik, William and Silva, Sam and Geiss, Andrew and Watson-Parris, Duncan},
	keywords = {★},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/H7BGGJZA/paper.pdf:application/pdf},
}

@techreport{blanchard_multi-scale_nodate,
	title = {A {Multi}-{Scale} {Deep} {Learning} {Framework} for {Projecting} {Weather} {Extremes}},
	abstract = {Weather extremes are a major societal and economic hazard, claiming thousands of lives and causing billions of dollars in damage every year. Under climate change, their impact and intensity are expected to worsen significantly. Unfortunately, general circulation models (GCMs), which are currently the primary tool for climate projections, cannot characterize weather extremes accurately. To address this, we present a multi-resolution deep-learning framework that, firstly, corrects a GCM's biases by matching low-order and tail statistics of its output with observations at coarse scales; and secondly, increases the level of detail of the debiased GCM output by reconstructing the finer scales as a function of the coarse scales. We use the proposed framework to generate statistically realistic realizations of the climate over Western Europe from a simple GCM corrected using observational atmospheric reanalysis. We also discuss implications for probabilistic risk assessment of natural disasters in a changing climate.},
	author = {Blanchard, Antoine and Parashar, Nishant and Dodov, Boyko and Lessig, Christian},
	keywords = {★},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/H33I87U5/multiscale_deep_extremes.pdf:application/pdf},
}

@techreport{sospedra-alfonso_deep_nodate,
	title = {Deep learning-based bias adjustment of decadal climate predictions},
	abstract = {Decadal climate predictions are key to inform adaptation strategies in a warming climate. Coupled climate models used for decadal predictions are, however, imperfect representations of the climate system causing forecast biases. Biases can also result from a poor model initialization that, when combined with forecast drift, can produce errors depending non-linearly on lead time. We propose a deep learning-based bias correction approach for post-processing gridded forecasts to enhance the accuracy of decadal climate predictions. 1 Motivation and problem statement Decadal or near-term climate prediction refers to climate forecasts on the range of a year to a decade. Unlike climate projections, which simulate the climate response to external forcing such as changes in greenhouse gas concentrations and aerosols, decadal predictions also simulate the climate response to unforced variations such as El Niño-Southern Oscillation (ENSO) and other modes of internal climate variability. As part of the Wold Climate Research Program (WCRP), the Decadal Climate Prediction Project (DCPP) [1] offers quasi-real-time decadal forecasts for potential users, whereas the World Meteorological Organization (WMO) Global Annual to Decadal Climate Update (GADCU) is produced annually to inform society on the state of the climate for the next 5 years [2]. Decadal forecasts typically drift from their observation-based initial conditions toward the uncon-strained model climatology, which may be far from observations. Consequently, operational decadal predictions often require some form of data post-processing to attain skill. This is often done using simple linear methods. Given the importance of climate predictions for informed adaptation strategies, the exploration of novel post-processing methods to correct forecast bias and drift is an important step to improve adaptation. We propose a deep learning model as a data post-processing tool for gridded climate predictions to enhance forecast skill. 2 Background and previous work While many studies describe adjustments of weather and subseasonal-to-seasonal (S2S) forecasts, there is limited work devoted to adjustments of decadal predictions, partly due to their relatively recent use, unique long-time range, drifts, and potential for erroneous trends. A simple approach is climatological bias correction, for which the difference between the modeled and observed clima-Tackling Climate Change with Machine Learning: workshop at NeurIPS 2022.},
	author = {Sospedra-Alfonso, Reinel and Exenberger, Johannes and Mcgraw, Marie C and Dang, Trung Kien},
	keywords = {★},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/T74K3BIC/paper (2).pdf:application/pdf},
}

@article{veldkamp_statistical_2021,
	title = {Statistical postprocessing of wind speed forecasts using convolutional neural networks},
	volume = {149},
	issn = {15200493},
	doi = {10.1175/MWR-D-20-0219.1},
	abstract = {Current statistical postprocessing methods for probabilistic weather forecasting are not capable of using full spatial patterns from the numerical weather prediction (NWP) model. In this paper, we incorporate spatial wind speed information by using convolutional neural networks (CNNs) and obtain probabilistic wind speed forecasts in the Netherlands for 48 h ahead, based on KNMI's deterministic HARMONIE-AROME NWP model. The probabilistic forecasts from the CNNs are shown to have higher Brier skill scores for medium to higher wind speeds, as well as a better continuous ranked probability score (CRPS) and logarithmic score, than the forecasts from fully connected neural networks and quantile regression forests. As a secondary result, we have compared the CNNs using three different density estimation methods [quantized softmax (QS), kernel mixture networks, and fitting a truncated normal distribution], and found the probabilistic forecasts based on the QS method to be best.},
	number = {4},
	journal = {Monthly Weather Review},
	author = {Veldkamp, Simon and Whan, Kirien and Dirksen, Sjoerd and Schmeits, Maurice},
	year = {2021},
	note = {arXiv: 2007.04005
Publisher: American Meteorological Society},
	keywords = {Forecast verification/skill, ★, Model output statistics, Probability forecasts/models/distribution, Deep learning, Neural networks, Machine learning},
	pages = {1141--1152},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/MJ7I7PQI/1520-0493-MWR-D-20-0219.1.pdf:application/pdf},
}

@article{walker_skill_2019,
	title = {Skill of dynamical and {GHACOF} consensus seasonal forecasts of {East} {African} rainfall},
	volume = {53},
	issn = {14320894},
	doi = {10.1007/s00382-019-04835-9},
	abstract = {Seasonal forecasts of rainfall are considered the priority timescale by many users in the tropics. In East Africa, the primary operational seasonal forecast for the region is produced by the Greater Horn of Africa Climate Outlook Forum (GHACOF), and issued ahead of each rainfall season. This study evaluates and compares the GHACOF consensus forecasts with dynamical model forecasts from the UK Met Office GloSea5 seasonal prediction system for the two rainy seasons. GloSea demonstrates positive skill (r = 0.69) for the short rains at 1 month lead. In contrast, skill is low for the long rains due to lack of predictability of driving factors. For both seasons GHACOF forecasts show generally lower levels of skill than GloSea. Several systematic errors within the GHACOF forecasts are identified; the largest being the tendency to over-estimate the likelihood of near normal rainfall, with over 70\% (80\%) of forecasts giving this category the highest probability in the short (long) rains. In a more detailed evaluation of GloSea, a large wet bias, increasing with forecast lead time, is identified in the short rains. This bias is attributed to a developing cold SST bias in the eastern Indian Ocean, driving an easterly wind bias across the equatorial Indian Ocean. These biases affect the mean state moisture availability, and could act to reduce the ability of the dynamical model in predicting interannual variability, which may also be relevant to predictions from coupled models on longer timescales.},
	number = {7-8},
	journal = {Climate Dynamics},
	author = {Walker, Dean P. and Birch, Cathryn E. and Marsham, John H. and Scaife, Adam A. and Graham, Richard J. and Segele, Zewdu T.},
	month = oct,
	year = {2019},
	note = {Publisher: Springer Verlag},
	keywords = {Precipitation, East Africa, Consensus outlooks, Probabilistic verification, Seasonal climate forecasts},
	pages = {4911--4935},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/4YH66J7L/s00382-019-04835-9.pdf:application/pdf},
}

@techreport{khayatkhoei_spatial_2022,
	title = {Spatial {Frequency} {Bias} in {Convolutional} {Generative} {Adversarial} {Networks}},
	url = {www.aaai.org},
	abstract = {Understanding the capability of Generative Adversarial Networks (GANs) in learning the full spectrum of spatial frequencies , that is, beyond the low-frequency dominant spectrum of natural images, is critical for assessing the reliability of GAN-generated data in any detail-sensitive application. In this work, we show that the ability of convolutional GANs to learn an image distribution depends on the spatial frequency of the underlying carrier signal, that is, they have a bias against learning high spatial frequencies. Our findings are consistent with the recent observations of high-frequency artifacts in GAN-generated images, but further suggest that such artifacts are the consequence of an underlying bias. We also provide a theoretical explanation for this bias as the manifestation of linear dependencies present in the spectrum of filters of a typical generative Convolutional Neural Network (CNN). Finally, by proposing a proof-of-concept method that can effectively manipulate this bias towards other spatial frequencies , we show that the bias is not fixed and can be exploited to explicitly direct computational resources towards any specific spatial frequency of interest in a dataset, with minimal computational overhead.},
	author = {Khayatkhoei, Mahyar and Elgammal, Ahmed},
	year = {2022},
	keywords = {★, FT: Computer Vision (CV), FT: Machine Learning (ML)},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/CH4PZ5C3/20675-Article Text-24688-1-2-20220628.pdf:application/pdf},
}

@article{vannitsem_predictability_2017,
	title = {Predictability of large-scale atmospheric motions: {Lyapunov} exponents and error dynamics},
	volume = {27},
	issn = {10541500},
	doi = {10.1063/1.4979042},
	abstract = {The deterministic equations describing the dynamics of the atmosphere (and of the climate system) are known to display the property of sensitivity to initial conditions. In the ergodic theory of chaos, this property is usually quantified by computing the Lyapunov exponents. In this review, these quantifiers computed in a hierarchy of atmospheric models (coupled or not to an ocean) are analyzed, together with their local counterparts known as the local or finite-time Lyapunov exponents. It is shown in particular that the variability of the local Lyapunov exponents (corresponding to the dominant Lyapunov exponent) decreases when the model resolution increases. The dynamics of (finite-amplitude) initial condition errors in these models is also reviewed, and in general found to display a complicated growth far from the asymptotic estimates provided by the Lyapunov exponents. The implications of these results for operational (high resolution) atmospheric and climate modelling are also discussed.},
	number = {3},
	journal = {Chaos},
	author = {Vannitsem, Stéphane},
	month = mar,
	year = {2017},
	pmid = {28364758},
	note = {arXiv: 1703.04284
Publisher: American Institute of Physics Inc.},
	keywords = {★},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/6F2KXPBX/1.4979042.pdf:application/pdf},
}

@article{vaughan_convolutional_2022,
	title = {Convolutional conditional neural processes for local climate downscaling},
	volume = {15},
	issn = {19919603},
	doi = {10.5194/gmd-15-251-2022},
	abstract = {A new model is presented for multisite statistical downscaling of temperature and precipitation using convolutional conditional neural processes (convCNPs). ConvCNPs are a recently developed class of models that allow deep-learning techniques to be applied to off-the-grid spatio-temporal data. In contrast to existing methods that map from low-resolution model output to high-resolution predictions at a discrete set of locations, this model outputs a stochastic process that can be queried at an arbitrary latitude-longitude coordinate. The convCNP model is shown to outperform an ensemble of existing downscaling techniques over Europe for both temperature and precipitation taken from the VALUE intercomparison project. The model also outperforms an approach that uses Gaussian processes to interpolate single-site downscaling models at unseen locations. Importantly, substantial improvement is seen in the representation of extreme precipitation events. These results indicate that the convCNP is a robust downscaling model suitable for generating localised projections for use in climate impact studies.},
	number = {1},
	journal = {Geoscientific Model Development},
	author = {Vaughan, Anna and Tebbutt, Will and Hosking, J. Scott and Turner, Richard E.},
	month = jan,
	year = {2022},
	note = {arXiv: 2101.07950
Publisher: Copernicus GmbH},
	keywords = {★},
	pages = {251--268},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/7Q53E99J/gmd-15-251-2022.pdf:application/pdf},
}

@techreport{ling_conditioned_nodate-1,
	title = {Conditioned {Spatial} {Downscaling} of {Climate} {Variables}},
	url = {https://github.com/evbecker/climate-spatial-downscaling},
	abstract = {Global Climate Models (GCM) play a vital role in assessing the large-scale impacts of climate change. Downscaling methods can translate coarse-resolution climate information from GCM to high-resolution predictions to forecast regional effects. Unfortunately, current downscaling methods struggle to fully take into account spatial relationships among variables, especially at long distances. In this work, we propose an instance-conditional pixel synthesis generative adversarial network (ICPS-GAN), wherein conditioning on spatial information is an explicit way of providing the GAN with previous high-resolution and current low-resolution data, resulting in an enhancement of the general performance. Experimental results on precipitation forecast for US region data outperform both traditional and other learning-based methods when extrapolating in space. The code is available at https://github.com/evbecker/climate-spatial-downscaling},
	author = {Ling, Alex and Hung, Yu and Becker, Evan and Zadouri, Ted and Grover, Aditya},
	keywords = {★},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/BPKG62YT/104_conditioned_spatial_downscalin.pdf:application/pdf},
}

@article{ji_clgan_nodate,
	title = {{CLGAN}: {A} {GAN}-based video prediction model for precipitation nowcasting},
	url = {https://doi.org/10.5194/egusphere-2022-859},
	doi = {10.5194/egusphere-2022-859},
	abstract = {The prediction of precipitation patterns at high spatio-temporal resolution up to two hours ahead, also known as precipitation nowcasting, is of great relevance in weather-dependant decision-making and early warning systems. In this study, we are aiming to provide an efficient and easy-to-understand model-CLGAN, to improve the nowcasting skills of heavy precipitation events with deep neural networks for video prediction. The model constitutes a Generative Adversarial Network (GAN) architecture whose generator is built upon an u-shaped encoder-decoder network (U-Net) equipped with recurrent 5 LSTM cells to capture spatio-temporal features. A comprehensive comparison among CLGAN, and baseline models optical flow model DenseRotation as well as the advanced video prediction model PredRNN-v2 is performed. We show that CLGAN outperforms in terms of scores for dichotomous events and object-based diagnostics. The ablation study indicates that the GAN-based architecture helps to capture heavy precipitation events. The results encourage future work based on the proposed CLGAN architecture to improve the precipitation nowcasting and early-warning systems.},
	author = {Ji, Yan and Gong, Bing and Langguth, Michael and Mozaffari, Amirpasha and Zhi, Xiefei},
	keywords = {★},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/YU3MRWNJ/egusphere-2022-859.pdf:application/pdf},
}

@article{castro-camilo_spliced_2019,
	title = {A {Spliced} {Gamma}-{Generalized} {Pareto} {Model} for {Short}-{Term} {Extreme} {Wind} {Speed} {Probabilistic} {Forecasting}},
	volume = {24},
	issn = {15372693},
	doi = {10.1007/s13253-019-00369-z},
	abstract = {Renewable sources of energy such as wind power have become a sustainable alternative to fossil fuel-based energy. However, the uncertainty and fluctuation of the wind speed derived from its intermittent nature bring a great threat to the wind power production stability, and to the wind turbines themselves. Lately, much work has been done on developing models to forecast average wind speed values, yet surprisingly little has focused on proposing models to accurately forecast extreme wind speeds, which can damage the turbines. In this work, we develop a flexible spliced Gamma-Generalized Pareto model to forecast extreme and non-extreme wind speeds simultaneously. Our model belongs to the class of latent Gaussian models, for which inference is conveniently performed based on the integrated nested Laplace approximation method. Considering a flexible additive regression structure, we propose two models for the latent linear predictor to capture the spatio-temporal dynamics of wind speeds. Our models are fast to fit and can describe both the bulk and the tail of the wind speed distribution while producing short-term extreme and non-extreme wind speed probabilistic forecasts. Supplementary materials accompanying this paper appear online.},
	number = {3},
	journal = {Journal of Agricultural, Biological, and Environmental Statistics},
	author = {Castro-Camilo, Daniela and Huser, Raphaël and Rue, Håvard},
	month = sep,
	year = {2019},
	note = {arXiv: 1810.04099
Publisher: Springer New York LLC},
	keywords = {★, Extreme-value theory, INLA, Latent Gaussian models, SPDE, Threshold-based inference, Wind speed forecasting},
	pages = {517--534},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/BXVF5UJE/s13253-019-00369-z.pdf:application/pdf},
}

@article{hayatbini_conditional_2019,
	title = {Conditional generative adversarial networks ({cGANs}) for near real-time precipitation estimation from multispectral {GOES}-16 satellite imageries-{PERSIANN}-{cGAN}},
	volume = {11},
	issn = {20724292},
	doi = {10.3390/rs11192193},
	abstract = {In this paper, we present a state-of-the-art precipitation estimation framework which leverages advances in satellite remote sensing as well as Deep Learning (DL). The framework takes advantage of the improvements in spatial, spectral and temporal resolutions of the Advanced Baseline Imager (ABI) onboard the GOES-16 platform along with elevation information to improve the precipitation estimates. The procedure begins by first deriving a Rain/No Rain (R/NR) binary mask through classification of the pixels and then applying regression to estimate the amount of rainfall for rainy pixels. A Fully Convolutional Network is used as a regressor to predict precipitation estimates. The network is trained using the non-saturating conditional Generative Adversarial Network (cGAN) and Mean Squared Error (MSE) loss terms to generate results that better learn the complex distribution of precipitation in the observed data. Common verification metrics such as Probability Of Detection (POD), False Alarm Ratio (FAR), Critical Success Index (CSI), Bias, Correlation and MSE are used to evaluate the accuracy of both R/NR classification and real-valued precipitation estimates. Statistics and visualizations of the evaluation measures show improvements in the precipitation retrieval accuracy in the proposed framework compared to the baseline models trained using conventional MSE loss terms. This framework is proposed as an augmentation for PERSIANN-CCS (Precipitation Estimation from Remotely Sensed Information using Artificial Neural Network- Cloud Classification System) algorithm for estimating global precipitation.},
	number = {19},
	journal = {Remote Sensing},
	author = {Hayatbini, Negin and Kong, Bailey and Hsu, Kuo Lin and Nguyen, Phu and Sorooshian, Soroosh and Stephens, Graeme and Fowlkes, Charless and Nemani, Ramakrishna and Ganguly, Sangram},
	month = oct,
	year = {2019},
	note = {Publisher: MDPI AG},
	keywords = {Precipitation, ★, Machine learning, Convolutional neural networks (CNNs), Generative adversarial networks (GANs), Multispectral satellite imagery},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/4LRU4DJK/remotesensing-11-02193-v2.pdf:application/pdf},
}

@techreport{wilson_bayesian_nodate,
	title = {Bayesian {Deep} {Learning} and a {Probabilistic} {Perspective} of {Generalization}},
	url = {https://github.com/izmailovpavel/understandingbdl.},
	abstract = {The key distinguishing property of a Bayesian approach is marginalization, rather than using a single setting of weights. Bayesian marginalization can particularly improve the accuracy and calibration of modern deep neural networks, which are typically underspecified by the data, and can represent many compelling but different solutions. We show that deep ensembles provide an effective mechanism for approximate Bayesian marginalization, and propose a related approach that further improves the predictive distribution by marginalizing within basins of attraction, without significant overhead. We also investigate the prior over functions implied by a vague distribution over neural network weights, explaining the generalization properties of such models from a probabilistic perspective. From this perspective, we explain results that have been presented as mysterious and distinct to neural network generalization, such as the ability to fit images with random labels, and show that these results can be reproduced with Gaussian processes. We also show that Bayesian model averaging alleviates double descent, resulting in monotonic performance improvements with increased flexibility.},
	author = {Wilson, Andrew Gordon and Izmailov, Pavel},
	keywords = {★},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/3HIIT4H8/NeurIPS-2020-bayesian-deep-learning-and-a-probabilistic-perspective-of-generalization-Paper.pdf:application/pdf},
}

@article{leinonen_stochastic_2020,
	title = {Stochastic {Super}-{Resolution} for {Downscaling} {Time}-{Evolving} {Atmospheric} {Fields} {With} a {Generative} {Adversarial} {Network}},
	volume = {59},
	issn = {0196-2892},
	doi = {10.1109/tgrs.2020.3032790},
	abstract = {Generative adversarial networks (GANs) have been recently adopted for super-resolution, an application closely related to what is referred to as "downscaling" in the atmospheric sciences: improving the spatial resolution of low-resolution images. The ability of conditional GANs to generate an ensemble of solutions for a given input lends itself naturally to stochastic downscaling, but the stochastic nature of GANs is not usually considered in super-resolution applications. Here, we introduce a recurrent, stochastic super-resolution GAN that can generate ensembles of time-evolving high-resolution atmospheric fields for an input consisting of a low-resolution sequence of images of the same field. We test the GAN using two datasets, one consisting of radar-measured precipitation from Switzerland, the other of cloud optical thickness derived from the Geostationary Earth Observing Satellite 16 (GOES-16). We find that the GAN can generate realistic, temporally consistent super-resolution sequences for both datasets. The statistical properties of the generated ensemble are analyzed using rank statistics, a method adapted from ensemble weather forecasting; these analyses indicate that the GAN produces close to the correct amount of variability in its outputs. As the GAN generator is fully convolutional, it can be applied after training to input images larger than the images used to train it. It is also able to generate time series much longer than the training sequences, as demonstrated by applying the generator to a three-month dataset of the precipitation radar data. The source code to our GAN is available at https://github.com/jleinonen/downscaling-rnn-gan.},
	number = {9},
	journal = {IEEE Transactions on Geoscience and Remote Sensing},
	author = {Leinonen, Jussi and Nerini, Daniele and Berne, Alexis},
	month = nov,
	year = {2020},
	note = {arXiv: 2005.10374
Publisher: Institute of Electrical and Electronics Engineers (IEEE)},
	pages = {7211--7223},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/BUTDXGTS/Stochastic_Super-Resolution_for_Downscaling_Time-Evolving_Atmospheric_Fields_With_a_Generative_Adversarial_Network.pdf:application/pdf},
}

@article{vandal_intercomparison_2019,
	title = {Intercomparison of machine learning methods for statistical downscaling: the case of daily and extreme precipitation},
	volume = {137},
	issn = {14344483},
	url = {https://link.springer.com/article/10.1007/s00704-018-2613-3},
	doi = {10.1007/s00704-018-2613-3},
	abstract = {Statistical downscaling of Global Climate Models (GCMs) allows researchers to study local climate change effects decades into the future. A wide range of statistical models have been applied to downscaling GCMs but recent advances in machine learning have not been explored compared to traditional approaches. In this paper, we compare five Perfect Prognosis (PP) approaches, Ordinary Least Squares, Elastic-Net, and Support Vector Machine along with two machine learning methods Multi-task Sparse Structure Learning (MSSL) and Autoencoder Neural Networks. In addition, we introduce a hybrid Model Output Statistics and PP approach by modeling the residuals of Bias Correction Spatial Disaggregation (BCSD) with MSSL. Metrics to evaluate each method’s ability to capture daily anomalies, large-scale climate shifts, and extremes are analyzed. Generally, we find inconsistent performance between PP methods in their ability to predict daily anomalies and extremes as well as monthly and annual precipitation. However, results suggest that L1 sparsity constraints aid in reducing error through internal feature selection. The MSSL+BCSD coupling, when compared with BCSD, improved daily, monthly, and annual predictability but decreased performance at the extremes. Hence, these results suggest that the direct application of state-of-the-art machine learning methods to statistical downscaling does not provide direct improvements over simpler, longstanding approaches.},
	number = {1-2},
	urldate = {2022-11-16},
	journal = {Theoretical and Applied Climatology},
	author = {Vandal, Thomas and Kodra, Evan and Ganguly, Auroop R.},
	month = jul,
	year = {2019},
	note = {arXiv: 1702.04018
Publisher: Springer-Verlag Wien},
	pages = {557--570},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/ZG9Q4D6P/s00704-018-2613-3.pdf:application/pdf},
}

@article{kashinath_physics-informed_2021,
	title = {Physics-informed machine learning: {Case} studies for weather and climate modelling},
	volume = {379},
	issn = {1364503X},
	doi = {10.1098/rsta.2020.0093},
	abstract = {Machine learning (ML) provides novel and powerful ways of accurately and efficiently recognizing complex patterns, emulating nonlinear dynamics, and predicting the spatio-temporal evolution of weather and climate processes. Off-the-shelf ML models, however, do not necessarily obey the fundamental governing laws of physical systems, nor do they generalize well to scenarios on which they have not been trained. We survey systematic approaches to incorporating physics and domain knowledge into ML models and distill these approaches into broad categories. Through 10 case studies, we show how these approaches have been used successfully for emulating, downscaling, and forecasting weather and climate processes. The accomplishments of these studies include greater physical consistency, reduced training time, improved data efficiency, and better generalization. Finally, we synthesize the lessons learned and identify scientific, diagnostic, computational, and resource challenges for developing truly robust and reliable physics-informed ML models for weather and climate processes. This article is part of the theme issue 'Machine learning for weather and climate modelling'.},
	number = {2194},
	journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Kashinath, K. and Mustafa, M. and Albert, A. and Wu, J. L. and Jiang, C. and Esmaeilzadeh, S. and Azizzadenesheli, K. and Wang, R. and Chattopadhyay, A. and Singh, A. and Manepalli, A. and Chirila, D. and Yu, R. and Walters, R. and White, B. and Xiao, H. and Tchelepi, H. A. and Marcus, P. and Anandkumar, A. and Hassanzadeh, P. and {Prabhat}},
	month = apr,
	year = {2021},
	pmid = {33583262},
	note = {Publisher: Royal Society Publishing},
	keywords = {★, neural networks, physical constraints, physics-informed machine learning, turbulent flows, weather and climate modeling},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/JDWPK65D/rsta.2020.0093.pdf:application/pdf},
}

@article{rampal_high-resolution_2022,
	title = {High-resolution downscaling with interpretable deep learning: {Rainfall} extremes over {New} {Zealand}},
	volume = {38},
	issn = {22120947},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2212094722001049},
	doi = {10.1016/j.wace.2022.100525},
	journal = {Weather and Climate Extremes},
	author = {Rampal, Neelesh and Gibson, Peter B. and Sood, Abha and Stuart, Stephen and Fauchereau, Nicolas C. and Brandolino, Chris and Noll, Ben and Meyers, Tristan},
	month = dec,
	year = {2022},
	pages = {100525},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/Q72V46NN/1-s2.0-S2212094722001049-main.pdf:application/pdf},
}

@inproceedings{vandal_deepsd_2017,
	address = {New York, NY, USA},
	title = {{DeepSD}: {Generating} {High} {Resolution} {Climate} {ChangeProjections} through {Single} {Image} {Super}-{Resolution}},
	isbn = {978-1-4503-4887-4},
	doi = {10.1145/3097983.3098004},
	booktitle = {Proceedings of the 23rd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {ACM},
	author = {Vandal, Thomas and Kodra, Evan and Ganguly, Sangram and Michaelis, Andrew and Nemani, Ramakrishna and Ganguly, Auroop R.},
	month = aug,
	year = {2017},
	keywords = {★},
	pages = {1663--1672},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/PAYZEZQE/3097983.3098004.pdf:application/pdf},
}

@article{steininger_convmos_2022,
	title = {{ConvMOS}: climate model output statistics with deep learning},
	issn = {1384-5810},
	url = {https://link.springer.com/10.1007/s10618-022-00877-6},
	doi = {10.1007/s10618-022-00877-6},
	abstract = {{\textless}p{\textgreater}Climate models are the tool of choice for scientists researching climate change. Like all models they suffer from errors, particularly systematic and location-specific representation errors. One way to reduce these errors is model output statistics (MOS) where the model output is fitted to observational data with machine learning. In this work, we assess the use of convolutional Deep Learning climate MOS approaches and present the ConvMOS architecture which is specifically designed based on the observation that there are systematic and location-specific errors in the precipitation estimates of climate models. We apply ConvMOS models to the simulated precipitation of the regional climate model REMO, showing that a combination of per-location model parameters for reducing location-specific errors and global model parameters for reducing systematic errors is indeed beneficial for MOS performance. We find that ConvMOS models can reduce errors considerably and perform significantly better than three commonly used MOS approaches and plain ResNet and U-Net models in most cases. Our results show that non-linear MOS models underestimate the number of extreme precipitation events, which we alleviate by training models specialized towards extreme precipitation events with the imbalanced regression method DenseLoss. While we consider climate MOS, we argue that aspects of ConvMOS may also be beneficial in other domains with geospatial data, such as air pollution modeling or weather forecasts.{\textless}/p{\textgreater}},
	journal = {Data Mining and Knowledge Discovery},
	author = {Steininger, Michael and Abel, Daniel and Ziegler, Katrin and Krause, Anna and Paeth, Heiko and Hotho, Andreas},
	month = oct,
	year = {2022},
	keywords = {★},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/3LWCKZUF/s10618-022-00877-6.pdf:application/pdf},
}

@article{rummukainen_state---art_2010,
	title = {State-of-the-art with regional climate models},
	volume = {1},
	url = {https://wires.onlinelibrary.wiley.com/doi/10.1002/wcc.8},
	doi = {10.1002/wcc.008},
	abstract = {Regional climate models are used by a large number of groups, for more or less all regions of the world. Regional climate models are complementary to global climate models. A typical use of regional climate models is to add further detail to global climate analyses or simulations, or to study climate processes in more detail than global models allow. The relationship between global and regional climate models is much akin to that of global and regional weather forecasting models. Over the past 20 years, the development of regional climate models has led to increased resolution, longer model runs, and steps towards regional climate system models. During recent years, community efforts have started to emerge in earnest, which can be expected to further advance the state-of-the-art in regional climate modeling. Applications of regional climate models span both the past and possible future climates, facilitating climate impact studies, information and support to climate policy, and adaptation.  2010 John Wiley \& Sons, Ltd. WIREs Clim Change 2010 1 82-96 G lobal climate models (GCMs) are a fundamental research tool for the understanding of climate. Regional climate models (RCMs) are a complementary research method, allowing more detailed process studies and simulation of regional and even local conditions. In so doing, they provide key input to climate impact studies as well as to adaptation planning, dealing with possible damages and opportunities related to climate variability and change. RCMs are thus vehicles for both research and applications. RCMs are not a new concept. They are at their core limited area models that are used in numerical weather prediction (NWP). The pioneering regional climate modeling efforts were those of Refs 1 and 2 For more information on the earlier developments, the reader is referred to Refs 3-7. Today, regional climate modeling encompasses a large international community and covers most geographical regions of the globe (see Figure 1). This article describes the essential principles of RCMs, outlining their potential and acknowledges fundamental limitations, for the interested interdis-ciplinary readership. Consideration is also given to the role of RCMs vis-` a-vis applications to climate projections. Other major uses are mentioned in brief, such as climate process and climate system studies. The references provided are not exhaustive and the discussion does not venture into deep detail. Weather and seasonal forecasting applications are outside the scope of this review. THE DOWNSCALING CONCEPT The climate system is global. Observations, theory, and models are all needed in climate research. Comprehensive climate models are based on physical laws and allow for numerical simulations. The climate system is characterized by a broad range of spatial scales and timescales. Consequently, GCMs can effectively address large-scale climate features such as the general circulation of the atmosphere and the ocean, and sub-continental patterns of, for example, temperature and precipitation. Their formal resolution (grid scale) is at best around 100-200 km. 8 Their real resolution is more like 6-8 grid distances, i.e., of the order of 1000 km. 9 This falls short of many key regional and local climate aspects, e.g. intensive precipitation. Very high global model resolution would of course give rise to simulation of regional and local aspects, see e.g., Ref 10. GCMs of this kind are, however, still not feasible due to their high computational cost. Other methods are therefore needed, which is the backdrop to downscaling (cf. Figure 2).},
	journal = {John Wiley \& Sons, Ltd},
	author = {Rummukainen, Markku},
	year = {2010},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/5CIZPNZB/WIREs Climate Change - 2009 - Rummukainen - State‐of‐the‐art with regional climate models.pdf:application/pdf},
}

@article{kumar_deep_nodate,
	title = {Deep learning-based downscaling of summer monsoon rainfall data over {Indian} region},
	url = {https://doi.org/10.1007/s00704-020-03489-6},
	doi = {10.1007/s00704-020-03489-6/Published},
	abstract = {Downscaling is necessary to generate high-resolution observation data to validate the climate model forecast or monitor rainfall at the micro-regional level operationally. Available observations generated by automated weather stations or meteorological observatories are often limited in spatial resolution resulting in misrepresentation or absence of rainfall information at these levels. Dynamical and statistical downscaling models are often used to get information at high-resolution gridded data over larger domains. As rainfall variability is dependent on the complex spatio-temporal process leading to non-linear or chaotic spatio-temporal variations, no single downscaling method can be considered efficient enough. In the domains dominated by complex topographies, quasi-periodicities, and non-linearities, deep learning (DL)-based methods provide an efficient solution in down-scaling rainfall data for regional climate forecasting and real-time rainfall observation data at high spatial resolutions. We employed three deep learning-based algorithms derived from the super-resolution convolutional neural network (SRCNN) methods in this work. Summer monsoon season data from India Meteorological Department (IMD) and the tropical rainfall measuring mission (TRMM) data set were downscaled up to 4 times higher resolution using these methods. High-resolution data derived from deep learning-based models provide better results than linear interpolation for up to 4 times higher resolution. Among the three algorithms, namely, SRCNN, stacked SRCNN, and DeepSD, employed here, the best spatial distribution of rainfall amplitude and minimum root-mean-square error is produced by DeepSD-based downscaling. Hence, the use of the DeepSD algorithm is advocated for future use. We found that spatial discontinuity in amplitude and intensity rainfall patterns is the main obstacle in the downscaling of precipitation. Furthermore, we applied these methods for model data post-processing, in particular, ERA5 reanalysis data. Downscaled ERA5 rainfall data show a much better distribution of spatial covariance and temporal variance when compared with observation. This study is the first step towards developing deep learning-based weather data downscaling model for Indian summer monsoon rainfall data.},
	author = {Kumar, Bipin and Chattopadhyay, Rajib and Singh, Manmeet and Chaudhari, Niraj and Kodari, Karthik and Barve, Amit},
	keywords = {Statistical downscaling, Deep learning method, Rainfall data over Indian region, Super-resolution},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/ISEH34Y4/s00704-020-03489-6.pdf:application/pdf},
}

@article{wang_deep_2021,
	title = {Deep {Learning} for {Daily} {Precipitation} and {Temperature} {Downscaling}},
	volume = {57},
	issn = {19447973},
	doi = {10.1029/2020WR029308},
	abstract = {Downscaling is a critical step to bridge the gap between large-scale climate information and local-scale impact assessment. This study presents a novel deep learning approach: Super Resolution Deep Residual Network (SRDRN) for downscaling daily precipitation and temperature. This approach was constructed based on an advanced deep convolutional neural network with residual blocks and batch normalizations. The data augmentation technique was utilized to address overfitting that is due to highly imbalanced precipitation and nonprecipitation days and sparse precipitation extremes. Synthetic experiments were designed to downscale daily maximum/minimum temperature and precipitation data from coarse resolutions (25, 50, and 100 km) to a high resolution (4 km). The results showed that, during the validation period, the SRDRN approach not only captured the spatial and temporal patterns remarkably well, but also reproduced both precipitation and temperature extremes in different locations and time at the local scale. Through transfer learning, the trained SRDRN model in one region was directly applied to downscale precipitation in another region with a different environment, and the results showed notable improvement compared to classic statistical downscaling methods. The outstanding performance of the SRDRN approach stemmed from its ability to fully extract spatial features without suffering from degradation and overfitting issues due to the incorporations of residual blocks, batch normalizations, and data augmentations. The SRDRN approach is thus a powerful tool for downscaling daily precipitation and temperature and can potentially be leveraged to downscale any hydrologic, climate, and earth system data.},
	number = {4},
	journal = {Water Resources Research},
	author = {Wang, Fang and Tian, Di and Lowe, Lisa and Kalin, Latif and Lehrter, John},
	month = apr,
	year = {2021},
	note = {Publisher: Blackwell Publishing Ltd},
	keywords = {precipitation, deep learning, downscaling, temperature},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/AN7HZ3W5/Water Resources Research - 2021 - Wang - Deep Learning for Daily Precipitation and Temperature Downscaling.pdf:application/pdf},
}

@article{hess_physically_2022,
	title = {Physically {Constrained} {Generative} {Adversarial} {Networks} for {Improving} {Precipitation} {Fields} from {Earth} {System} {Models}},
	url = {http://arxiv.org/abs/2209.07568},
	abstract = {Precipitation results from complex processes across many scales, making its accurate simulation in Earth system models (ESMs) challenging. Existing post-processing methods can improve ESM simulations locally, but cannot correct errors in modelled spatial patterns. Here we propose a framework based on physically constrained generative adversarial networks (GANs) to improve local distributions and spatial structure simultaneously. We apply our approach to the computationally efficient ESM CM2Mc-LPJmL. Our method outperforms existing ones in correcting local distributions, and leads to strongly improved spatial patterns especially regarding the intermittency of daily precipitation. Notably, a double-peaked Intertropical Convergence Zone, a common problem in ESMs, is removed. Enforcing a physical constraint to preserve global precipitation sums, the GAN can generalize to future climate scenarios unseen during training. Feature attribution shows that the GAN identifies regions where the ESM exhibits strong biases. Our method constitutes a general framework for correcting ESM variables and enables realistic simulations at a fraction of the computational costs.},
	journal = {Nature Machine Intelligence},
	author = {Hess, Philipp and Drüke, Markus and Petri, Stefan and Strnad, Felix M. and Boers, Niklas},
	month = aug,
	year = {2022},
	note = {arXiv: 2209.07568},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/Z246S36E/2209.07568.pdf:application/pdf},
}

@article{geiss_strict_2020,
	title = {Strict {Enforcement} of {Conservation} {Laws} and {Invertibility} in {CNN}-{Based} {Super} {Resolution} for {Scientific} {Datasets}},
	url = {http://arxiv.org/abs/2011.05586},
	abstract = {Recently, deep Convolutional Neural Networks (CNNs) have revolutionized image super-resolution (SR), dramatically outperforming past methods for enhancing image resolution. They could be a boon for the many scientific fields that involve image or gridded datasets: satellite remote sensing, radar meteorology, medical imaging, numerical modeling etc. Unfortunately, while SR-CNNs produce visually compelling outputs, they may break physical conservation laws when applied to scientific datasets. Here, a method for ``Downsampling Enforcement" in SR-CNNs is proposed. A differentiable operator is derived that, when applied as the final transfer function of a CNN, ensures the high resolution outputs exactly reproduce the low resolution inputs under 2D-average downsampling while improving performance of the SR schemes. The method is demonstrated across seven modern CNN-based SR schemes on several benchmark image datasets, and applications to weather radar, satellite imager, and climate model data are also shown. The approach improves training time and performance while ensuring physical consistency between the super-resolved and low resolution data.},
	author = {Geiss, Andrew and Hardin, Joseph C.},
	month = nov,
	year = {2020},
	note = {arXiv: 2011.05586},
	keywords = {★},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/PZI6WV6T/2011.05586.pdf:application/pdf},
}

@techreport{palmer_extended-range_nodate,
	title = {Extended-range atmospheric prediction and the {Lorenz} model},
	abstract = {The physical basis for extended-range prediction is explored using the famous three-component Lorenz convection model, taken as a conceptual representation of the chaotic extratropical circulation , and extended by coupling to a linear oscillator to represent large-scale tropical-extratropical interactions. The model is used to analyze the roles of time averaging and ensemble forecasting, and, in extended form, the impact of both anomalous tropical sea surface temperature and anomalous extratropical sea surface temperature. The conceptual paradigms and analytic calculations presented are used to interpret results from numerical weather prediction and general circulation model experiments. Some remarks on the relevance of predictability studies for the climate change problem are given.},
	author = {Palmer, TN},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/3DX7TQNG/[15200477 - Bulletin of the American Meteorological Society] Extended-Range Atmospheric Prediction and the Lorenz Model.pdf:application/pdf},
}

@techreport{wikipedia_numerical_nodate,
	title = {Numerical {Weather} {Prediction} ({Wikipedia})},
	author = {{Wikipedia}},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/P56IE6P6/Numerical_weather_prediction.pdf:application/pdf},
}

@article{bauer_quiet_2015,
	title = {The quiet revolution of numerical weather prediction},
	volume = {525},
	issn = {14764687},
	doi = {10.1038/nature14956},
	abstract = {Advances in numerical weather prediction represent a quiet revolution because they have resulted from a steady accumulation of scientific knowledge and technological advances over many years that, with only a few exceptions, have not been associated with the aura of fundamental physics breakthroughs. Nonetheless, the impact of numerical weather prediction is among the greatest of any area of physical science. As a computational problem, global weather prediction is comparable to the simulation of the human brain and of the evolution of the early Universe, and it is performed every day at major operational centres across the world.},
	number = {7567},
	journal = {Nature},
	author = {Bauer, Peter and Thorpe, Alan and Brunet, Gilbert},
	month = sep,
	year = {2015},
	note = {Publisher: Nature Publishing Group},
	pages = {47--55},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/HREVLLJJ/Bauer et al 2015 The quiet revolution of numerical weather prediction.pdf:application/pdf},
}

@article{leutbecher_ensemble_2008,
	title = {Ensemble forecasting},
	volume = {227},
	issn = {10902716},
	doi = {10.1016/j.jcp.2007.02.014},
	abstract = {Numerical weather prediction models as well as the atmosphere itself can be viewed as nonlinear dynamical systems in which the evolution depends sensitively on the initial conditions. The fact that estimates of the current state are inaccurate and that numerical models have inadequacies, leads to forecast errors that grow with increasing forecast lead time. The growth of errors depends on the flow itself. Ensemble forecasting aims at quantifying this flow-dependent forecast uncertainty. The sources of uncertainty in weather forecasting are discussed. Then, an overview is given on evaluating probabilistic forecasts and their usefulness compared with single forecasts. Thereafter, the representation of uncertainties in ensemble forecasts is reviewed with an emphasis on the initial condition perturbations. The review is complemented by a detailed description of the methodology to generate initial condition perturbations of the Ensemble Prediction System (EPS) of the European Centre for Medium-Range Weather Forecasts (ECMWF). These perturbations are based on the leading part of the singular value decomposition of the operator describing the linearised dynamics over a finite time interval. The perturbations are flow-dependent as the linearisation is performed with respect to a solution of the nonlinear forecast model. The extent to which the current ECMWF ensemble prediction system is capable of predicting flow-dependent variations in uncertainty is assessed for the large-scale flow in mid-latitudes. © 2007 Elsevier Inc. All rights reserved.},
	number = {7},
	journal = {Journal of Computational Physics},
	author = {Leutbecher, M. and Palmer, T. N.},
	month = mar,
	year = {2008},
	note = {Publisher: Academic Press Inc.},
	keywords = {Predictability, Numerical weather prediction, Uncertainty},
	pages = {3515--3539},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/S3GP5BEQ/Leutbecher and Palmer 2008 Ensemble forecasting.pdf:application/pdf},
}

@article{slingo_uncertainty_2011,
	title = {Uncertainty in weather and climate prediction},
	volume = {369},
	issn = {1364503X},
	doi = {10.1098/rsta.2011.0161},
	abstract = {Following Lorenz's seminal work on chaos theory in the 1960s, probabilistic approaches to prediction have come to dominate the science of weather and climate forecasting. This paper gives a perspective on Lorenz's work and how it has influenced the ways in which we seek to represent uncertainty in forecasts on all lead times from hours to decades. It looks at how model uncertainty has been represented in probabilistic prediction systems and considers the challenges posed by a changing climate. Finally, the paper considers how the uncertainty in projections of climate change can be addressed to deliver more reliable and confident assessments that support decision-making on adaptation and mitigation. This journal is © 2011 The Royal Society.},
	number = {1956},
	journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Slingo, Julia and Palmer, Tim},
	month = dec,
	year = {2011},
	note = {Publisher: Royal Society},
	keywords = {Uncertainty, Climate prediction, Ensemble prediction system, Probabilities, Weather forecasting},
	pages = {4751--4767},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/NU4VH537/Slingo and Palmer 2011 Uncertainty in weather and climate prediction.pdf:application/pdf},
}

@article{beucler_enforcing_2019,
	title = {Enforcing {Analytic} {Constraints} in {Neural}-{Networks} {Emulating} {Physical} {Systems}},
	url = {http://arxiv.org/abs/1909.00912},
	doi = {10.1103/PhysRevLett.126.098302},
	abstract = {Neural networks can emulate nonlinear physical systems with high accuracy, yet they may produce physically-inconsistent results when violating fundamental constraints. Here, we introduce a systematic way of enforcing nonlinear analytic constraints in neural networks via constraints in the architecture or the loss function. Applied to convective processes for climate modeling, architectural constraints enforce conservation laws to within machine precision without degrading performance. Enforcing constraints also reduces errors in the subsets of the outputs most impacted by the constraints.},
	journal = {Physical Review Letters},
	author = {Beucler, Tom and Pritchard, Michael and Rasp, Stephan and Ott, Jordan and Baldi, Pierre and Gentine, Pierre},
	month = sep,
	year = {2019},
	note = {arXiv: 1909.00912},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/V7G43X8V/1909.00912.pdf:application/pdf},
}

@article{pacchiardi_probabilistic_2021,
	title = {Probabilistic {Forecasting} with {Generative} {Networks} via {Scoring} {Rule} {Minimization}},
	url = {http://arxiv.org/abs/2112.08217},
	abstract = {Generative networks are often trained to minimize a statistical divergence between the reference distribution and the generative one in an adversarial setting. Some works trained instead generative networks to minimize Scoring Rules, functions assessing how well the generative distribution matches each training sample individually. We show how the Scoring Rule formulation easily extends to the so-called prequential (predictive-sequential) score, whose minimization allows performing probabilistic forecasting with generative networks. This objective leads to adversarial-free training, therefore easily avoiding uncertainty underestimation due to mode collapse, which is a common issue in the adversarial setting and undesirable for probabilistic forecasting. We provide consistency guarantees for the minimizer of the prequential score and employ that to perform probabilistic forecasting for two chaotic dynamical models and a benchmark dataset of global weather observations. For this last example, we define scoring rules for spatial data by drawing from the relevant literature, with which we obtain better uncertainty quantification with little hyperparameter tuning compared to adversarial training.},
	author = {Pacchiardi, Lorenzo and Adewoyin, Rilwan and Dueben, Peter and Dutta, Ritabrata},
	month = dec,
	year = {2021},
	note = {arXiv: 2112.08217},
	keywords = {★},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/WQTACMIL/2112.08217.pdf:application/pdf},
}

@article{larsen_autoencoding_2015,
	title = {Autoencoding beyond pixels using a learned similarity metric},
	url = {http://arxiv.org/abs/1512.09300},
	abstract = {We present an autoencoder that leverages learned representations to better measure similarities in data space. By combining a variational autoencoder with a generative adversarial network we can use learned feature representations in the GAN discriminator as basis for the VAE reconstruction objective. Thereby, we replace element-wise errors with feature-wise errors to better capture the data distribution while offering invariance towards e.g. translation. We apply our method to images of faces and show that it outperforms VAEs with element-wise similarity measures in terms of visual fidelity. Moreover, we show that the method learns an embedding in which high-level abstract visual features (e.g. wearing glasses) can be modified using simple arithmetic.},
	author = {Larsen, Anders Boesen Lindbo and Sønderby, Søren Kaae and Larochelle, Hugo and Winther, Ole},
	month = dec,
	year = {2015},
	note = {arXiv: 1512.09300},
	keywords = {★},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/FDS4PILH/1512.09300.pdf:application/pdf},
}

@techreport{su_pixel-adaptive_nodate,
	title = {Pixel-{Adaptive} {Convolutional} {Neural} {Networks}},
	abstract = {Convolutions are the fundamental building blocks of CNNs. The fact that their weights are spatially shared is one of the main reasons for their widespread use, but it is also a major limitation, as it makes convolutions content-agnostic. We propose a pixel-adaptive convolution (PAC) operation, a simple yet effective modification of standard convolutions, in which the filter weights are multiplied with a spatially varying kernel that depends on learnable, local pixel features. PAC is a generalization of several popular filtering techniques and thus can be used for a wide range of use cases. Specifically, we demonstrate state-of-the-art performance when PAC is used for deep joint image upsampling. PAC also offers an effective alternative to fully-connected CRF (Full-CRF), called PAC-CRF, which performs competitively compared to Full-CRF, while being considerably faster. In addition, we also demonstrate that PAC can be used as a drop-in replacement for convolution layers in pre-trained networks, resulting in consistent performance improvements.},
	author = {Su, Hang and Jampani, Varun and Sun, Deqing and Gallo, Orazio and Learned-Miller, Erik and Kautz, Jan and Amherst, UMass},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/J3Y6WPTZ/Su_Pixel-Adaptive_Convolutional_Neural_Networks_CVPR_2019_paper.pdf:application/pdf},
}

@article{clare_combining_2021,
	title = {Combining distribution‐based neural networks to predict weather forecast probabilities},
	volume = {147},
	issn = {0035-9009},
	doi = {10.1002/qj.4180},
	number = {741},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Clare, Mariana C.A. and Jamil, Omar and Morcrette, Cyril J.},
	month = oct,
	year = {2021},
	keywords = {★},
	pages = {4337--4357},
}

@article{kingma_auto-encoding_2013,
	title = {Auto-{Encoding} {Variational} {Bayes}},
	url = {http://arxiv.org/abs/1312.6114},
	abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
	author = {Kingma, Diederik P and Welling, Max},
	month = dec,
	year = {2013},
	note = {arXiv: 1312.6114},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/F794K3R3/1312.6114.pdf:application/pdf},
}

@article{reichstein_deep_2019,
	title = {Deep learning and process understanding for data-driven {Earth} system science},
	volume = {566},
	issn = {14764687},
	doi = {10.1038/s41586-019-0912-1},
	abstract = {Machine learning approaches are increasingly used to extract patterns and insights from the ever-increasing stream of geospatial data, but current approaches may not be optimal when system behaviour is dominated by spatial or temporal context. Here, rather than amending classical machine learning, we argue that these contextual cues should be used as part of deep learning (an approach that is able to extract spatio-temporal features automatically) to gain further process understanding of Earth system science problems, improving the predictive ability of seasonal forecasting and modelling of long-range spatial connections across multiple timescales, for example. The next step will be a hybrid modelling approach, coupling physical process models with the versatility of data-driven machine learning.},
	number = {7743},
	journal = {Nature},
	author = {Reichstein, Markus and Camps-Valls, Gustau and Stevens, Bjorn and Jung, Martin and Denzler, Joachim and Carvalhais, Nuno and {Prabhat}},
	month = feb,
	year = {2019},
	pmid = {30760912},
	note = {Publisher: Nature Publishing Group},
	pages = {195--204},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/LNJJ4I69/s41586-019-0912-1.pdf:application/pdf},
}

@incollection{vallis_effects_2017,
	title = {Effects of {Rotation} and {Stratification}},
	booktitle = {Atmospheric and {Oceanic} {Fluid} {Dynamics}},
	publisher = {Cambridge University Press},
	author = {Vallis, Geoffrey K.},
	month = may,
	year = {2017},
	doi = {10.1017/9781107588417.003},
	pages = {55--104},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/26YHW2SP/effects-of-rotation-and-stratification.pdf:application/pdf},
}

@incollection{vallis_equations_2017,
	title = {Equations of {Motion}},
	booktitle = {Atmospheric and {Oceanic} {Fluid} {Dynamics}},
	publisher = {Cambridge University Press},
	author = {Vallis, Geoffrey K.},
	month = may,
	year = {2017},
	doi = {10.1017/9781107588417.002},
	pages = {3--54},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/6XQRB53Y/equations_of_motion.pdf:application/pdf},
}

@article{bochenek_machine_2022,
	title = {Machine {Learning} in {Weather} {Prediction} and {Climate} {Analyses}—{Applications} and {Perspectives}},
	volume = {13},
	issn = {20734433},
	doi = {10.3390/atmos13020180},
	abstract = {In this paper, we performed an analysis of the 500 most relevant scientific articles published since 2018, concerning machine learning methods in the field of climate and numerical weather prediction using the Google Scholar search engine. The most common topics of interest in the abstracts were identified, and some of them examined in detail: in numerical weather prediction research—photovoltaic and wind energy, atmospheric physics and processes; in climate research— parametrizations, extreme events, and climate change. With the created database, it was also possible to extract the most commonly examined meteorological fields (wind, precipitation, temperature, pressure, and radiation), methods (Deep Learning, Random Forest, Artificial Neural Networks, Support Vector Machine, and XGBoost), and countries (China, USA, Australia, India, and Germany) in these topics. Performing critical reviews of the literature, authors are trying to predict the future research direction of these fields, with the main conclusion being that machine learning methods will be a key feature in future weather forecasting.},
	number = {2},
	journal = {Atmosphere},
	author = {Bochenek, Bogdan and Ustrnul, Zbigniew},
	month = feb,
	year = {2022},
	note = {Publisher: MDPI},
	keywords = {Numerical weather prediction, Climate, Machine learning, Weather},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/3C9X5TX6/atmosphere-13-00180.pdf:application/pdf},
}

@article{noauthor_comparison_nodate,
	title = {Comparison of {CMIP6} and {CMIP5} models in simulating mean and extreme precipitation over {East} {Africa}},
	doi = {https://doi.org/10.1002/joc.7207},
	file = {_.pdf:/Users/bobbyantonio/Zotero/storage/VN9D4HWR/_.pdf:application/pdf},
}

@article{liebmann_climatology_2017,
	title = {Climatology and {Interannual} {Variability} of {Boreal} {Spring} {Wet} {Season} {Precipitation} in the {Eastern} {Horn} of {Africa} and {Implications} for {Its} {Recent} {Decline}},
	volume = {30},
	issn = {0894-8755, 1520-0442},
	url = {https://journals.ametsoc.org/view/journals/clim/30/10/jcli-d-16-0452.1.xml},
	doi = {10.1175/JCLI-D-16-0452.1},
	abstract = {Abstract The 1981–2014 climatology and variability of the March–May eastern Horn of Africa boreal spring wet season are examined using precipitation, upper- and lower-level winds, low-level specific humidity, and convective available potential energy (CAPE), with the aim of better understanding the establishment of the wet season and the cause of the recent observed decline. At 850 mb, the development of the wet season is characterized by increasing specific humidity and winds that veer from northeasterly in February to southerly in June and advect moisture into the region, in agreement with an earlier study. Equally important, however, is a substantial weakening of the 200-mb climatological easterly winds in March. Likewise, the shutdown of the wet season coincides with the return of strong easterly winds in June. Similar changes are seen in the daily evolution of specific humidity and 200-mb wind when composited relative to the interannual wet season onset and end, with the easterlies decreasing (increasing) several days prior to the start (end) of the wet season. The 1981–2014 decrease in March–May precipitation has also coincided with an increase in 200-mb easterly winds, with no attendant change in specific humidity, leading to the conclusion that, while high values of specific humidity are an important ingredient of the wet season, the recent observed precipitation decline has resulted mostly from a strengthening of the 200-mb easterlies. This change in the easterly winds appears to be related to an increase in convection over the Indonesian region and in the associated outflow from that enhanced heat source.},
	language = {EN},
	number = {10},
	urldate = {2023-08-08},
	journal = {Journal of Climate},
	author = {Liebmann, Brant and Bladé, Ileana and Funk, Chris and Allured, Dave and Quan, Xiao-Wei and Hoerling, Martin and Hoell, Andrew and Peterson, Pete and Thiaw, Wassila M.},
	month = may,
	year = {2017},
	note = {Publisher: American Meteorological Society
Section: Journal of Climate},
	pages = {3867--3886},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/57GKUEVL/Liebmann et al. - 2017 - Climatology and Interannual Variability of Boreal .pdf:application/pdf},
}

@article{zadra_systematic_2018,
	title = {Systematic {Errors} in {Weather} and {Climate} {Models}: {Nature}, {Origins}, and {Ways} {Forward}},
	volume = {99},
	issn = {0003-0007, 1520-0477},
	shorttitle = {Systematic {Errors} in {Weather} and {Climate} {Models}},
	url = {https://journals.ametsoc.org/view/journals/bams/99/4/bams-d-17-0287.1.xml},
	doi = {10.1175/BAMS-D-17-0287.1},
	abstract = {"Systematic Errors in Weather and Climate Models: Nature, Origins, and Ways Forward" published on Apr 2018 by American Meteorological Society.},
	language = {EN},
	number = {4},
	urldate = {2023-08-04},
	journal = {Bulletin of the American Meteorological Society},
	author = {Zadra, Ayrton and Williams, Keith and Frassoni, Ariane and Rixen, Michel and Adames, Ángel F. and Berner, Judith and Bouyssel, François and Casati, Barbara and Christensen, Hannah and Ek, Michael B. and Flato, Greg and Huang, Yi and Judt, Falko and Lin, Hai and Maloney, Eric and Merryfield, William and Niekerk, Annelize Van and Rackow, Thomas and Saito, Kazuo and Wedi, Nils and Yadav, Priyanka},
	month = apr,
	year = {2018},
	note = {Publisher: American Meteorological Society
Section: Bulletin of the American Meteorological Society},
	pages = {ES67--ES70},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/SRZ9KFEV/Zadra et al. - 2018 - Systematic Errors in Weather and Climate Models N.pdf:application/pdf},
}

@article{watson_machine_2022,
	title = {Machine learning applications for weather and climate need greater focus on extremes},
	volume = {17},
	issn = {1748-9326},
	url = {https://dx.doi.org/10.1088/1748-9326/ac9d4e},
	doi = {10.1088/1748-9326/ac9d4e},
	language = {en},
	number = {11},
	urldate = {2023-08-04},
	journal = {Environmental Research Letters},
	author = {Watson, Peter A. G.},
	month = nov,
	year = {2022},
	note = {Publisher: IOP Publishing},
	pages = {111004},
	file = {IOP Full Text PDF:/Users/bobbyantonio/Zotero/storage/DS9GKCK5/Watson - 2022 - Machine learning applications for weather and clim.pdf:application/pdf},
}

@techreport{watkiss_socio-economic_2020,
	title = {The {Socio}-{Economic} {Benefits} of the {HIGHWAY} project},
	language = {en},
	institution = {Weather and Climate Information Services for Africa (WISER)},
	author = {Watkiss, Paul and Powell, Robert and Hunt, Alistair and Cimato, Federica},
	month = sep,
	year = {2020},
	file = {Watkiss et al. - The Socio-Economic Benefits of the HIGHWAY project.pdf:/Users/bobbyantonio/Zotero/storage/8KJ356RN/Watkiss et al. - The Socio-Economic Benefits of the HIGHWAY project.pdf:application/pdf},
}

@article{harris_multiscale_2001,
	title = {Multiscale {Statistical} {Properties} of a {High}-{Resolution} {Precipitation} {Forecast}},
	volume = {2},
	issn = {1525-7541, 1525-755X},
	url = {https://journals.ametsoc.org/view/journals/hydr/2/4/1525-7541_2001_002_0406_mspoah_2_0_co_2.xml},
	doi = {10.1175/1525-7541(2001)002<0406:MSPOAH>2.0.CO;2},
	abstract = {Abstract Small-scale (less than ∼15 km) precipitation variability significantly affects the hydrologic response of a basin and the accurate estimation of water and energy fluxes through coupled land–atmosphere modeling schemes. It also affects the radiative transfer through precipitating clouds and thus rainfall estimation from microwave sensors. Because both land–atmosphere and cloud–radiation interactions are nonlinear and occur over a broad range of scales (from a few centimeters to several kilometers), it is important that, over these scales, cloud-resolving numerical models realistically reproduce the observed precipitation variability. This issue is examined herein by using a suite of multiscale statistical methods to compare the scale dependence of precipitation variability of a numerically simulated convective storm with that observed by radar. In particular, Fourier spectrum, structure function, and moment-scale analyses are used to show that, although the variability of modeled precipitation agrees with that observed for scales larger than approximately 5 times the model resolution, the model shows a falloff in variability at smaller scales. Thus, depending upon the smallest scale at which variability is considered to be important for a specific application, one has to resort either to very high resolution model runs (resolutions 5 times higher than the scale of interest) or to stochastic methods that can introduce the missing small-scale variability. The latter involve upscaling the model output to a scale approximately 5 times the model resolution and then stochastically downscaling it to smaller scales. The results of multiscale analyses, such as those presented herein, are key to the implementation of such stochastic downscaling methodologies.},
	language = {EN},
	number = {4},
	urldate = {2023-08-03},
	journal = {Journal of Hydrometeorology},
	author = {Harris, Daniel and Foufoula-Georgiou, Efi and Droegemeier, Kelvin K. and Levit, Jason J.},
	month = aug,
	year = {2001},
	note = {Publisher: American Meteorological Society
Section: Journal of Hydrometeorology},
	pages = {406--418},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/RZHUQLMH/Harris et al. - 2001 - Multiscale Statistical Properties of a High-Resolu.pdf:application/pdf},
}

@article{sinclair_empirical_2005,
	title = {Empirical {Mode} {Decomposition} in 2-{D} space and time: a tool for space-time rainfall analysis and nowcasting},
	volume = {9},
	issn = {1027-5606},
	shorttitle = {Empirical {Mode} {Decomposition} in 2-{D} space and time},
	url = {https://hess.copernicus.org/articles/9/127/2005/},
	doi = {10.5194/hess-9-127-2005},
	abstract = {A data-driven method for extracting temporally persistent information, at different spatial scales, from rainfall data (as measured by radar/satellite) is described, which extends the Empirical Mode Decomposition (EMD) algorithm into two dimensions. The EMD technique is used here to decompose spatial rainfall data into a sequence of high through to low frequency components. This process is equivalent to the application of successive low-pass spatial filters, but based on the observed properties of the data rather than the predetermined basis functions used in traditional Fourier or Wavelet decompositions. It has been suggested in the literature that the lower frequency components (those with large spatial extent) of spatial rainfall data exhibit greater temporal persistence than the higher frequency ones. This idea is explored here in the context of Empirical Mode Decomposition. The paper focuses on the implementation and development of the two-dimensional extension to the EMD algorithm and it's application to radar rainfall data, as well as examining temporal persistence in the data at different spatial scales.},
	language = {English},
	number = {3},
	urldate = {2023-08-03},
	journal = {Hydrology and Earth System Sciences},
	author = {Sinclair, S. and Pegram, G. G. S.},
	month = jul,
	year = {2005},
	note = {Publisher: Copernicus GmbH},
	pages = {127--137},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/Y8I5CCQU/Sinclair and Pegram - 2005 - Empirical Mode Decomposition in 2-D space and time.pdf:application/pdf},
}

@article{gebremeskel_haile_droughts_2019,
	title = {Droughts in {East} {Africa}: {Causes}, impacts and resilience},
	volume = {193},
	issn = {0012-8252},
	shorttitle = {Droughts in {East} {Africa}},
	url = {https://www.sciencedirect.com/science/article/pii/S0012825218303519},
	doi = {10.1016/j.earscirev.2019.04.015},
	abstract = {East Africa (EA) has been the primary focus for various drought studies in recent years. However, a comprehensive analysis of droughts, including their evolution, complexity, social implications and people's vulnerability is currently lacking. Hence, there is a pressing need for an overview of drought studies in EA. Here, we present a state-of-the-art review of the causes and impacts of, and resilience to droughts in EA. Studies reveal that droughts tend to be more frequent, longer and more severe in the boreal spring and summer in EA, as the overall precipitation and water storage abruptly decline. A decrease in drought frequency is observed during the boreal autumn season (October–November). As these studies have only been analysed within the context of sparse and short-term regional climate data with very complex spatial and seasonal climate patterns, they are subject to uncertainties. The main causes for the changing pattern of droughts include climate variabilities and anthropogenic effects. Droughts have extensive impacts on human beings, environment, water resources and agriculture. Environmental rehabilitation involving the development of ecosystem services, biodiversity enhancement and soil and water conservation is found to be a suitable strategy to adapt to drought conditions. A better understanding of the causes and impacts of droughts, participatory management and community level actions are essential for building resilience to drought. Strong citizens–government–stakeholder cooperation is also valuable in monitoring and managing drought. The knowledge and insights gained from this review will help the countries in EA to build a drought-resilient society and will form a basis of information for other regions outside of EA.},
	language = {en},
	urldate = {2023-08-03},
	journal = {Earth-Science Reviews},
	author = {Gebremeskel Haile, Gebremedhin and Tang, Qiuhong and Sun, Siao and Huang, Zhongwei and Zhang, Xuejun and Liu, Xingcai},
	month = jun,
	year = {2019},
	keywords = {Rainfall, East Africa, Anthropogenic activities, Climate variability, Drought, Horn of Africa},
	pages = {146--161},
	file = {ScienceDirect Snapshot:/Users/bobbyantonio/Zotero/storage/KF9EKS76/S0012825218303519.html:text/html},
}

@article{luhunga_analysis_2020,
	title = {Analysis of {Climate} {Change} and {Extreme} {Climatic} {Events} in the {Lake} {Victoria} {Region} of {Tanzania}},
	volume = {2},
	issn = {2624-9553},
	url = {https://www.frontiersin.org/articles/10.3389/fclim.2020.559584},
	abstract = {The understanding of climate change impacts and the associated climate extreme events at regional and local scales is of critical importance for planning and development of feasible adaptation strategies. In this paper, we present an analysis of climate change and extreme climate events in the Lake Victoria region of Tanzania, focusing on the Kagera and Geita regions. We use daily simulated climate variables (rainfall and minimum and maximum temperatures) from the Coordinated Regional Climate Downscaling Experiment Program Regional Climate Models (CORDEX\_RCMs) for the analysis. Extreme climate event, rainfall, and minimum and maximum temperatures time series during historical (1971–2000) climate condition are compared to future climate projection (2011–2100) under two Representative Concentration Pathway (RCP): RCP 4.5 and RCP 8.5 emission scenarios. The existence, magnitude, and statistical significance of potential trends in climate data time series are estimated using the Mann–Kendall (MK) non-parametric test and Theil-SEN slope estimator methods. Results show that during historical (1971–2000) climate, the Lake Victoria region of Tanzania experienced a statistically significant increasing trend in temperature. The annual minimum and maximum temperatures in the Kagera and Geita regions have increased by 0.54–0.69°C, and 0.51–0.69°C, respectively. The numbers of warm days (TX90p) and warm nights (TN90p) during the historical climate have increased, while the numbers of cold days (TX10p) and cold nights (TN10p) have decreased significantly. However, in future climate condition (2011–2100) under both RCP 4.5 and RCP 8.5 emission scenarios, the Lake Victoria region is likely to experience increased temperatures and rainfall. The frequency of cold events (cold days and cold nights) is likely to decrease, while the frequency of warm events (warm days and warm nights) is likely to increase significantly. The number of consecutive wet days, the intensity of very wet days, and the number of extreme wet days are likely to increase. These results indicate that in future climate condition, socioeconomic livelihoods of people in the Kagera and Geita regions are likely to experience significant challenges from climate-related stresses. It is, therefore, recommended that appropriate planning and effective adaptation policies are in place for disaster risk prevention.},
	urldate = {2023-08-02},
	journal = {Frontiers in Climate},
	author = {Luhunga, Philbert Modest and Songoro, Alexander Elias},
	year = {2020},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/V2FNC3EP/Luhunga and Songoro - 2020 - Analysis of Climate Change and Extreme Climatic Ev.pdf:application/pdf},
}

@misc{wang_esrgan_2018,
	title = {{ESRGAN}: {Enhanced} {Super}-{Resolution} {Generative} {Adversarial} {Networks}},
	shorttitle = {{ESRGAN}},
	url = {http://arxiv.org/abs/1809.00219},
	abstract = {The Super-Resolution Generative Adversarial Network (SRGAN) is a seminal work that is capable of generating realistic textures during single image super-resolution. However, the hallucinated details are often accompanied with unpleasant artifacts. To further enhance the visual quality, we thoroughly study three key components of SRGAN - network architecture, adversarial loss and perceptual loss, and improve each of them to derive an Enhanced SRGAN (ESRGAN). In particular, we introduce the Residual-in-Residual Dense Block (RRDB) without batch normalization as the basic network building unit. Moreover, we borrow the idea from relativistic GAN to let the discriminator predict relative realness instead of the absolute value. Finally, we improve the perceptual loss by using the features before activation, which could provide stronger supervision for brightness consistency and texture recovery. Benefiting from these improvements, the proposed ESRGAN achieves consistently better visual quality with more realistic and natural textures than SRGAN and won the first place in the PIRM2018-SR Challenge. The code is available at https://github.com/xinntao/ESRGAN .},
	urldate = {2023-08-02},
	publisher = {arXiv},
	author = {Wang, Xintao and Yu, Ke and Wu, Shixiang and Gu, Jinjin and Liu, Yihao and Dong, Chao and Loy, Chen Change and Qiao, Yu and Tang, Xiaoou},
	month = sep,
	year = {2018},
	note = {arXiv:1809.00219 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: To appear in ECCV 2018 workshop. Won Region 3 in the PIRM2018-SR Challenge. Code and models are at https://github.com/xinntao/ESRGAN},
	file = {arXiv.org Snapshot:/Users/bobbyantonio/Zotero/storage/5VHRBTFM/1809.html:text/html;Full Text PDF:/Users/bobbyantonio/Zotero/storage/8TV3BCPH/Wang et al. - 2018 - ESRGAN Enhanced Super-Resolution Generative Adver.pdf:application/pdf},
}

@article{kashinath_physics-informed_2021-1,
	title = {Physics-informed machine learning: case studies for weather and climate modelling},
	volume = {379},
	shorttitle = {Physics-informed machine learning},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2020.0093},
	doi = {10.1098/rsta.2020.0093},
	abstract = {Machine learning (ML) provides novel and powerful ways of accurately and efficiently recognizing complex patterns, emulating nonlinear dynamics, and predicting the spatio-temporal evolution of weather and climate processes. Off-the-shelf ML models, however, do not necessarily obey the fundamental governing laws of physical systems, nor do they generalize well to scenarios on which they have not been trained. We survey systematic approaches to incorporating physics and domain knowledge into ML models and distill these approaches into broad categories. Through 10 case studies, we show how these approaches have been used successfully for emulating, downscaling, and forecasting weather and climate processes. The accomplishments of these studies include greater physical consistency, reduced training time, improved data efficiency, and better generalization. Finally, we synthesize the lessons learned and identify scientific, diagnostic, computational, and resource challenges for developing truly robust and reliable physics-informed ML models for weather and climate processes.

This article is part of the theme issue ‘Machine learning for weather and climate modelling’.},
	number = {2194},
	urldate = {2023-08-02},
	journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Kashinath, K. and Mustafa, M. and Albert, A. and Wu, J-L. and Jiang, C. and Esmaeilzadeh, S. and Azizzadenesheli, K. and Wang, R. and Chattopadhyay, A. and Singh, A. and Manepalli, A. and Chirila, D. and Yu, R. and Walters, R. and White, B. and Xiao, H. and Tchelepi, H. A. and Marcus, P. and Anandkumar, A. and Hassanzadeh, P. and Prabhat, null},
	month = feb,
	year = {2021},
	note = {Publisher: Royal Society},
	keywords = {neural networks, physical constraints, physics-informed machine learning, turbulent flows, weather and climate modeling},
	pages = {20200093},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/B2TW4P7S/Kashinath et al. - 2021 - Physics-informed machine learning case studies fo.pdf:application/pdf},
}

@article{giorgi_regional_2015,
	title = {Regional {Dynamical} {Downscaling} and the {CORDEX} {Initiative}},
	volume = {40},
	url = {https://doi.org/10.1146/annurev-environ-102014-021217},
	doi = {10.1146/annurev-environ-102014-021217},
	abstract = {We review the challenges and future perspectives of regional climate model (RCM), or dynamical downscaling, activities. Among the main technical issues in need of better understanding are those of selection and sensitivity to the model domain and resolution, techniques for providing lateral boundary conditions, and RCM internal variability. The added value (AV) obtained with the use of RCMs remains a central issue, which needs more rigorous and comprehensive analysis strategies. Within the context of regional climate projections, large ensembles of simulations are needed to better understand the models and characterize uncertainties. This has provided an impetus for the development of the Coordinated Regional Downscaling Experiment (CORDEX), the first international program offering a common protocol for downscaling experiments, and we discuss how CORDEX can address the key scientific challenges in downscaling research. Among the main future developments in RCM research, we highlight the development of coupled regional Earth system models and the transition to very high-resolution, cloud-resolving models.},
	number = {1},
	urldate = {2023-07-31},
	journal = {Annual Review of Environment and Resources},
	author = {Giorgi, Filippo and Gutowski, William J.},
	year = {2015},
	note = {\_eprint: https://doi.org/10.1146/annurev-environ-102014-021217},
	keywords = {regional climate, climate change, CORDEX, downscaling added value, dynamical downscaling, high-resolution modeling, model evaluation, RCM, regional climate modeling, regional Earth system modeling},
	pages = {467--490},
}

@article{eyring_overview_2016,
	title = {Overview of the {Coupled} {Model} {Intercomparison} {Project} {Phase} 6 ({CMIP6}) experimental design and organization},
	volume = {9},
	issn = {1991-959X},
	url = {https://gmd.copernicus.org/articles/9/1937/2016/},
	doi = {10.5194/gmd-9-1937-2016},
	abstract = {By coordinating the design and distribution of global climate model simulations of the past, current, and future climate, the Coupled Model Intercomparison Project (CMIP) has become one of the foundational elements of climate science. However, the need to address an ever-expanding range of scientific questions arising from more and more research communities has made it necessary to revise the organization of CMIP. After a long and wide community consultation, a new and more federated structure has been put in place. It consists of three major elements: (1) a handful of common experiments, the DECK (Diagnostic, Evaluation and Characterization of Klima) and CMIP historical simulations (1850–near present) that will maintain continuity and help document basic characteristics of models across different phases of CMIP; (2) common standards, coordination, infrastructure, and documentation that will facilitate the distribution of model outputs and the characterization of the model ensemble; and (3) an ensemble of CMIP-Endorsed Model Intercomparison Projects (MIPs) that will be specific to a particular phase of CMIP (now CMIP6) and that will build on the DECK and CMIP historical simulations to address a large range of specific questions and fill the scientific gaps of the previous CMIP phases. The DECK and CMIP historical simulations, together with the use of CMIP data standards, will be the entry cards for models participating in CMIP. Participation in CMIP6-Endorsed MIPs by individual modelling groups will be at their own discretion and will depend on their scientific interests and priorities. With the Grand Science Challenges of the World Climate Research Programme (WCRP) as its scientific backdrop, CMIP6 will address three broad questions: 

 \&ndash; How does the Earth system respond to forcing?

 \&ndash; What are the origins and consequences of systematic model biases? 

 \&ndash; How can we assess future climate changes given internal climate variability, predictability, and uncertainties in scenarios?

 This CMIP6 overview paper presents the background and rationale for the new structure of CMIP, provides a detailed description of the DECK and CMIP6 historical simulations, and includes a brief introduction to the 21 CMIP6-Endorsed MIPs.},
	language = {English},
	number = {5},
	urldate = {2023-07-31},
	journal = {Geoscientific Model Development},
	author = {Eyring, Veronika and Bony, Sandrine and Meehl, Gerald A. and Senior, Catherine A. and Stevens, Bjorn and Stouffer, Ronald J. and Taylor, Karl E.},
	month = may,
	year = {2016},
	note = {Publisher: Copernicus GmbH},
	pages = {1937--1958},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/DY65ZJJF/Eyring et al. - 2016 - Overview of the Coupled Model Intercomparison Proj.pdf:application/pdf},
}

@article{luhunga_analysis_2020-1,
	title = {Analysis of {Climate} {Change} and {Extreme} {Climatic} {Events} in the {Lake} {Victoria} {Region} of {Tanzania}},
	volume = {2},
	issn = {2624-9553},
	url = {https://www.frontiersin.org/articles/10.3389/fclim.2020.559584},
	abstract = {The understanding of climate change impacts and the associated climate extreme events at regional and local scales is of critical importance for planning and development of feasible adaptation strategies. In this paper, we present an analysis of climate change and extreme climate events in the Lake Victoria region of Tanzania, focusing on the Kagera and Geita regions. We use daily simulated climate variables (rainfall and minimum and maximum temperatures) from the Coordinated Regional Climate Downscaling Experiment Program Regional Climate Models (CORDEX\_RCMs) for the analysis. Extreme climate event, rainfall, and minimum and maximum temperatures time series during historical (1971–2000) climate condition are compared to future climate projection (2011–2100) under two Representative Concentration Pathway (RCP): RCP 4.5 and RCP 8.5 emission scenarios. The existence, magnitude, and statistical significance of potential trends in climate data time series are estimated using the Mann–Kendall (MK) non-parametric test and Theil-SEN slope estimator methods. Results show that during historical (1971–2000) climate, the Lake Victoria region of Tanzania experienced a statistically significant increasing trend in temperature. The annual minimum and maximum temperatures in the Kagera and Geita regions have increased by 0.54–0.69°C, and 0.51–0.69°C, respectively. The numbers of warm days (TX90p) and warm nights (TN90p) during the historical climate have increased, while the numbers of cold days (TX10p) and cold nights (TN10p) have decreased significantly. However, in future climate condition (2011–2100) under both RCP 4.5 and RCP 8.5 emission scenarios, the Lake Victoria region is likely to experience increased temperatures and rainfall. The frequency of cold events (cold days and cold nights) is likely to decrease, while the frequency of warm events (warm days and warm nights) is likely to increase significantly. The number of consecutive wet days, the intensity of very wet days, and the number of extreme wet days are likely to increase. These results indicate that in future climate condition, socioeconomic livelihoods of people in the Kagera and Geita regions are likely to experience significant challenges from climate-related stresses. It is, therefore, recommended that appropriate planning and effective adaptation policies are in place for disaster risk prevention.},
	urldate = {2023-07-31},
	journal = {Frontiers in Climate},
	author = {Luhunga, Philbert Modest and Songoro, Alexander Elias},
	year = {2020},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/J8ZLX7LP/Luhunga and Songoro - 2020 - Analysis of Climate Change and Extreme Climatic Ev.pdf:application/pdf},
}

@article{dosio_projected_2021,
	title = {Projected future daily characteristics of {African} precipitation based on global ({CMIP5}, {CMIP6}) and regional ({CORDEX}, {CORDEX}-{CORE}) climate models},
	volume = {57},
	issn = {1432-0894},
	url = {https://doi.org/10.1007/s00382-021-05859-w},
	doi = {10.1007/s00382-021-05859-w},
	abstract = {We provide an assessment of future daily characteristics of African precipitation by explicitly comparing the results of large ensembles of global (CMIP5, CMIP6) and regional (CORDEX, CORE) climate models, specifically highlighting the similarities and inconsistencies between them. Results for seasonal mean precipitation are not always consistent amongst ensembles: in particular, global models tend to project a wetter future compared to regional models, especially over the Eastern Sahel, Central and East Africa. However, results for other precipitation characteristics are more consistent. In general, all ensembles project an increase in maximum precipitation intensity during the wet season over all regions and emission scenarios (except the West Sahel for CORE) and a decrease in precipitation frequency (under the Representative Concentration Pathways RCP8.5) especially over the West Sahel, the Atlas region, southern central Africa, East Africa and southern Africa. Depending on the season, the length of dry spells is projected to increase consistently by all ensembles and for most (if not all) models over southern Africa, the Ethiopian highlands and the Atlas region. Discrepancies exist between global and regional models on the projected change in precipitation characteristics over specific regions and seasons. For instance, over the Eastern Sahel in July–August most global models show an increase in precipitation frequency but regional models project a robust decrease. Global and regional models also project an opposite sign in the change of the length of dry spells. CORE results show a marked drying over the regions affected by the West Africa monsoon throughout the year, accompanied by a decrease in mean precipitation intensity between May and July that is not present in the other ensembles. This enhanced drying may be related to specific physical mechanisms that are better resolved by the higher resolution models and highlights the importance of a process-based evaluation of the mechanisms controlling precipitation over the region.},
	language = {en},
	number = {11},
	urldate = {2023-07-31},
	journal = {Climate Dynamics},
	author = {Dosio, Alessandro and Jury, Martin W. and Almazroui, Mansour and Ashfaq, Moetasim and Diallo, Ismaila and Engelbrecht, Francois A. and Klutse, Nana A. B. and Lennard, Christopher and Pinto, Izidine and Sylla, Mouhamadou B. and Tamoffo, Alain T.},
	month = dec,
	year = {2021},
	pages = {3135--3158},
	file = {Dosio et al. - 2021 - Projected future daily characteristics of African .pdf:/Users/bobbyantonio/Zotero/storage/5KTR35K4/Dosio et al. - 2021 - Projected future daily characteristics of African .pdf:application/pdf;Full Text PDF:/Users/bobbyantonio/Zotero/storage/GY2ASAU8/Dosio et al. - 2021 - Projected future daily characteristics of African .pdf:application/pdf},
}

@article{mbigi_coupled_2022,
	title = {Coupled {Model} {Intercomparison} {Project} {Phase} 6 simulations of the spatial structure of rainfall variability over {East} {Africa}: {Evaluation} and projection},
	volume = {42},
	copyright = {© 2022 Royal Meteorological Society},
	issn = {1097-0088},
	shorttitle = {Coupled {Model} {Intercomparison} {Project} {Phase} 6 simulations of the spatial structure of rainfall variability over {East} {Africa}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/joc.7868},
	doi = {10.1002/joc.7868},
	abstract = {Modifications in rainfall patterns may have significant effects on a variety of natural and human systems. This study evaluates the ability of 20 Coupled Model Intercomparison Project Phase 6 (CMIP6) to simulate the interannual variability of rainfall over East Africa (EA) using a method based on the empirical orthogonal function (EOF) analysis. The future changes in rainfall variability during the near (2021–2040), middle (2041–2060) and late (2080–2099) future are analysed under two different shared socioeconomic pathways (SSP), SSP2-4.5 and SSP5-8.5. Results reveal that most models captured better spatial climatological rainfall pattern than simulated amplitude in the EA region receiving bimodal rainfall pattern (EABM) compared to that with unimodal rainfall regime (EAUM) in the historical period. An ensemble mean of all models (AMME) and a set of 13 models that best simulated the rainfall variability in the base period were selected using a robust method based on the EOF analysis for further analysis. Most of the selected models and their ensemble mean (BMME) displayed good capability in representing the annual standard deviation (SD) in recent decades, whereas BMME corroborates AMME, particularly over the EABM and EAUM regions. Based on these findings, the AMME and BMME were used to evaluate the future changes in rainfall variability. The models project a significant increase in rainfall variability during March by the mid and late 21st century over the EAUM region under SSP5-8.5, whereas the increase appears much earlier in the near-future over the EABM region. In all future periods and SSPs, SD demonstrates a considerable increase over most of the EABM region, and the magnitude gradually increases from the AMME to BMME projections. Moreover, a relatively stronger increase is anticipated to actualize by the mid of 21st century.},
	language = {en},
	number = {16},
	urldate = {2023-07-31},
	journal = {International Journal of Climatology},
	author = {Mbigi, Dickson and Onyango, Augustine Omondi and Mtewele, Zacharia Florence and Kiprotich, Paul and Xiao, Ziniu},
	year = {2022},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/joc.7868},
	keywords = {East Africa, CMIP6, empirical orthogonal function, rainfall variability},
	pages = {9865--9885},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/SQN9VWUK/Mbigi et al. - 2022 - Coupled Model Intercomparison Project Phase 6 simu.pdf:application/pdf;Snapshot:/Users/bobbyantonio/Zotero/storage/U9YP9CEB/joc.html:text/html},
}

@article{ngoma_projected_2022,
	title = {Projected changes in rainfall over {Uganda} based on {CMIP6} models},
	volume = {149},
	issn = {1434-4483},
	url = {https://doi.org/10.1007/s00704-022-04106-4},
	doi = {10.1007/s00704-022-04106-4},
	abstract = {Information about likely future patterns of climate variables is important in climate change mitigation and adaptation efforts. This study investigates future (2021–2100) changes in rainfall based on CMIP6 datasets over Uganda. The projection period is divided into two sub-periods: 2021–2060 (near future) and 2061–2100 (far future), relative to the baseline period (1985–2014). Two emission scenarios: SSP2-4.5 and SSP5-8.5, are considered. The results reveal a larger decrease (increase) in rainfall during March–April (November–December) under both SSPs. Moreover, an enhanced decline (increase) is projected under SSP2-4.5 (SSP5-8.5). The spatial distribution of future changes in seasonal rainfall reveals a decrease in MAM rainfall in the near future over most parts of the country under both emission scenarios. However, a recovery is exhibited towards the end of the century with more increase in the south-western parts of the country, and a higher magnitude under SSP5-8.5. In contrast, SON rainfall reveals wetter conditions during both timelines and emission scenarios. Maximum (minimum) wet conditions are expected in the north-western parts of the country (around the Lake Victoria basin). The linear trend analysis shows a non-significant (z =  − 0.714) decreasing trend for MAM rainfall during the historical period. This pattern is reflected in the near future with z-scores of − 0.757 and − 1.281 under SSP2-4.5 and SSP5-8.5, respectively. However, a significant increase for MAM and annual rainfall (z-scores of 2.785 and 3.46, respectively) is projected towards the end of the century under SSP5-8.5. These findings provide guidance to policy makers in devising appropriate adaptation measures to cope with expected changes in the local climate. Given the increase in intensity and frequency of extreme rainfall over the study region, future work should focus on examining projected changes in rainfall extremes under different global warming scenarios with consideration of model performance and independence.},
	language = {en},
	number = {3},
	urldate = {2023-07-31},
	journal = {Theoretical and Applied Climatology},
	author = {Ngoma, Hamida and Ayugi, Brian and Onyutha, Charles and Babaousmail, Hassen and Lim Kam Sian, Kenny T. C. and Iyakaremye, Vedaste and Mumo, Richard and Ongoma, Victor},
	month = aug,
	year = {2022},
	pages = {1117--1134},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/3MRMAWZU/Ngoma et al. - 2022 - Projected changes in rainfall over Uganda based on.pdf:application/pdf},
}

@article{ayugi_east_2022,
	title = {East {African} population exposure to precipitation extremes under 1.5 °{C} and 2.0 °{C} warming levels based on {CMIP6} models},
	volume = {17},
	issn = {1748-9326},
	url = {https://dx.doi.org/10.1088/1748-9326/ac5d9d},
	doi = {10.1088/1748-9326/ac5d9d},
	abstract = {Understanding population exposure to precipitation-related extreme events is important for effective climate change adaptation and mitigation measures. We analyze extreme precipitation using indices (EPIs), including consecutive dry days (CDD), annual total precipitation, simple daily intensity, and the number of extremely wet days, under the past and future climatic conditions over East Africa. The exposure of the East African population to these extreme events at 1.5 °C and 2.0 °C global warming levels (GWLs) is analyzed based on Climate Model Intercomparison Project phase 6 models. Exposure is computed from extremely wet and dry days (R95p and CDD, respectively). Under both GWLs, EPIs (except CDD) averaged over East Africa are projected to increase under the Shared Socio-economic Pathways (SSP)2-4.5 and SSP5-8.5 scenarios. The largest increase in wet events will likely occur in eastern and northern Kenya. The results also reveal an intensification of precipitation extremes over Burundi, Rwanda, and some parts of Uganda. However, small changes are expected over most parts of Kenya and Tanzania. Examination of population exposure to EPIs shows that the most prominent and net intense occurrence is over Burundi, Rwanda, and some parts of Uganda. In contrast, less change is noted to occur over vast parts of Kenya and Tanzania. Meanwhile, limiting the warming target to less than 1.5 °C but not more than 2.0 °C has 37\% (44.2\%) and 92\% (4\%) less impact on the occurrence of EPIs for R95p (CDD) under SSP2-4.5 (SSP5-8.5) scenarios, respectively. The study establishes that future exposure is predominantly driven by changes in population compared to other factors such as climate or concurrent changes in climate and population (the nonlinear interaction effect). For instance, climate effects are anticipated to contribute ∼10.6\% (12.6\%) of the total change in population exposure under 1.5 °C (2.0 °C) warming levels, while population and interaction effects are expected to contribute ∼77.4\% (71.9\%) and 12\% (15.5\%), respectively, under 1.5 °C (2.0 °C) scenarios. Interestingly, the projected changes in regional exposure due to the interaction effects under SSP2-4.5 are greater than the climate effect, while the reverse pattern is observed under SSP5-8.5. For example, under SSP5-8.5, climate effects for 1.5 °C and 2.0 °C are larger (after population effect) with ∼3.8 × 105 (15.7\%) and ∼6.1 × 105 (17.5\%) billion person-mm, respectively. The high exposure noted over East Africa calls for a shift in policies to instate suitable adaptation measures to cushion the already vulnerable population.},
	language = {en},
	number = {4},
	urldate = {2023-07-31},
	journal = {Environmental Research Letters},
	author = {Ayugi, Brian and Jiang, Zhihong and Iyakaremye, Vedaste and Ngoma, Hamida and Babaousmail, Hassen and Onyutha, Charles and Dike, Victor Nnamdi and Mumo, Richard and Ongoma, Victor},
	month = mar,
	year = {2022},
	note = {Publisher: IOP Publishing},
	pages = {044051},
	file = {IOP Full Text PDF:/Users/bobbyantonio/Zotero/storage/ZUCREY4W/Ayugi et al. - 2022 - East African population exposure to precipitation .pdf:application/pdf},
}

@article{ayugi_future_2021,
	title = {Future {Changes} in {Precipitation} {Extremes} over {East} {Africa} {Based} on {CMIP6} {Models}},
	volume = {13},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2073-4441},
	url = {https://www.mdpi.com/2073-4441/13/17/2358},
	doi = {10.3390/w13172358},
	abstract = {This paper presents an analysis of projected precipitation extremes over the East African region. The study employs six indices defined by the Expert Team on Climate Change Detection Indices to evaluate extreme precipitation. Observed datasets and Coupled Model Intercomparison Project Phase six (CMIP6) simulations are employed to assess the changes during the two main rainfall seasons: March to May (MAM) and October to December (OND). The results show an increase in consecutive dry days (CDD) and decrease in consecutive wet days (CWD) towards the end of the 21st century (2081–2100) relative to the baseline period (1995–2014) in both seasons. Moreover, simple daily intensity (SDII), very wet days (R95 p), very heavy precipitation {\textgreater}20 mm (R20 mm), and total wet-day precipitation (PRCPTOT) demonstrate significant changes during OND compared to the MAM season. The spatial variation for extreme incidences shows likely intensification over Uganda and most parts of Kenya, while a reduction is observed over the Tanzania region. The increase in projected extremes may pose a serious threat to the sustainability of societal infrastructure and ecosystem wellbeing. The results from these analyses present an opportunity to understand the emergence of extreme events and the capability of model outputs from CMIP6 in estimating the projected changes. More studies are recommended to examine the underlying physical features modulating the occurrence of extreme incidences projected for relevant policies.},
	language = {en},
	number = {17},
	urldate = {2023-07-31},
	journal = {Water},
	author = {Ayugi, Brian and Dike, Victor and Ngoma, Hamida and Babaousmail, Hassen and Mumo, Richard and Ongoma, Victor},
	month = jan,
	year = {2021},
	note = {Number: 17
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {East Africa, CMIP6, extreme precipitation, projections, scenarios},
	pages = {2358},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/8SCEL7J6/Ayugi et al. - 2021 - Future Changes in Precipitation Extremes over East.pdf:application/pdf},
}

@article{thiery_impact_2015,
	title = {The {Impact} of the {African} {Great} {Lakes} on the {Regional} {Climate}},
	volume = {28},
	issn = {0894-8755, 1520-0442},
	url = {https://journals.ametsoc.org/view/journals/clim/28/10/jcli-d-14-00565.1.xml},
	doi = {10.1175/JCLI-D-14-00565.1},
	abstract = {Abstract Although the African Great Lakes are important regulators for the East African climate, their influence on atmospheric dynamics and the regional hydrological cycle remains poorly understood. This study aims to assess this impact by comparing a regional climate model simulation that resolves individual lakes and explicitly computes lake temperatures to a simulation without lakes. The Consortium for Small-Scale Modelling model in climate mode (COSMO-CLM) coupled to the Freshwater Lake model (FLake) and Community Land Model (CLM) is used to dynamically downscale a simulation from the African Coordinated Regional Downscaling Experiment (CORDEX-Africa) to 7-km grid spacing for the period of 1999–2008. Evaluation of the model reveals good performance compared to both in situ and satellite observations, especially for spatiotemporal variability of lake surface temperatures (0.68-K bias), and precipitation (−116 mm yr−1 or 8\% bias). Model integrations indicate that the four major African Great Lakes almost double the annual precipitation amounts over their surface but hardly exert any influence on precipitation beyond their shores. Except for Lake Kivu, the largest lakes also cool the annual near-surface air by −0.6 to −0.9 K on average, this time with pronounced downwind influence. The lake-induced cooling happens during daytime, when the lakes absorb incoming solar radiation and inhibit upward turbulent heat transport. At night, when this heat is released, the lakes warm the near-surface air. Furthermore, Lake Victoria has a profound influence on atmospheric dynamics and stability, as it induces circular airflow with over-lake convective inhibition during daytime and the reversed pattern at night. Overall, this study shows the added value of resolving individual lakes and realistically representing lake surface temperatures for climate studies in this region.},
	language = {EN},
	number = {10},
	urldate = {2023-07-31},
	journal = {Journal of Climate},
	author = {Thiery, Wim and Davin, Edouard L. and Panitz, Hans-Jürgen and Demuzere, Matthias and Lhermitte, Stef and Lipzig, Nicole van},
	month = may,
	year = {2015},
	note = {Publisher: American Meteorological Society
Section: Journal of Climate},
	pages = {4061--4085},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/QH58KJQ9/Thiery et al. - 2015 - The Impact of the African Great Lakes on the Regio.pdf:application/pdf},
}

@misc{annau_algorithmic_2023,
	title = {Algorithmic {Hallucinations} of {Near}-{Surface} {Winds}: {Statistical} {Downscaling} with {Generative} {Adversarial} {Networks} to {Convection}-{Permitting} {Scales}},
	shorttitle = {Algorithmic {Hallucinations} of {Near}-{Surface} {Winds}},
	url = {http://arxiv.org/abs/2302.08720},
	abstract = {This paper explores the application of emerging machine learning methods from image super-resolution (SR) to the task of statistical downscaling. We specifically focus on convolutional neural network-based Generative Adversarial Networks (GANs). Our GANs are conditioned on low-resolution (LR) inputs to generate high-resolution (HR) surface winds emulating Weather Research and Forecasting (WRF) model simulations over North America. Unlike traditional SR models, where LR inputs are idealized coarsened versions of the HR images, WRF emulation involves using non-idealized LR and HR pairs resulting in shared-scale mismatches due to internal variability. Our study builds upon current SR-based statistical downscaling by experimenting with a novel frequency-separation (FS) approach from the computer vision field. To assess the skill of SR models, we carefully select evaluation metrics, and focus on performance measures based on spatial power spectra. Our analyses reveal how GAN configurations influence spatial structures in the generated fields, particularly biases in spatial variability spectra. Using power spectra to evaluate the FS experiments reveals that successful applications of FS in computer vision do not translate to climate fields. However, the FS experiments demonstrate the sensitivity of power spectra to a commonly used GAN-based SR objective function, which helps interpret and understand its role in determining spatial structures. This result motivates the development of a novel partial frequency-separation scheme as a promising configuration option. We also quantify the influence on GAN performance of non-idealized LR fields resulting from internal variability. Furthermore, we conduct a spectra-based feature-importance experiment allowing us to explore the dependence of the spatial structure of generated fields on different physically relevant LR covariates.},
	urldate = {2023-07-31},
	publisher = {arXiv},
	author = {Annau, Nicolaas J. and Cannon, Alex J. and Monahan, Adam H.},
	month = jul,
	year = {2023},
	note = {arXiv:2302.08720 [physics]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Physics - Atmospheric and Oceanic Physics},
	annote = {Comment: 43 pages, including 11 main figures, and 16 supplemental figures},
	file = {arXiv.org Snapshot:/Users/bobbyantonio/Zotero/storage/EXKFJXC4/2302.html:text/html;Full Text PDF:/Users/bobbyantonio/Zotero/storage/W7LYLVLX/Annau et al. - 2023 - Algorithmic Hallucinations of Near-Surface Winds .pdf:application/pdf},
}

@article{zipser_where_2006,
	title = {Where are the most intense thunderstorms on earth?},
	volume = {87},
	issn = {0003-0007, 1520-0477},
	url = {https://journals.ametsoc.org/view/journals/bams/87/8/bams-87-8-1057.xml},
	doi = {10.1175/BAMS-87-8-1057},
	abstract = {The instruments on the Tropical Rainfall Measuring Mission (TRMM) satellite have been observing storms as well as rainfall since December 1997. This paper shows the results of a systematic search through seven full years of the TRMM database to find indicators of uncommonly intense storms. These include strong ({\textgreater} 40 dBZ) radar echoes extending to great heights, high lightning flash rates, and very low brightness temperatures at 37 and 85 GHz. These are used as proxy variables, indicating powerful convective updrafts. The main physical principles supporting this assertion involve the effects of such updrafts in producing and lofting large ice particles high into the storm, where TRMM's radar easily detects them near storm top. TRMM's passive microwave radiometer detects the large integrated ice water path as very low brightness temperatures, while high lightning flash rates are a physically related but instrumentally independent indicator. The geographical locations of these very intense convective storms demonstrate strong regional preferences for certain land areas while they are extremely rare over tropical oceans. Favored locations include the south-central United States, southeast South America, and equatorial Africa. Other regions have extreme storms mainly in specific seasons, such as the Sahel, the Indian subcontinent, and northern Australia. Because intense storms are distributed quite differently from rainfall, these maps provide some new metrics for global models, if they are to simulate the type of convection as a component of our climate system.},
	language = {en},
	number = {8},
	urldate = {2023-07-27},
	journal = {Bulletin of the American Meteorological Society},
	author = {Zipser, E. J. and Cecil, Daniel J. and Liu, Chuntao and Nesbitt, Stephen W. and Yorty, David P.},
	month = aug,
	year = {2006},
	note = {Publisher: American Meteorological Society
Section: Bulletin of the American Meteorological Society},
	pages = {1057--1072},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/D8FFGX55/Zipser et al. - 2006 - WHERE ARE THE MOST INTENSE THUNDERSTORMS ON EARTH.pdf:application/pdf},
}

@article{thiery_early_2017,
	title = {Early warnings of hazardous thunderstorms over {Lake} {Victoria}},
	volume = {12},
	issn = {1748-9326},
	url = {https://dx.doi.org/10.1088/1748-9326/aa7521},
	doi = {10.1088/1748-9326/aa7521},
	abstract = {Weather extremes have harmful impacts on communities around Lake Victoria in East Africa. Every year, intense nighttime thunderstorms cause numerous boating accidents on the lake, resulting in thousands of deaths among fishermen. Operational storm warning systems are therefore crucial. Here we complement ongoing early warning efforts based on numerical weather prediction, by presenting a new satellite data-driven storm prediction system, the prototype Lake Victoria Intense storm Early Warning System (VIEWS). VIEWS derives predictability from the correlation between afternoon land storm activity and nighttime storm intensity on Lake Victoria, and relies on logistic regression techniques to forecast extreme thunderstorms from satellite observations. Evaluation of the statistical model reveals that predictive power is high and independent of the type of input dataset. We then optimise the configuration and show that false alarms also contain valuable information. Our results suggest that regression-based models that are motivated through process understanding have the potential to reduce the vulnerability of local fishing communities around Lake Victoria. The experimental prediction system is publicly available under the MIT licence at http://github.com/wthiery/VIEWS.},
	language = {en},
	number = {7},
	urldate = {2023-07-27},
	journal = {Environmental Research Letters},
	author = {Thiery, Wim and Gudmundsson, Lukas and Bedka, Kristopher and Semazzi, Fredrick H. M. and Lhermitte, Stef and Willems, Patrick and Lipzig, Nicole P. M. van and Seneviratne, Sonia I.},
	month = jul,
	year = {2017},
	note = {Publisher: IOP Publishing},
	pages = {074012},
	file = {Full Text:/Users/bobbyantonio/Zotero/storage/44XWISD4/Thiery et al. - 2017 - Early warnings of hazardous thunderstorms over Lak.pdf:application/pdf},
}

@article{thiery_hazardous_2016,
	title = {Hazardous thunderstorm intensification over {Lake} {Victoria}},
	volume = {7},
	copyright = {2016 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/ncomms12786},
	doi = {10.1038/ncomms12786},
	abstract = {Weather extremes have harmful impacts on communities around Lake Victoria, where thousands of fishermen die every year because of intense night-time thunderstorms. Yet how these thunderstorms will evolve in a future warmer climate is still unknown. Here we show that Lake Victoria is projected to be a hotspot of future extreme precipitation intensification by using new satellite-based observations, a high-resolution climate projection for the African Great Lakes and coarser-scale ensemble projections. Land precipitation on the previous day exerts a control on night-time occurrence of extremes on the lake by enhancing atmospheric convergence (74\%) and moisture availability (26\%). The future increase in extremes over Lake Victoria is about twice as large relative to surrounding land under a high-emission scenario, as only over-lake moisture advection is high enough to sustain Clausius–Clapeyron scaling. Our results highlight a major hazard associated with climate change over East Africa and underline the need for high-resolution projections to assess local climate change.},
	language = {en},
	number = {1},
	urldate = {2023-07-27},
	journal = {Nature Communications},
	author = {Thiery, Wim and Davin, Edouard L. and Seneviratne, Sonia I. and Bedka, Kristopher and Lhermitte, Stef and van Lipzig, Nicole P. M.},
	month = sep,
	year = {2016},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Climate and Earth system modelling, Projection and prediction, Atmospheric science},
	pages = {12786},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/AJU5MI86/Thiery et al. - 2016 - Hazardous thunderstorm intensification over Lake V.pdf:application/pdf},
}

@article{finney_implications_2019,
	title = {Implications of {Improved} {Representation} of {Convection} for the {East} {Africa} {Water} {Budget} {Using} a {Convection}-{Permitting} {Model}},
	volume = {32},
	issn = {0894-8755, 1520-0442},
	url = {https://journals.ametsoc.org/view/journals/clim/32/7/jcli-d-18-0387.1.xml},
	doi = {10.1175/JCLI-D-18-0387.1},
	abstract = {Abstract The precipitation and diabatic heating resulting from moist convection make it a key component of the atmospheric water budget in the tropics. With convective parameterization being a known source of uncertainty in global models, convection-permitting (CP) models are increasingly being used to improve understanding of regional climate. Here, a new 10-yr CP simulation is used to study the characteristics of rainfall and atmospheric water budget for East Africa and the Lake Victoria basin. The explicit representation of convection leads to a widespread improvement in the intensities and diurnal cycle of rainfall when compared with a parameterized simulation. Differences in large-scale moisture fluxes lead to a shift in the mean rainfall pattern from the Congo to Lake Victoria basin in the CP simulation—highlighting the important connection between local changes in the representation of convection and larger-scale dynamics and rainfall. Stronger lake–land contrasts in buoyancy in the CP model lead to a stronger nocturnal land breeze over Lake Victoria, increasing evaporation and moisture flux convergence (MFC), and likely unrealistically high rainfall. However, for the mountains east of the lake, the CP model produces a diurnal rainfall cycle much more similar to satellite estimates, which is related to differences in the timing of MFC. Results here demonstrate that, while care is needed regarding lake forcings, a CP approach offers a more realistic representation of several rainfall characteristics through a more physically based realization of the atmospheric dynamics around the complex topography of East Africa.},
	language = {EN},
	number = {7},
	urldate = {2023-07-27},
	journal = {Journal of Climate},
	author = {Finney, Declan L. and Marsham, John H. and Jackson, Lawrence S. and Kendon, Elizabeth J. and Rowell, David P. and Boorman, Penelope M. and Keane, Richard J. and Stratton, Rachel A. and Senior, Catherine A.},
	month = apr,
	year = {2019},
	note = {Publisher: American Meteorological Society
Section: Journal of Climate},
	pages = {2109--2129},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/5YFX992M/Finney et al. - 2019 - Implications of Improved Representation of Convect.pdf:application/pdf},
}

@article{noauthor_dynamics_nodate,
	title = {Dynamics of the {Lorenz}-96 model},
	language = {en},
	file = {Dynamics of the Lorenz-96 model.pdf:/Users/bobbyantonio/Zotero/storage/R2B3NHDB/Dynamics of the Lorenz-96 model.pdf:application/pdf},
}

@article{christensen_simulating_2015,
	title = {Simulating weather regimes: impact of stochastic and perturbed parameter schemes in a simple atmospheric model},
	volume = {44},
	issn = {1432-0894},
	shorttitle = {Simulating weather regimes},
	url = {https://doi.org/10.1007/s00382-014-2239-9},
	doi = {10.1007/s00382-014-2239-9},
	abstract = {Representing model uncertainty is important for both numerical weather and climate prediction. Stochastic parametrisation schemes are commonly used for this purpose in weather prediction, while perturbed parameter approaches are widely used in the climate community. The performance of these two representations of model uncertainty is considered in the context of the idealised Lorenz ’96 system, in terms of their ability to capture the observed regime behaviour of the system. These results are applicable to the atmosphere, where evidence points to the existence of persistent weather regimes, and where it is desirable that climate models capture this regime behaviour. The stochastic parametrisation schemes considerably improve the representation of regimes when compared to a deterministic model: both the structure and persistence of the regimes are found to improve. The stochastic parametrisation scheme represents the small scale variability present in the full system, which enables the system to explore a larger portion of the system’s attractor, improving the simulated regime behaviour. It is important that temporally correlated noise is used in the stochastic parametrisation—white noise schemes performed similarly to the deterministic model. In contrast, the perturbed parameter ensemble was unable to capture the regime structure of the attractor, with many individual members exploring only one regime. This poor performance was not evident in other climate diagnostics. Finally, a ‘climate change’ experiment was performed, where a change in external forcing resulted in changes to the regime structure of the attractor. The temporally correlated stochastic schemes captured these changes well.},
	language = {en},
	number = {7},
	urldate = {2023-07-26},
	journal = {Climate Dynamics},
	author = {Christensen, H. M. and Moroz, I. M. and Palmer, T. N.},
	month = apr,
	year = {2015},
	keywords = {Climate change, Lorenz ’96 system, Model uncertainty, Perturbed parameter schemes, Stochastic physics, Weather regimes},
	pages = {2195--2214},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/RPDEGSHI/Christensen et al. - 2015 - Simulating weather regimes impact of stochastic a.pdf:application/pdf},
}

@article{palmer_towards_2012,
	title = {Towards the probabilistic {Earth}-system simulator: a vision for the future of climate and weather prediction},
	volume = {138},
	issn = {1477-870X},
	shorttitle = {Towards the probabilistic {Earth}-system simulator},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/qj.1923},
	doi = {10.1002/qj.1923},
	abstract = {There is no more challenging problem in computational science than that of estimating, as accurately as science and technology allows, the future evolution of Earth's climate; nor indeed is there a problem whose solution has such importance and urgency. Historically, the simulation tools needed to predict climate have been developed, somewhat independently, at a number of weather and climate institutes around the world. While these simulators are individually deterministic, it is often assumed that the resulting diversity provides a useful quantification of uncertainty in global or regional predictions. However, this notion is not well founded theoretically and corresponding ‘multi-simulator’ estimates of uncertainty can be prone to systemic failure. Separate to this, individual institutes are now facing considerable challenges in finding the human and computational resources needed to develop more accurate weather and climate simulators with higher resolution and full Earth-system complexity. A new approach, originally designed to improve reliability in ensemble-based numerical weather prediction, is introduced to help solve these two rather different problems. Using stochastic mathematics, this approach recognizes uncertainty explicitly in the parametrized representation of unresolved climatic processes. Stochastic parametrization is shown to be more consistent with the underlying equations of motion and, moreover, provides more skilful estimates of uncertainty when compared with estimates from traditional multi-simulator ensembles, on time-scales where verification data exist. Stochastic parametrization can also help reduce long-term biases which have bedevilled numerical simulations of climate from the earliest days to the present. As a result, it is suggested that the need to maintain a large ‘gene pool’ of quasi-independent deterministic simulators may be obviated by the development of probabilistic Earth-system simulators. Consistent with the conclusions of the World Summit on Climate Modelling, this in turn implies that individual institutes will be able to pool human and computational resources in developing future-generation simulators, thus benefitting from economies of scale; the establishment of the Airbus consortium provides a useful analogy here. As a further stimulus for such evolution, discussion is given to a potential new synergy between the development of dynamical cores, and stochastic processing hardware. However, it is concluded that the traditional challenge in numerical weather prediction, of reducing deterministic measures of forecast error, may increasingly become an obstacle to the seamless development of probabilistic weather and climate simulators, paradoxical as that may appear at first sight. Indeed, going further, it is argued that it may be time to consider focusing operational weather forecast development entirely on high-resolution ensemble prediction systems. Finally, by considering the exceptionally challenging problem of quantifying cloud feedback in climate change, it is argued that the development of the probabilistic Earth-system simulator may actually provide a route to reducing uncertainty in climate prediction. Copyright © 2012 Royal Meteorological Society},
	language = {en},
	number = {665},
	urldate = {2023-07-26},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Palmer, T. N.},
	year = {2012},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/qj.1923},
	keywords = {Earth-system simulation, ensemble prediction, stochastic parametrization},
	pages = {841--861},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/HKPR4539/Palmer - 2012 - Towards the probabilistic Earth-system simulator .pdf:application/pdf;Snapshot:/Users/bobbyantonio/Zotero/storage/SIKSRX4N/qj.html:text/html},
}

@article{arnold_stochastic_2013,
	title = {Stochastic parametrizations and model uncertainty in the {Lorenz} ’96 system},
	volume = {371},
	url = {https://royalsocietypublishing.org/doi/abs/10.1098/rsta.2011.0479},
	doi = {10.1098/rsta.2011.0479},
	abstract = {Simple chaotic systems are useful tools for testing methods for use in numerical weather simulations owing to their transparency and computational cheapness. The Lorenz system was used here; the full system was defined as ‘truth’, whereas a truncated version was used as a testbed for parametrization schemes. Several stochastic parametrization schemes were investigated, including additive and multiplicative noise. The forecasts were started from perfect initial conditions, eliminating initial condition uncertainty. The stochastically generated ensembles were compared with perturbed parameter ensembles and deterministic schemes. The stochastic parametrizations showed an improvement in weather and climate forecasting skill over deterministic parametrizations. Including a temporal autocorrelation resulted in a significant improvement over white noise, challenging the standard idea that a parametrization should only represent sub-gridscale variability. The skill of the ensemble at representing model uncertainty was tested; the stochastic ensembles gave better estimates of model uncertainty than the perturbed parameter ensembles. The forecasting skill of the parametrizations was found to be linked to their ability to reproduce the climatology of the full model. This is important in a seamless prediction system, allowing the reliability of short-term forecasts to provide a quantitative constraint on the accuracy of climate predictions from the same system.},
	number = {1991},
	urldate = {2023-07-26},
	journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Arnold, H. M. and Moroz, I. M. and Palmer, T. N.},
	month = may,
	year = {2013},
	note = {Publisher: Royal Society},
	keywords = {ensemble prediction, model uncertainty, reliability, seamless prediction, stochastic parametrizations},
	pages = {20110479},
}

@article{christensen_stochastic_2015,
	title = {Stochastic and {Perturbed} {Parameter} {Representations} of {Model} {Uncertainty} in {Convection} {Parameterization}},
	volume = {72},
	issn = {0022-4928, 1520-0469},
	url = {https://journals.ametsoc.org/view/journals/atsc/72/6/jas-d-14-0250.1.xml},
	doi = {10.1175/JAS-D-14-0250.1},
	abstract = {Abstract It is now acknowledged that representing model uncertainty in atmospheric simulators is essential for the production of reliable probabilistic forecasts, and a number of different techniques have been proposed for this purpose. This paper presents new perturbed parameter schemes for use in the European Centre for Medium-Range Weather Forecasts (ECMWF) convection scheme. Two types of scheme are developed and implemented. Both schemes represent the joint uncertainty in four of the parameters in the convection parameterization scheme, which was estimated using the Ensemble Prediction and Parameter Estimation System (EPPES). The first scheme developed is a fixed perturbed parameter scheme, where the values of uncertain parameters are varied between ensemble members, but held constant over the duration of the forecast. The second is a stochastically varying perturbed parameter scheme. The performance of these schemes was compared to the ECMWF operational stochastic scheme, stochastically perturbed parameterization tendencies (SPPT), and to a model that does not represent uncertainty in convection. The skill of probabilistic forecasts made using the different models was evaluated. While the perturbed parameter schemes improve on the stochastic parameterization in some regards, the SPPT scheme outperforms the perturbed parameter approaches when considering forecast variables that are particularly sensitive to convection. Overall, SPPT schemes are the most skillful representations of model uncertainty owing to convection parameterization.},
	language = {EN},
	number = {6},
	urldate = {2023-07-26},
	journal = {Journal of the Atmospheric Sciences},
	author = {Christensen, H. M. and Moroz, I. M. and Palmer, T. N.},
	month = jun,
	year = {2015},
	note = {Publisher: American Meteorological Society
Section: Journal of the Atmospheric Sciences},
	pages = {2525--2544},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/AGIKVX98/Christensen et al. - 2015 - Stochastic and Perturbed Parameter Representations.pdf:application/pdf},
}

@inproceedings{singh_numerical_2019,
	address = {Vancouver, Canada},
	title = {Numerical {Weather} {Model} {Super}-{Resolution}},
	abstract = {Numerical simulation of weather is constrained due to the high computational cost of integrating the coupled PDEs that govern atmospheric motion. Even the ﬁnest-scale numerical weather prediction models cannot model the scales that dictate weather in urban areas and regions with high topographic complexity, like mountains. Thus, several statistical methods have been developed in the climate community to upsample numerical model output to ﬁner resolutions. This is conceptually similar to image super-resolution (SR) [1] and in this work we report the results of applying SR methods to this problem. We compare several methods and ﬁnd ESRGAN [2] to give high-ﬁdelity qualitative recovery but poorer performance on metrics such as MSE. However, the high frequency power spectrum is captured remarkably well by ESRGAN, virtually identical to the real data, while other method’s ﬁdelity drops signiﬁcantly at high frequency. We use this observation to modify our approach to optimize the power spectrum directly in our loss function, and call this technique PSD-Net. We achieve better performance across all metrics, along with increased stability and faster training time.},
	language = {en},
	booktitle = {33rd {Conference} on {Neural} {Information} {Processing} {Systems} ({NeurIPS})},
	author = {Singh, Alok and White, Brian and Albert, Adrian},
	year = {2019},
	file = {Singh et al. - Numerical Weather Model Super-Resolution.pdf:/Users/bobbyantonio/Zotero/storage/CNZFUHGH/Singh et al. - Numerical Weather Model Super-Resolution.pdf:application/pdf},
}

@misc{parthipan_using_2022,
	title = {Using {Probabilistic} {Machine} {Learning} to {Better} {Model} {Temporal} {Patterns} in {Parameterizations}: a case study with the {Lorenz} 96 model},
	shorttitle = {Using {Probabilistic} {Machine} {Learning} to {Better} {Model} {Temporal} {Patterns} in {Parameterizations}},
	url = {http://arxiv.org/abs/2203.14814},
	abstract = {The modelling of small-scale processes is a major source of error in climate models, hindering the accuracy of low-cost models which must approximate such processes through parameterization. Red noise is essential to many operational parameterization schemes, helping model temporal correlations. We show how to build on the successes of red noise by combining the known benefits of stochasticity with machine learning. This is done using a physically-informed recurrent neural network within a probabilistic framework. Our model is competitive and often superior to both a bespoke baseline and an existing probabilistic machine learning approach (GAN) when applied to the Lorenz 96 atmospheric simulation. This is due to its superior ability to model temporal patterns compared to standard first-order autoregressive schemes. It also generalises to unseen scenarios. We evaluate across a number of metrics from the literature, and also discuss the benefits of using the probabilistic metric of hold-out likelihood.},
	urldate = {2023-07-26},
	publisher = {arXiv},
	author = {Parthipan, Raghul and Christensen, Hannah M. and Hosking, J. Scott and Wischik, Damon J.},
	month = sep,
	year = {2022},
	note = {arXiv:2203.14814 [physics]},
	keywords = {Computer Science - Machine Learning, Physics - Atmospheric and Oceanic Physics},
	annote = {Comment: Submitted to Geoscientific Model Development (GMD). 26 pages, 10 figures. The manuscript was revised following helpful comments from the reviewers after rejection from the Journal of Advances in Modeling Earth Systems (JAMES). These included further experimental results and changes to the narrative, amongst other revisions. New version created to include grant numbers of funding bodies},
	file = {arXiv.org Snapshot:/Users/bobbyantonio/Zotero/storage/YKINTANQ/2203.html:text/html;Full Text PDF:/Users/bobbyantonio/Zotero/storage/2E4XNFE8/Parthipan et al. - 2022 - Using Probabilistic Machine Learning to Better Mod.pdf:application/pdf},
}

@article{gagne_ii_machine_2020,
	title = {Machine {Learning} for {Stochastic} {Parameterization}: {Generative} {Adversarial} {Networks} in the {Lorenz} '96 {Model}},
	volume = {12},
	issn = {1942-2466},
	shorttitle = {Machine {Learning} for {Stochastic} {Parameterization}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2019MS001896},
	doi = {10.1029/2019MS001896},
	abstract = {Stochastic parameterizations account for uncertainty in the representation of unresolved subgrid processes by sampling from the distribution of possible subgrid forcings. Some existing stochastic parameterizations utilize data-driven approaches to characterize uncertainty, but these approaches require significant structural assumptions that can limit their scalability. Machine learning models, including neural networks, are able to represent a wide range of distributions and build optimized mappings between a large number of inputs and subgrid forcings. Recent research on machine learning parameterizations has focused only on deterministic parameterizations. In this study, we develop a stochastic parameterization using the generative adversarial network (GAN) machine learning framework. The GAN stochastic parameterization is trained and evaluated on output from the Lorenz '96 model, which is a common baseline model for evaluating both parameterization and data assimilation techniques. We evaluate different ways of characterizing the input noise for the model and perform model runs with the GAN parameterization at weather and climate time scales. Some of the GAN configurations perform better than a baseline bespoke parameterization at both time scales, and the networks closely reproduce the spatiotemporal correlations and regimes of the Lorenz '96 system. We also find that, in general, those models which produce skillful forecasts are also associated with the best climate simulations.},
	language = {en},
	number = {3},
	urldate = {2023-07-26},
	journal = {Journal of Advances in Modeling Earth Systems},
	author = {Gagne II, David John and Christensen, Hannah M. and Subramanian, Aneesh C. and Monahan, Adam H.},
	year = {2020},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/2019MS001896},
	keywords = {machine learning, weather, climate, generative adversarial networks, lorenz, stochastic parameterization},
	pages = {e2019MS001896},
	annote = {e2019MS001896 10.1029/2019MS001896},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/I4HMVN73/Gagne II et al. - 2020 - Machine Learning for Stochastic Parameterization .pdf:application/pdf;Snapshot:/Users/bobbyantonio/Zotero/storage/MP5LWL2T/2019MS001896.html:text/html},
}

@article{delaunay_interpretable_2022,
	title = {Interpretable {Deep} {Learning} for {Probabilistic} {MJO} {Prediction}},
	volume = {49},
	issn = {1944-8007},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2022GL098566},
	doi = {10.1029/2022GL098566},
	abstract = {The Madden-Julian oscillation (MJO) is the dominant source of sub-seasonal variability in the tropics. It consists of an Eastward moving region of enhanced convection coupled to changes in zonal winds. It is not possible to predict the precise evolution of the MJO, so sub-seasonal forecasts are generally probabilistic. We present a deep convolutional neural network (CNN) that produces skilful state-dependent probabilistic MJO forecasts. Importantly, the CNN's forecast uncertainty varies depending on the instantaneous predictability of the MJO. The CNN accounts for intrinsic chaotic uncertainty by predicting the standard deviation about the mean, and model uncertainty using Monte-Carlo dropout. Interpretation of the CNN mean forecasts highlights known MJO mechanisms, providing confidence in the model. Interpretation of forecast uncertainty indicates mechanisms governing MJO predictability. In particular, we find an initially stronger MJO signal is associated with more uncertainty, and that MJO predictability is affected by the state of the Walker Circulation.},
	language = {en},
	number = {16},
	urldate = {2023-07-26},
	journal = {Geophysical Research Letters},
	author = {Delaunay, Antoine and Christensen, Hannah M.},
	year = {2022},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/2022GL098566},
	keywords = {MJO, deep learning, Madden-Julian oscillation, predictability, XAI},
	pages = {e2022GL098566},
	annote = {e2022GL098566 2022GL098566},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/VA929WQQ/Delaunay and Christensen - 2022 - Interpretable Deep Learning for Probabilistic MJO .pdf:application/pdf;Snapshot:/Users/bobbyantonio/Zotero/storage/AT3U8K3P/2022GL098566.html:text/html},
}

@book{murphy_probabilistic_2022,
	title = {Probabilistic {Machine} {Learning}},
	publisher = {MIT Press},
	author = {Murphy, Kevin},
	year = {2022},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/P5EDALKT/book2.pdf:application/pdf},
}

@inproceedings{li_generative_2015,
	title = {Generative {Moment} {Matching} {Networks}},
	url = {https://proceedings.mlr.press/v37/li15.html},
	abstract = {We consider the problem of learning deep generative models from data. We formulate a method that generates an independent sample via a single feedforward pass through a multilayer preceptron, as in the recently proposed generative adversarial networks (Goodfellow et al., 2014). Training a generative adversarial network, however, requires careful optimization of a difficult minimax program. Instead, we utilize a technique from statistical hypothesis testing known as maximum mean discrepancy (MMD), which leads to a simple objective that can be interpreted as matching all orders of statistics between a dataset and samples from the model, and can be trained by backpropagation. We further boost the performance of this approach by combining our generative network with an auto-encoder network, using MMD to learn to generate codes that can then be decoded to produce samples. We show that the combination of these techniques yields excellent generative models compared to baseline approaches as measured on MNIST and the Toronto Face Database.},
	language = {en},
	urldate = {2023-07-20},
	booktitle = {Proceedings of the 32nd {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Li, Yujia and Swersky, Kevin and Zemel, Rich},
	month = jun,
	year = {2015},
	note = {ISSN: 1938-7228},
	pages = {1718--1727},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/V9XH4NNB/Li et al. - 2015 - Generative Moment Matching Networks.pdf:application/pdf},
}

@article{li_generative_nodate,
	title = {Generative {Moment} {Matching} {Networks}},
	abstract = {We consider the problem of learning deep generative models from data. We formulate a method that generates an independent sample via a single feedforward pass through a multilayer perceptron, as in the recently proposed generative adversarial networks (Goodfellow et al., 2014). Training a generative adversarial network, however, requires careful optimization of a difﬁcult minimax program. Instead, we utilize a technique from statistical hypothesis testing known as maximum mean discrepancy (MMD), which leads to a simple objective that can be interpreted as matching all orders of statistics between a dataset and samples from the model, and can be trained by backpropagation. We further boost the performance of this approach by combining our generative network with an auto-encoder network, using MMD to learn to generate codes that can then be decoded to produce samples. We show that the combination of these techniques yields excellent generative models compared to baseline approaches as measured on MNIST and the Toronto Face Database.},
	language = {en},
	author = {Li, Yujia and Swersky, Kevin and Zemel, Richard},
	file = {Li et al. - Generative Moment Matching Networks.pdf:/Users/bobbyantonio/Zotero/storage/S5W5BMMK/Li et al. - Generative Moment Matching Networks.pdf:application/pdf},
}

@article{brecht_computing_2023,
	title = {Computing the {Ensemble} {Spread} {From} {Deterministic} {Weather} {Predictions} {Using} {Conditional} {Generative} {Adversarial} {Networks}},
	volume = {50},
	copyright = {© 2023 The Authors.},
	issn = {1944-8007},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2022GL101452},
	doi = {10.1029/2022GL101452},
	abstract = {Ensemble prediction systems are an invaluable tool for weather forecasting. Practically, ensemble predictions are obtained by running several perturbations of the deterministic control forecast. However, ensemble prediction is associated with a high computational cost and often involves statistical post-processing steps to improve its quality. Here we propose to use deep-learning-based algorithms to learn the statistical properties of an ensemble prediction system, the ensemble spread, given only the deterministic control forecast. Thus, once trained, the costly ensemble prediction system will not be needed anymore to obtain future ensemble forecasts, and the statistical properties of the ensemble can be derived from a single deterministic forecast. We adapt the classical pix2pix architecture to a three-dimensional model and train them against several years of operational (ensemble) weather forecasts for the 500 hPa geopotential height. The results demonstrate that the trained models indeed allow obtaining a highly accurate ensemble spread from the control forecast only.},
	language = {en},
	number = {2},
	urldate = {2023-07-20},
	journal = {Geophysical Research Letters},
	author = {Brecht, Rüdiger and Bihlo, Alex},
	year = {2023},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/2022GL101452},
	pages = {e2022GL101452},
	annote = {e2022GL101452 2022GL101452},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/W7HHTEAL/Brecht and Bihlo - 2023 - Computing the Ensemble Spread From Deterministic W.pdf:application/pdf;Snapshot:/Users/bobbyantonio/Zotero/storage/PC3XYBWE/2022GL101452.html:text/html},
}

@misc{pacchiardi_probabilistic_2022,
	title = {Probabilistic {Forecasting} with {Generative} {Networks} via {Scoring} {Rule} {Minimization}},
	url = {http://arxiv.org/abs/2112.08217},
	abstract = {Generative networks are often trained to minimize a statistical divergence between the reference distribution and the generative one in an adversarial setting. Some works trained instead generative networks to minimize Scoring Rules, functions assessing how well the generative distribution matches each training sample individually. We show how the Scoring Rule formulation easily extends to the so-called prequential (predictive-sequential) score, whose minimization allows performing probabilistic forecasting with generative networks. This objective leads to adversarial-free training, therefore easily avoiding uncertainty underestimation due to mode collapse, which is a common issue in the adversarial setting and undesirable for probabilistic forecasting. We provide consistency guarantees for the minimizer of the prequential score and employ that to perform probabilistic forecasting for two chaotic dynamical models and a benchmark dataset of global weather observations. For this last example, we define scoring rules for spatial data by drawing from the relevant literature, with which we obtain better uncertainty quantification with little hyperparameter tuning compared to adversarial training.},
	urldate = {2023-07-20},
	publisher = {arXiv},
	author = {Pacchiardi, Lorenzo and Adewoyin, Rilwan and Dueben, Peter and Dutta, Ritabrata},
	month = may,
	year = {2022},
	note = {arXiv:2112.08217 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv.org Snapshot:/Users/bobbyantonio/Zotero/storage/CGSJY54K/2112.html:text/html;Full Text PDF:/Users/bobbyantonio/Zotero/storage/LB78KIFS/Pacchiardi et al. - 2022 - Probabilistic Forecasting with Generative Networks.pdf:application/pdf},
}

@misc{chen_generative_2022,
	title = {Generative machine learning methods for multivariate ensemble post-processing},
	url = {http://arxiv.org/abs/2211.01345},
	doi = {10.48550/arXiv.2211.01345},
	abstract = {Ensemble weather forecasts based on multiple runs of numerical weather prediction models typically show systematic errors and require post-processing to obtain reliable forecasts. Accurately modeling multivariate dependencies is crucial in many practical applications, and various approaches to multivariate post-processing have been proposed where ensemble predictions are first post-processed separately in each margin and multivariate dependencies are then restored via copulas. These two-step methods share common key limitations, in particular the difficulty to include additional predictors in modeling the dependencies. We propose a novel multivariate post-processing method based on generative machine learning to address these challenges. In this new class of nonparametric data-driven distributional regression models, samples from the multivariate forecast distribution are directly obtained as output of a generative neural network. The generative model is trained by optimizing a proper scoring rule which measures the discrepancy between the generated and observed data, conditional on exogenous input variables. Our method does not require parametric assumptions on univariate distributions or multivariate dependencies and allows for incorporating arbitrary predictors. In two case studies on multivariate temperature and wind speed forecasting at weather stations over Germany, our generative model shows significant improvements over state-of-the-art methods and particularly improves the representation of spatial dependencies.},
	urldate = {2023-07-20},
	publisher = {arXiv},
	author = {Chen, Jieyu and Janke, Tim and Steinke, Florian and Lerch, Sebastian},
	month = sep,
	year = {2022},
	note = {arXiv:2211.01345 [physics, stat]},
	keywords = {Computer Science - Machine Learning, Physics - Atmospheric and Oceanic Physics, Statistics - Methodology},
	file = {arXiv Fulltext PDF:/Users/bobbyantonio/Zotero/storage/FG7U2HK6/Chen et al. - 2022 - Generative machine learning methods for multivaria.pdf:application/pdf;arXiv.org Snapshot:/Users/bobbyantonio/Zotero/storage/K3QDEILB/2211.html:text/html},
}

@article{creswell_generative_2018,
	title = {Generative {Adversarial} {Networks}: {An} {Overview}},
	volume = {35},
	issn = {1558-0792},
	shorttitle = {Generative {Adversarial} {Networks}},
	doi = {10.1109/MSP.2017.2765202},
	abstract = {Generative adversarial networks (GANs) provide a way to learn deep representations without extensively annotated training data. They achieve this by deriving backpropagation signals through a competitive process involving a pair of networks. The representations that can be learned by GANs may be used in a variety of applications, including image synthesis, semantic image editing, style transfer, image superresolution, and classification. The aim of this review article is to provide an overview of GANs for the signal processing community, drawing on familiar analogies and concepts where possible. In addition to identifying different methods for training and constructing GANs, we also point to remaining challenges in their theory and application.},
	number = {1},
	journal = {IEEE Signal Processing Magazine},
	author = {Creswell, Antonia and White, Tom and Dumoulin, Vincent and Arulkumaran, Kai and Sengupta, Biswa and Bharath, Anil A.},
	month = jan,
	year = {2018},
	note = {Conference Name: IEEE Signal Processing Magazine},
	keywords = {Machine learning, Convolutional codes, Data models, Generators, Image resolution, Semantics, Signal resolution, Training data},
	pages = {53--65},
	file = {IEEE Xplore Abstract Record:/Users/bobbyantonio/Zotero/storage/UY2F63CT/8253599.html:text/html;Submitted Version:/Users/bobbyantonio/Zotero/storage/KM2GVPTU/Creswell et al. - 2018 - Generative Adversarial Networks An Overview.pdf:application/pdf},
}

@article{zhang_skilful_2023,
	title = {Skilful nowcasting of extreme precipitation with {NowcastNet}},
	copyright = {2023 The Author(s)},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-023-06184-4},
	doi = {10.1038/s41586-023-06184-4},
	abstract = {Extreme precipitation is a considerable contributor to meteorological disasters and there is a great need to mitigate its socioeconomic effects through skilful nowcasting that has high resolution, long lead times and local details1–3. Current methods are subject to blur, dissipation, intensity or location errors, with physics-based numerical methods struggling to capture pivotal chaotic dynamics such as convective initiation4 and data-driven learning methods failing to obey intrinsic physical laws such as advective conservation5. We present NowcastNet, a nonlinear nowcasting model for extreme precipitation that unifies physical-evolution schemes and conditional-learning methods into a neural-network framework with end-to-end forecast error optimization. On the basis of radar observations from the USA and China, our model produces physically plausible precipitation nowcasts with sharp multiscale patterns over regions of 2,048 km × 2,048 km and with lead times of up to 3 h. In a systematic evaluation by 62 professional meteorologists from across China, our model ranks first in 71\% of cases against the leading methods. NowcastNet provides skilful forecasts at light-to-heavy rain rates, particularly for extreme-precipitation events accompanied by advective or convective processes that were previously considered intractable.},
	language = {en},
	urldate = {2023-07-14},
	journal = {Nature},
	author = {Zhang, Yuchen and Long, Mingsheng and Chen, Kaiyuan and Xing, Lanxiang and Jin, Ronghua and Jordan, Michael I. and Wang, Jianmin},
	month = jul,
	year = {2023},
	note = {Publisher: Nature Publishing Group},
	keywords = {Atmospheric science, Computational science, Computer science},
	pages = {1--7},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/7V3GRL7W/Zhang et al. - 2023 - Skilful nowcasting of extreme precipitation with N.pdf:application/pdf},
}

@article{harris_generative_2022,
	title = {A {Generative} {Deep} {Learning} {Approach} to {Stochastic} {Downscaling} of {Precipitation} {Forecasts}},
	volume = {14},
	abstract = {Despite continuous improvements, precipitation forecasts are still not as accurate and reliable as those of other meteorological variables. A major contributing factor to this is that several key processes affecting precipitation distribution and intensity occur below the resolved scale of global weather models. Generative adversarial networks (GANs) have been demonstrated by the computer vision community to be successful at super-resolution problems, i.e., learning to add fine-scale structure to coarse images. Leinonen et al. (2020) previously applied a GAN to produce ensembles of reconstructed high-resolution atmospheric fields, given coarsened input data. In this paper, we demonstrate this approach can be extended to the more challenging problem of increasing the accuracy and resolution of comparatively low-resolution input from a weather forecasting model, using high-resolution radar measurements as a "ground truth". The neural network must learn to add resolution and structure whilst accounting for non-negligible forecast error. We show that GANs and VAE-GANs can match the statistical properties of state-of-the-art pointwise post-processing methods whilst creating high-resolution, spatially coherent precipitation maps. Our model compares favourably to the best existing downscaling methods in both pixel-wise and pooled CRPS scores, power spectrum information and rank histograms (used to assess calibration). We test our models and show that they perform in a range of scenarios, including heavy rainfall.},
	number = {10},
	journal = {Journal of Advances in Modeling Earth Systems},
	author = {Harris, Lucy and McRae, Andrew T. T. and Chantry, Matthew and Dueben, Peter D. and Palmer, Tim N.},
	month = apr,
	year = {2022},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/E7B8ZBAG/2204.02028.pdf:application/pdf},
}

@article{ravuri_skilful_2021,
	title = {Skilful precipitation nowcasting using deep generative models of radar: {Supplementary} {Information}},
	volume = {597},
	issn = {0028-0836, 1476-4687},
	url = {https://www.nature.com/articles/s41586-021-03854-z},
	doi = {10.1038/s41586-021-03854-z},
	abstract = {Abstract
            
              Precipitation nowcasting, the high-resolution forecasting of precipitation up to two hours ahead, supports the real-world socioeconomic needs of many sectors reliant on weather-dependent decision-making
              1,2
              . State-of-the-art operational nowcasting methods typically advect precipitation fields with radar-based wind estimates, and struggle to capture important non-linear events such as convective initiations
              3,4
              . Recently introduced deep learning methods use radar to directly predict future rain rates, free of physical constraints
              5,6
              . While they accurately predict low-intensity rainfall, their operational utility is limited because their lack of constraints produces blurry nowcasts at longer lead times, yielding poor performance on rarer medium-to-heavy rain events. Here we present a deep generative model for the probabilistic nowcasting of precipitation from radar that addresses these challenges. Using statistical, economic and cognitive measures, we show that our method provides improved forecast quality, forecast consistency and forecast value. Our model produces realistic and spatiotemporally consistent predictions over regions up to 1,536 km × 1,280 km and with lead times from 5–90 min ahead. Using a systematic evaluation by more than 50 expert meteorologists, we show that our generative model ranked first for its accuracy and usefulness in 89\% of cases against two competitive methods. When verified quantitatively, these nowcasts are skillful without resorting to blurring. We show that generative nowcasting can provide probabilistic predictions that improve forecast value and support operational utility, and at resolutions and lead times where alternative methods struggle.},
	language = {en},
	number = {7878},
	urldate = {2023-07-06},
	journal = {Nature},
	author = {Ravuri, Suman and Lenc, Karel and Willson, Matthew and Kangin, Dmitry and Lam, Remi and Mirowski, Piotr and Fitzsimons, Megan and Athanassiadou, Maria and Kashem, Sheleem and Madge, Sam and Prudden, Rachel and Mandhane, Amol and Clark, Aidan and Brock, Andrew and Simonyan, Karen and Hadsell, Raia and Robinson, Niall and Clancy, Ellen and Arribas, Alberto and Mohamed, Shakir},
	month = sep,
	year = {2021},
	pages = {672--677},
	file = {Ravuri et al. - 2021 - Skilful precipitation nowcasting using deep genera.pdf:/Users/bobbyantonio/Zotero/storage/RXGTIFY7/Ravuri et al. - 2021 - Skilful precipitation nowcasting using deep genera.pdf:application/pdf},
}

@inproceedings{arjovsky_wasserstein_2017,
	title = {Wasserstein {Generative} {Adversarial} {Networks}},
	url = {https://proceedings.mlr.press/v70/arjovsky17a.html},
	abstract = {We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to different distances between distributions.},
	language = {en},
	urldate = {2023-07-05},
	booktitle = {Proceedings of the 34th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Arjovsky, Martin and Chintala, Soumith and Bottou, Léon},
	month = jul,
	year = {2017},
	note = {ISSN: 2640-3498},
	pages = {214--223},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/BBHABW32/Arjovsky et al. - 2017 - Wasserstein Generative Adversarial Networks.pdf:application/pdf;Supplementary PDF:/Users/bobbyantonio/Zotero/storage/5VYHVRGM/Arjovsky et al. - 2017 - Wasserstein Generative Adversarial Networks.pdf:application/pdf},
}

@article{goodfellow_generative_2020,
	title = {Generative adversarial networks},
	volume = {63},
	issn = {0001-0782},
	url = {https://dl.acm.org/doi/10.1145/3422622},
	doi = {10.1145/3422622},
	abstract = {Generative adversarial networks are a kind of artificial intelligence algorithm designed to solve the generative modeling problem. The goal of a generative model is to study a collection of training examples and learn the probability distribution that generated them. Generative Adversarial Networks (GANs) are then able to generate more examples from the estimated probability distribution. Generative models based on deep learning are common, but GANs are among the most successful generative models (especially in terms of their ability to generate realistic high-resolution images). GANs have been successfully applied to a wide variety of tasks (mostly in research settings) but continue to present unique challenges and research opportunities because they are based on game theory while most other approaches to generative modeling are based on optimization.},
	number = {11},
	urldate = {2023-07-05},
	journal = {Communications of the ACM},
	author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	month = oct,
	year = {2020},
	pages = {139--144},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/LN2IMPM3/Goodfellow et al. - 2020 - Generative adversarial networks.pdf:application/pdf},
}

@inproceedings{goodfellow_generative_2014,
	title = {Generative {Adversarial} {Nets}},
	volume = {27},
	url = {https://proceedings.neurips.cc/paper_files/paper/2014/hash/5ca3e9b122f61f8f06494c97b1afccf3-Abstract.html},
	abstract = {We propose a new framework for estimating generative models via adversarial nets, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitatively evaluation of the generated samples.},
	urldate = {2023-07-05},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	year = {2014},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/LRR2GLGI/Goodfellow et al. - 2014 - Generative Adversarial Nets.pdf:application/pdf},
}

@inproceedings{gulrajani_improved_2017,
	title = {Improved {Training} of {Wasserstein} {GANs}},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper_files/paper/2017/hash/892c3b1c6dccd52936e27cbd0ff683d6-Abstract.html},
	abstract = {Generative Adversarial Networks (GANs) are powerful generative models, but suffer from training instability. The recently proposed Wasserstein GAN (WGAN) makes progress toward stable training of GANs, but sometimes can still generate only poor samples or fail to converge. We find that these problems are often due to the use of weight clipping in WGAN to enforce a Lipschitz constraint on the critic, which can lead to undesired behavior. We propose an alternative to clipping weights: penalize the norm of gradient of the critic with respect to its input. Our proposed method performs better than standard WGAN and enables stable training of a wide variety of GAN architectures with almost no hyperparameter tuning, including 101-layer ResNets and language models with continuous generators. We also achieve high quality generations on CIFAR-10 and LSUN bedrooms.},
	urldate = {2023-07-05},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Gulrajani, Ishaan and Ahmed, Faruk and Arjovsky, Martin and Dumoulin, Vincent and Courville, Aaron C},
	year = {2017},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/HEZ8FHF8/Gulrajani et al. - 2017 - Improved Training of Wasserstein GANs.pdf:application/pdf},
}

@article{schwartz_comparison_2017,
	title = {A {Comparison} of {Methods} {Used} to {Populate} {Neighborhood}-{Based} {Contingency} {Tables} for {High}-{Resolution} {Forecast} {Verification}},
	volume = {32},
	issn = {1520-0434, 0882-8156},
	url = {https://journals.ametsoc.org/view/journals/wefo/32/2/waf-d-16-0187_1.xml},
	doi = {10.1175/WAF-D-16-0187.1},
	abstract = {Abstract As high-resolution numerical weather prediction models are now commonplace, “neighborhood” verification metrics are regularly employed to evaluate forecast quality. These neighborhood approaches relax the requirement that perfect forecasts must match observations at the grid scale, contrasting traditional point-by-point verification methods. One recently proposed metric, the neighborhood equitable threat score, is calculated from 2 × 2 contingency tables that are populated within a neighborhood framework. However, the literature suggests three subtly different methods of populating neighborhood-based contingency tables. Thus, this work compares and contrasts these three variants and shows they yield statistically significantly different conclusions regarding forecast performance, illustrating that neighborhood-based contingency tables should be constructed carefully and transparently. Furthermore, this paper shows how two of the methods use inconsistent event definitions and suggests a “neighborhood maximum” approach be used to fill neighborhood-based contingency tables.},
	language = {EN},
	number = {2},
	urldate = {2023-07-04},
	journal = {Weather and Forecasting},
	author = {Schwartz, Craig S.},
	month = apr,
	year = {2017},
	note = {Publisher: American Meteorological Society
Section: Weather and Forecasting},
	pages = {733--741},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/7IE2QFJM/Schwartz - 2017 - A Comparison of Methods Used to Populate Neighborh.pdf:application/pdf},
}

@article{stein_neighborhood-based_2019,
	title = {Neighborhood-{Based} {Contingency} {Tables} {Including} {Errors} {Compensation}},
	volume = {147},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/147/1/mwr-d-17-0288.1.xml},
	doi = {10.1175/MWR-D-17-0288.1},
	abstract = {Abstract Some specific scores use a neighborhood strategy in order to reduce double penalty effects, which penalize high-resolution models, compared to large-scale models. Contingency tables based on this strategy have already been proposed, but can sometimes display undesirable behavior. A new method of populating contingency tables is proposed: pairs of missed events and false alarms located in the same local neighborhood compensate in order to give pairs of hits and correct rejections. Local tables are summed up so as to provide the final table for the whole verification domain. It keeps track of the bias of the forecast when neighborhoods are taken into account. Moreover, the scores computed from this table depend on the distance between forecast and observed patterns. This method is applied to binary and multicategorical events in a simplified framework so as to present the method and to compare the new tables with previous neighborhood-based contingency tables. The new tables are then used for the verification of two models operational at Météo-France: AROME, a high-resolution model, and ARPEGE, a large-scale global model. The comparison of several contingency scores shows that the importance of the double penalty decreases more for AROME than for ARPEGE when the neighboring size increases. Scores designed for rare events are also applied to these neighborhood-based contingency tables.},
	language = {EN},
	number = {1},
	urldate = {2023-07-04},
	journal = {Monthly Weather Review},
	author = {Stein, Joël and Stoop, Fabien},
	month = jan,
	year = {2019},
	note = {Publisher: American Meteorological Society
Section: Monthly Weather Review},
	pages = {329--344},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/MYQM3EMR/Stein and Stoop - 2019 - Neighborhood-Based Contingency Tables Including Er.pdf:application/pdf},
}

@misc{youds_gcrf_2021,
	type = {Monograph},
	title = {{GCRF} {African} {SWIFT} and {ForPAc} {SHEAR} {White} {Paper} on the {Potential} of {Operational} {Weather} {Prediction} to {Save} {Lives} and {Improve} {Livelihoods} and {Economies} in {Sub}-{Saharan} {Africa}},
	copyright = {cc\_by\_4},
	url = {https://eprints.whiterose.ac.uk/181045/},
	abstract = {The ‘silent revolution’ of numerical weather prediction (NWP) has led to significant social benefits and billions of dollars in economic benefits to mid-latitude countries, however the level of benefit in sub-Saharan Africa has been very limited, despite the potential to save lives, improve livelihoods, protect property and infrastructure and boost economies. Ongoing climate change in Africa, and the associated projected intensification of weather impacts in coming decades, makes the realisation of effective and more reliable weather forecasts and climate services even more urgent. It is widely recognised that to achieve this potential, investment is required in strengthening decision makers’ understanding of weather predictions and confidence in interpreting and appropriately applying forecasts, alongside transparent communication of the levels of skill and probability or certainty in forecast products. However, on all time scales of prediction, it is generally unrecognised that many forecasts that produce user-relevant metrics have such low skill that they are only marginally valuable to stakeholders, creating significant practical and ethical barriers to increasing uptake and generating benefits. Here, we present substantial evidence that even a modest investment in science for weather information and forecast techniques, to provide new technology and tools for Africa, can significantly increase the skill of user-relevant forecast products on all time scales. This will be a necessary enabler for building trust in and uptake of decision-relevant forecasts with the potential to deliver significant social and economic benefits. We present here an argument that incremental improvements in the skill of weather forecasting across all timescales in the African tropics, alongside strengthening communication and understanding of these forecasts, is fundamental to saving lives and enhancing livelihoods. Investing in the capacity and capability of National Meteorological Services and research institutions is essential to ensure lifesaving and life-enhancing services continue to be developed with and designed to serve the populations of sub-Saharan countries.},
	language = {en},
	urldate = {2023-07-04},
	author = {Youds, L. H. and Parker, D. J. and Adefisan, E. A. and Antwi-Agyei, P. and Bain, C. L. and Black, E. C. L. and Blyth, A. M. and Dougill, A. J. and Hirons, L. C. and Indasi, V. S. and Lamptey, B. L. and Marshall, F. and Marsham, J. H. and Stein, T. H. M. and Taylor, C. M. and Todd, M. C. and Visman, E. L. and Woolnough, S. J.},
	month = nov,
	year = {2021},
	note = {Publisher: University of Leeds},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/ZDGKDHVQ/Youds et al. - 2021 - GCRF African SWIFT and ForPAc SHEAR White Paper on.pdf:application/pdf;Snapshot:/Users/bobbyantonio/Zotero/storage/VEIU7RM7/181045.html:text/html},
}

@article{schaefer_critical_1990,
	title = {The {Critical} {Success} {Index} as an {Indicator} of {Warning} {Skill}},
	volume = {5},
	issn = {1520-0434, 0882-8156},
	url = {https://journals.ametsoc.org/view/journals/wefo/5/4/1520-0434_1990_005_0570_tcsiaa_2_0_co_2.xml},
	doi = {10.1175/1520-0434(1990)005<0570:TCSIAA>2.0.CO;2},
	abstract = {Abstract A form of the critical success index (CSI) is used by the National Weather Service to indicate the value of warnings. This verification statistic assumes that the times when an event was neither expected nor observed are of no consequence. It can be shown that the CSI is not an unbiased indicator of forecast skill but is proportional to the frequency of the event being forecast. This innate bias is demonstrated theoretically and via example. An unbiased verification statistic appropriate for forecast of rare events is presented and applied to severe convective weather warnings. Comparisons of this score to the CSI show the extent of the penalty the CSI extracts from forecasters who work in areas that are not climatically prone to given events.},
	language = {EN},
	number = {4},
	urldate = {2023-07-03},
	journal = {Weather and Forecasting},
	author = {Schaefer, Joseph T.},
	month = dec,
	year = {1990},
	note = {Publisher: American Meteorological Society
Section: Weather and Forecasting},
	pages = {570--575},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/XEA37TUH/Schaefer - 1990 - The Critical Success Index as an Indicator of Warn.pdf:application/pdf},
}

@article{bhatia_exgan_2021,
	title = {{ExGAN}: {Adversarial} {Generation} of {Extreme} {Samples}},
	volume = {35},
	copyright = {Copyright (c) 2021 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	shorttitle = {{ExGAN}},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/16834},
	doi = {10.1609/aaai.v35i8.16834},
	abstract = {Mitigating the risk arising from extreme events is a fundamental goal with many applications, such as the modelling of natural disasters, financial crashes, epidemics, and many others. To manage this risk, a vital step is to be able to understand or generate a wide range of extreme scenarios. Existing approaches based on Generative Adversarial Networks (GANs) excel at generating realistic samples, but seek to generate typical samples, rather than extreme samples. Hence, in this work, we propose ExGAN, a GAN-based approach to generate realistic and extreme samples. To model the extremes of the training distribution in a principled way, our work draws from Extreme Value Theory (EVT), a probabilistic approach for modelling the extreme tails of distributions. For practical utility, our framework allows the user to specify both the desired extremeness measure, as well as the desired extremeness probability they wish to sample at. Experiments on real US Precipitation data show that our method generates realistic samples, based on visual inspection and quantitative measures, in an efficient manner. Moreover, generating increasingly extreme examples using ExGAN can be done in constant time (with respect to the extremeness probability τ), as opposed to the O(1/τ) time required by the baseline approach.},
	language = {en},
	number = {8},
	urldate = {2023-07-03},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Bhatia, Siddharth and Jain, Arjit and Hooi, Bryan},
	month = may,
	year = {2021},
	note = {Number: 8},
	keywords = {Adversarial Learning \& Robustness},
	pages = {6750--6758},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/F3UYTTDW/Bhatia et al. - 2021 - ExGAN Adversarial Generation of Extreme Samples.pdf:application/pdf},
}

@misc{noauthor_ethiopia_nodate,
	title = {Ethiopia – 240,000 {Impacted} by {Heavy} {Rains} and {Floods}, 29 {Dead}, {Says} {UN} – {FloodList}},
	url = {https://floodlist.com/africa/ethiopia-floods-march-april-2023},
	urldate = {2023-06-30},
	file = {Ethiopia – 240,000 Impacted by Heavy Rains and Floods, 29 Dead, Says UN – FloodList:/Users/bobbyantonio/Zotero/storage/XYAWHIZI/ethiopia-floods-march-april-2023.html:text/html},
}

@article{moise_new_2011,
	title = {New climate model metrics based on object-orientated pattern matching of rainfall},
	volume = {116},
	copyright = {Copyright 2011 by the American Geophysical Union.},
	issn = {2156-2202},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2010JD015318},
	doi = {10.1029/2010JD015318},
	abstract = {Climate metrics are becoming a more widespread tool used in global circulation model (GCM) evaluation as well as climate change projections. In their more simple form they provide a quick overview of the performance of a large ensemble of GCM simulations such as the CMIP3 archive of coupled ocean-atmosphere GCMs. Most existing metrics focus on the comparison of fields at each grid point. We present here a complementary metric which targets structures as a whole (patterns). The methodology is based on a pattern matching technique used previously in numerical weather prediction and has been modified for the analysis of mean climate fields. The resulting error decomposition allows for a more detailed assessment of the field structure with regard to errors in placement, rotation, volume, and pattern. The technique is applied to two observational rainfall data sets and GCM simulations from the CMIP3 archive for seasonal rainfall structures over the South Pacific Convergence Zone.},
	language = {en},
	number = {D12},
	urldate = {2023-06-30},
	journal = {Journal of Geophysical Research: Atmospheres},
	author = {Moise, Aurel F. and Delage, Francois P.},
	year = {2011},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/2010JD015318},
	keywords = {precipitation, climate change, model evaluation, global climate models, South Pacific Convergence Zone},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/KH58AMUP/Moise and Delage - 2011 - New climate model metrics based on object-orientat.pdf:application/pdf;Snapshot:/Users/bobbyantonio/Zotero/storage/KB4VXIMQ/2010JD015318.html:text/html},
}

@article{yu_benchmark_2020,
	title = {Benchmark rainfall verification of landfall tropical cyclone forecasts by operational {ACCESS}-{TC} over {China}},
	volume = {27},
	issn = {1469-8080},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/met.1842},
	doi = {10.1002/met.1842},
	abstract = {Results from object-based verification of rainfall forecasts for landfalling tropical cyclones (TCs) over China during the period 2012–2015 are presented. The sample consists of 25 landfall events and 133 operational numerical forecasts from the TC version of the Australian Community Climate and Earth System Simulator. Mean equitable threat scores, probabilities of detection and false alarm ratios for the 30 mm isohyet for the unadjusted forecasts at 0–6 hr (essentially the initialization) are (0.23, 0.55, 0.65), while the performance measures of 24 hr forecast accumulations are the best for the 0–24 hr forecast (0.37, 0.67, 0.40) and then worsen to (0.16, 0.38, 0.66) for the 48–72 hr forecast. Forecast ability also decreases with the increase in rainfall amount. The contiguous rain area (CRA) verification method is used to diagnose the source of systematic errors from the displacement, rotation, volume and pattern of the forecasted rain fields. Results show that the errors are mostly from rainfall patterns, followed by displacement errors, particularly for very heavy rain. After application of the displacement and rotation adjustments of the CRA method, averaged errors improve by about 15\%. Results suggest that rainfall prediction will continue to improve with improved track prediction, but more work is needed on model initialization and the prediction of TC structure. The study has uncertainty related to the limited sample size, which could cause large variability, particularly for heavy rainfall at 6 and 72 hr. However, the results still represent a useful benchmark for future verification of landfalling TCs.},
	language = {en},
	number = {1},
	urldate = {2023-06-30},
	journal = {Meteorological Applications},
	author = {Yu, Zifeng and Chen, Ying Jun and Ebert, Beth and Davidson, Noel E. and Xiao, Yi and Yu, Hui and Duan, Yihong},
	year = {2020},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/met.1842},
	keywords = {typhoon, precipitation forecast, rainfall evaluation, tropical cyclone},
	pages = {e1842},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/HN8RWBUR/Yu et al. - 2020 - Benchmark rainfall verification of landfall tropic.pdf:application/pdf;Snapshot:/Users/bobbyantonio/Zotero/storage/WQDLEDS2/met.html:text/html},
}

@article{dorninger_editorial_2020,
	title = {Editorial: {Recent} developments and application examples on forecast verification},
	volume = {27},
	copyright = {© 2020 The Authors. Meteorological Applications published by John Wiley \& Sons Ltd on behalf of the Royal Meteorological Society.},
	issn = {1469-8080},
	shorttitle = {Editorial},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/met.1934},
	doi = {10.1002/met.1934},
	language = {en},
	number = {4},
	urldate = {2023-06-30},
	journal = {Meteorological Applications},
	author = {Dorninger, Manfred and Ghelli, Anna and Lerch, Sebastian},
	year = {2020},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/met.1934},
	pages = {e1934},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/IWHJ5JZ5/Dorninger et al. - 2020 - Editorial Recent developments and application exa.pdf:application/pdf;Snapshot:/Users/bobbyantonio/Zotero/storage/UIZ6FETZ/met.html:text/html},
}

@article{bofinger_qualification_2002,
	title = {Qualification of wind power forecasts},
	abstract = {In order to manage the remarkable share of wind power as present in several utilities forecast information is needed. In the last years several respective procedures have been developed and put into operation. Up to now the outcome of the forecast tools is mainly restricted to the forecasted value itself and general information of the overall error of the procedure as e.g. the standard deviation. However, for the handling of these forecast information in the framework of e.g. power station dispatch schemes, more detailed information of the structure of the expected errors - beyond the expected standard deviation - seem to be desirable. Due to the fact that the output of wind turbine systems is limited between zero and the maximum power, the error statistics cannot follow a normal distribution. Thus, for the assessment of the probability of occurrence of a certain forecast error a model for the distribution function of the errors has to be set up. We have analysed the errors of the forecast model PREVIENTO as applied for an ensemble of installations representing the lumped power output of the turbines within a given region. Given bias free forecasts, the applicability of various models for the distribution function of the set of errors has been tested. It turned out, that the use of a beta function is justifiable for this task with respect to chi -squared tests. Together with an empirically derived parametric model for the expected standard deviation of the ensemble forecast, the knowledge of the respective distribution function allows for the assignment of risk figures to any decision taken based on the wind power forecast.},
	journal = {2002 Global Windpower Conference, Vol. 2; Paris},
	author = {Bofinger, Stefan and Luig, A. and Beyer, Hans Georg},
	month = jan,
	year = {2002},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/IHNVZQYP/Bofinger et al. - 2002 - Qualification of wind power forecasts.pdf:application/pdf},
}

@article{bremnes_probabilistic_2004,
	title = {Probabilistic wind power forecasts using local quantile regression},
	volume = {7},
	issn = {1099-1824},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/we.107},
	doi = {10.1002/we.107},
	abstract = {Wind power forecasts are in various ways valuable for users in decision-making processes. However, most forecasts are deterministic, and hence possibly important information about uncertainty is not available. Complete information about future production can be obtained by using probabilistic forecasts, and this article demonstrates how such forecasts can be created by means of local quantile regression. The approach has several advantages, such as no distributional assumptions and flexible inclusion of predictive information. In addition, it can be shown that, for some purposes, forecasts in terms of quantiles provide the type of information required to make optimal economic decisions. The methodology is applied to data from a wind farm in Norway. Copyright © 2004 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {1},
	urldate = {2023-06-30},
	journal = {Wind Energy},
	author = {Bremnes, John Bjørnar},
	year = {2004},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/we.107},
	keywords = {economic value, probabilistic forecasts, quantile regression, wind power},
	pages = {47--54},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/7TMDCNNZ/Bremnes - 2004 - Probabilistic wind power forecasts using local qua.pdf:application/pdf;Snapshot:/Users/bobbyantonio/Zotero/storage/PC5T56MS/we.html:text/html},
}

@article{meinshausen_quantile_2006,
	title = {Quantile {Regression} {Forests}},
	volume = {7},
	issn = {1533-7928},
	url = {http://jmlr.org/papers/v7/meinshausen06a.html},
	abstract = {Random forests were introduced as a machine learning tool in Breiman (2001) and have since proven to be very popular and powerful for high-dimensional regression and classification. For regression, random forests give an accurate approximation of the conditional mean of a response variable. It is shown here that random forests provide information about the full conditional distribution of the response variable, not only about the conditional mean. Conditional quantiles can be inferred with quantile regression forests, a generalisation of random forests. Quantile regression forests give a non-parametric and accurate way of estimating conditional quantiles for high-dimensional predictor variables. The algorithm is shown to be consistent. Numerical examples suggest that the algorithm is competitive in terms of predictive power.},
	number = {35},
	urldate = {2023-06-30},
	journal = {Journal of Machine Learning Research},
	author = {Meinshausen, Nicolai},
	year = {2006},
	pages = {983--999},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/Z5SF2HQZ/Meinshausen - 2006 - Quantile Regression Forests.pdf:application/pdf},
}

@article{hayatbini_conditional_2019-1,
	title = {Conditional {Generative} {Adversarial} {Networks} ({cGANs}) for {Near} {Real}-{Time} {Precipitation} {Estimation} from {Multispectral} {GOES}-16 {Satellite} {Imageries}—{PERSIANN}-{cGAN}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2072-4292},
	url = {https://www.mdpi.com/2072-4292/11/19/2193},
	doi = {10.3390/rs11192193},
	abstract = {In this paper, we present a state-of-the-art precipitation estimation framework which leverages advances in satellite remote sensing as well as Deep Learning (DL). The framework takes advantage of the improvements in spatial, spectral and temporal resolutions of the Advanced Baseline Imager (ABI) onboard the GOES-16 platform along with elevation information to improve the precipitation estimates. The procedure begins by first deriving a Rain/No Rain (R/NR) binary mask through classification of the pixels and then applying regression to estimate the amount of rainfall for rainy pixels. A Fully Convolutional Network is used as a regressor to predict precipitation estimates. The network is trained using the non-saturating conditional Generative Adversarial Network (cGAN) and Mean Squared Error (MSE) loss terms to generate results that better learn the complex distribution of precipitation in the observed data. Common verification metrics such as Probability Of Detection (POD), False Alarm Ratio (FAR), Critical Success Index (CSI), Bias, Correlation and MSE are used to evaluate the accuracy of both R/NR classification and real-valued precipitation estimates. Statistics and visualizations of the evaluation measures show improvements in the precipitation retrieval accuracy in the proposed framework compared to the baseline models trained using conventional MSE loss terms. This framework is proposed as an augmentation for PERSIANN-CCS (Precipitation Estimation from Remotely Sensed Information using Artificial Neural Network- Cloud Classification System) algorithm for estimating global precipitation.},
	language = {en},
	number = {19},
	urldate = {2023-06-30},
	journal = {Remote Sensing},
	author = {Hayatbini, Negin and Kong, Bailey and Hsu, Kuo-lin and Nguyen, Phu and Sorooshian, Soroosh and Stephens, Graeme and Fowlkes, Charless and Nemani, Ramakrishna and Ganguly, Sangram},
	month = jan,
	year = {2019},
	note = {Number: 19
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {machine learning, precipitation, convolutional neural networks (CNNs), generative adversarial networks (GANs), multispectral satellite imagery},
	pages = {2193},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/GTBK6CES/Hayatbini et al. - 2019 - Conditional Generative Adversarial Networks (cGANs.pdf:application/pdf},
}

@article{widmann_validation_2019,
	title = {Validation of spatial variability in downscaling results from the {VALUE} perfect predictor experiment},
	volume = {39},
	issn = {1097-0088},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/joc.6024},
	doi = {10.1002/joc.6024},
	abstract = {The spatial dependence of meteorological variables is crucial for many impacts, for example, droughts, floods, river flows, energy demand, and crop yield. There is thus a need to understand how well it is represented in downscaling (DS) products. Within the COST Action VALUE, we have conducted a comprehensive analysis of spatial variability in the output of over 40 different DS methods in a perfect predictor setup. The DS output is evaluated against daily precipitation and temperature observations for the period 1979–2008 at 86 sites across Europe and 53 sites across Germany. We have analysed the dependency of correlations of daily temperature and precipitation series at station pairs on the distance between the stations. For the European data set, we have also investigated the complexity of the downscaled data by calculating the number of independent spatial degrees of freedom. For daily precipitation at the German network, we have additionally evaluated the dependency of the joint exceedance of the wet day threshold and of the local 90th percentile on the distance between the stations. Finally, we have investigated regional patterns of European monthly precipitation obtained from rotated principal component analysis. We analysed Perfect Prog (PP) methods, which are based on statistical relationships derived from observations, as well as Model Output Statistics (MOS) approaches, which attempt to correct simulated variables. In summary, we found that most PP DS methods, with the exception of multisite analog methods and a method that explicitly models spatial dependence yield unrealistic spatial characteristics. Regional climate model-based MOS methods showed good performance with respect to correlation lengths and the joint occurrence of wet days, but a substantial overestimation of the joint occurrence of heavy precipitation events. These findings apply to the spatial scales that are resolved by our observation network, and similar studies with higher resolutions, which are relevant for small hydrological catchment, are desirable.},
	language = {en},
	number = {9},
	urldate = {2023-06-29},
	journal = {International Journal of Climatology},
	author = {Widmann, Martin and Bedia, Joaquin and Gutiérrez, José M. and Bosshard, Thomas and Hertig, Elke and Maraun, Douglas and Casado, María J. and Ramos, Petra and Cardoso, Rita M. and Soares, Pedro M. M. and Ribalaygua, Jamie and Pagé, Christian and Fischer, Andreas M. and Herrera, Sixto and Huth, Radan},
	year = {2019},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/joc.6024},
	keywords = {regional climate, validation, downscaling, bias adjustment, model output statistics, perfect prognosis, spatial variability},
	pages = {3819--3845},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/PLSNNNPM/Widmann et al. - 2019 - Validation of spatial variability in downscaling r.pdf:application/pdf;Snapshot:/Users/bobbyantonio/Zotero/storage/EPD2VWGY/joc.html:text/html},
}

@inproceedings{yang_improving_2023,
	title = {Improving {Seasonal} {Prediction} of {Summer} {Precipitation} in the {Middle}–{Lower} {Reaches} of the {Yangtze} {River} {Using} a {TU}-{Net} {Deep} {Learning} {Approach}},
	url = {https://www.semanticscholar.org/paper/Improving-Seasonal-Prediction-of-Summer-in-the-of-a-Yang-Ling/47b70cad0936bb6ff0cd24e47db34ea7f29d6201?utm_source=alert_email&utm_content=LibraryFolder&utm_campaign=AlertEmails_WEEKLY&utm_term=LibraryFolder&email_index=3-0-5&utm_medium=17770581},
	abstract = {The two-step U-Net model (TU-Net) contains a western North Pacific subtropical high (WNPSH) prediction model and a precipitation prediction model fed by the WNPSH predictions, oceanic heat content, and surface temperature. The data-driven forecast model provides improved 4-month lead predictions of the WNPSH and precipitation in the middle and lower reaches of the Yangtze River (MLYR), which has important implications for water resources management and precipitation-related disaster prevention in China. When compared with five state-of-the-art dynamical climate models including the Climate Forecast System of Nanjing University of Information Science and Technology (NUIST-CFS1.0) and four models participating in the North American Multi-Model Ensemble (NMME) project, the TU-Net produces comparable skills in forecasting 4-month lead geopotential height and winds at the 500and 850-hPa levels. For the 4-month lead prediction of precipitation over the MLYR region, the TU-Net has the best correlation scores and mean latitude-weighted RMSE in each summer month and in boreal summer [June–August (JJA)], and pattern correlation coefficient scores are slightly lower than the dynamical models only in June and JJA. In addition, the results show that the constructed TU-Net is also superior to most of the dynamical models in predicting 2-m air temperature in the MLYR region at a 4-month lead. Thus, the deep learning-based TU-Net model can provide a rapid and inexpensive way to improve the seasonal prediction of summer precipitation and 2-m air temperature over the MLYR region. SIGNIFICANCE STATEMENT: The purpose of this study is to examine the seasonal predictive skill of the western North Pacific subtropical high anomalies and summer rainfall anomalies over the middle and lower reaches of the Yangtze River region by means of deep learning methods. Our deep learning model provides a rapid and inexpensive way to improve the seasonal prediction of summer precipitation as well as 2-m air temperature. The work has important implications for water resources management and precipitation-related disaster prevention in China and can be extended in the future to predict other climate variables as well.},
	urldate = {2023-06-26},
	author = {Yang, Shu-Chih and Ling, Fenghua and Yue, L. and LUOa, JING-JIA},
	year = {2023},
}

@book{bishop_pattern_2006,
	address = {New York},
	series = {Information science and statistics},
	title = {Pattern recognition and machine learning},
	isbn = {978-0-387-31073-2},
	language = {en},
	publisher = {Springer},
	author = {Bishop, Christopher M.},
	year = {2006},
	keywords = {Machine learning, Pattern perception},
	file = {Bishop - 2006 - Pattern recognition and machine learning.pdf:/Users/bobbyantonio/Zotero/storage/7FDWX9S3/Bishop - 2006 - Pattern recognition and machine learning.pdf:application/pdf},
}

@article{chantry_opportunities_2021-1,
	title = {Opportunities and challenges for machine learning in weather and climate modelling: {Hard}, medium and soft {AI}},
	volume = {379},
	issn = {1364503X},
	doi = {10.1098/rsta.2020.0083},
	abstract = {In September 2019, a workshop was held to highlight the growing area of applying machine learning techniques to improve weather and climate prediction. In this introductory piece, we outline the motivations, opportunities and challenges ahead in this exciting avenue of research. This article is part of the theme issue 'Machine learning for weather and climate modelling'.},
	number = {2194},
	journal = {Phil. Trans. T. Soc. A},
	author = {Chantry, Matthew and Christensen, Hannah and Dueben, Peter and Palmer, Tim},
	month = apr,
	year = {2021},
	pmid = {33583261},
	note = {Publisher: Royal Society Publishing},
	keywords = {climate modelling, machine learning, weather prediction},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/UWEPHSU6/rsta.2020.0083.pdf:application/pdf},
}

@inproceedings{tartaglione_searching_2008,
	title = {Searching for systematic location errors of quantitative precipitation forecasts over the {Calabria} region},
	volume = {15},
	doi = {10.1002/met.55},
	abstract = {This article statistically analyses the location errors of the precipitation patterns forecast by three limited area models, namely the Fifth-Generation NCAR/Penn State Mesoscale Model (MM5), the QUADRICS BOlogna Limited Area Model (QBOLAM) and the Regional Atmospheric Modelling System (RAMS), over the Calabria region (Italy) for the period October 2000-May 2002. Contiguous rain area (CRA) analysis is the diagnostic tool used to assess and quantify the position errors of the precipitation forecasts with respect to the observed precipitation patterns. Observation gridded analyses were obtained by means of the Barnes algorithm on the available rain gauge observations. Moreover, an approach to measure the quality of precipitation forecasts routinely by means of a global indicator called CRA Mean Shift (CMS) that summarizes the CRA verification outcomes is proposed. The CMS index would represent a statistical indicator of model quality in forecasting the correct positions of precipitation patterns. The model's tendency to misplace, the forecast precipitation patterns towards a particular direction was tested by using a bootstrap procedure. All models seem to show statistically poor abilities in forecasting the correct precipitation pattern position over the verification domain considered. As far as the tendency towards a particular direction is concerned, only the RAMS model seems to show a systematic horizontal misplacement of precipitation patterns towards a particular direction. Copyright © 2008 Royal Meteorological Society.},
	booktitle = {Meteorological {Applications}},
	publisher = {John Wiley and Sons Ltd},
	author = {Tartaglione, Nazario and Mariani, Stefano and Casaioli, Marco and Accadia, Christophe and Federico, Stefano and Michaelides, Silas Chr},
	year = {2008},
	note = {Issue: 1
ISSN: 14698080},
	keywords = {Precipitation, Verification, Forecast},
	pages = {85--95},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/KFS4SPKV/Meteorological Applications - 2008 - Tartaglione - Searching for systematic location errors of quantitative precipitation.pdf:application/pdf},
}

@article{venugopal_new_2005,
	title = {A new metric for comparing precipitation patterns with an application to ensemble forecasts},
	volume = {110},
	issn = {01480227},
	doi = {10.1029/2004JD005395},
	abstract = {Ensemble forecasting can be seen as serving two purposes: (1) by comparison of the control and ensemble members to the observed precipitation field, one can assess the forecast performance probabilistically; and (2) by comparison of ensemble members to the control forecast, one can assess the "diversity" of an ensemble and quantify the uncertainty of the forecast. Both problems are grounded to the basic requirement of being able to compare spatially nonhomogeneous, intermittent fields and come up with low-dimensional metrics that can summarize this comparison. Several standard metrics exist (e.g., root mean square error (RMSE), Brier score, and equitable threat score (EqTh)) and are adopted in many operational studies. We studied (1) a fine-scale ensemble precipitation forecast produced from the Advanced Regional Prediction System (ARPS) and (2) forecasts from multiple models (e.g., the 1998 Storm and Mesoscale Ensemble Experiment (SAMEX '98)) for the purpose of exploring how the selection of the performance metric can affect inferences about the quality and uncertainty of a forecast. We propose a new measure called forecast quality index, which combines image analysis and nonlinear shape comparison features, and we show that it is a more robust and informative metric compared to traditional metrics such as RMSE and EqTh. Copyright 2005 by the American Geophysical Union.},
	number = {8},
	journal = {Journal of Geophysical Research D: Atmospheres},
	author = {Venugopal, V. and Basu, S. and Foufoula-Georgiou, E.},
	month = apr,
	year = {2005},
	pages = {1--11},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/IREEQXS9/Journal of Geophysical Research  Atmospheres - 2005 - Venugopal - A new metric for comparing precipitation patterns with an.pdf:application/pdf},
}

@article{brocker_ensemble_2008,
	title = {From ensemble forecasts to predictive distribution functions},
	volume = {60 A},
	issn = {02806495},
	doi = {10.1111/j.1600-0870.2008.00333.x},
	abstract = {The translation of an ensemble of model runs into a probability distribution is a common task in model-based prediction. Common methods for such ensemble interpretations proceed as if verification and ensemble were draws from the same underlying distribution, an assumption not viable for most, if any, real world ensembles. An alternative is to consider an ensemble as merely a source of information rather than the possible scenarios of reality. This approach, which looks for maps between ensembles and probabilistic distributions, is investigated and extended. Common methods are revisited, and an improvement to standard kernel dressing, called 'affine kernel dressing' (AKD), is introduced. AKD assumes an affine mapping between ensemble and verification, typically not acting on individual ensemble members but on the entire ensemble as a whole, the parameters of this mapping are determined in parallel with the other dressing parameters, including a weight assigned to the unconditioned (climatological) distribution. These amendments to standard kernel dressing, albeit simple, can improve performance significantly and are shown to be appropriate for both overdispersive and underdispersive ensembles, unlike standard kernel dressing which exacerbates over dispersion. Studies are presented using operational numerical weather predictions for two locations and data from the Lorenz63 system, demonstrating both effectiveness given operational constraints and statistical significance given a large sample. © Journal compilation © 2008 Blackwell Munksgaard.},
	number = {4},
	journal = {Tellus, Series A: Dynamic Meteorology and Oceanography},
	author = {Bröcker, Jochen and Smith, Leonard A.},
	month = aug,
	year = {2008},
	pages = {663--678},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/BJ44FJZ9/From ensemble forecasts to predictive distribution (lsero).pdf:application/pdf},
}

@article{brocker_scoring_2007,
	title = {Scoring probabilistic forecasts: {The} importance of being proper},
	volume = {22},
	issn = {08828156},
	doi = {10.1175/WAF966.1},
	abstract = {Questions remain regarding how the skill of operational probabilistic forecasts is most usefully evaluated or compared, even though probability forecasts have been a long-standing aim in meteorological forecasting. This paper explains the importance of employing proper scores when selecting between the various measures of forecast skill. It is demonstrated that only proper scores provide internally consistent evaluations of probability forecasts, justifying the focus on proper scores independent of any attempt to influence the behavior of a forecaster. Another property of scores (i.e., locality) is discussed. Several scores are examined in this light. There is, effectively, only one proper, local score for probability forecasts of a continuous variable. It is also noted that operational needs of weather forecasts suggest that the current concept of a score may be too narrow; a possible generalization is motivated and discussed in the context of propriety and locality. © 2007 American Meteorological Society.},
	number = {2},
	journal = {Weather and Forecasting},
	author = {Bröcker, Jochen and Smith, Leonard A.},
	month = apr,
	year = {2007},
	pages = {382--388},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/55KYFZRS/1520-0434-waf966_1.pdf:application/pdf},
}

@article{peirolo_information_2011,
	title = {Information gain as a score for probabilistic forecasts},
	volume = {18},
	issn = {14698080},
	doi = {10.1002/met.188},
	abstract = {A measure of the information added by a probabilistic forecast to that contained in the climatological distribution is presented in this paper. This measure, called information gain, is mathematically closely related to the traditional ignorance score, but is more intuitive. Its advantages over other scores for probabilistic forecasts are also shown. The information gain score is tested on ECMWF ensemble forecasts of 500 hPa geopotential and 850 hPa temperature. The trends observed are in good agreement with those seen in other verification measures applied to the same data. In particular, the information gain decays with increasing lead time and increases over the years, in agreement with the improvement of the model. © 2010 Royal Meteorological Society.},
	number = {1},
	journal = {Meteorological Applications},
	author = {Peirolo, Riccardo},
	year = {2011},
	note = {Publisher: John Wiley and Sons Ltd},
	keywords = {★, Forecast verification, Information theory, Intuitive accuracy measure},
	pages = {9--17},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/SSIK8WPC/Meteorological Applications - 2011 - Peirolo - Information gain as a score for probabilistic forecasts.pdf:application/pdf},
}

@article{boe_statistical_2007,
	title = {Statistical and dynamical downscaling of the {Seine} basin climate for hydro-meteorological studies},
	volume = {27},
	issn = {08998418},
	doi = {10.1002/joc.1602},
	abstract = {Two downscaling methods designed for the study of the hydrological impact of climate change on the Seine basin in France are tested for present climate. First, a multivariate statistical downscaling (SD) methodology based on weather typing and conditional resampling is described. Then, a bias correction technique for dynamical downscaling based on quantile-quantile mapping is introduced. To evaluate the end-to-end SD methodology, the atmospheric forcing derived from the large-scale circulation (LSC) of the ERA40 reanalysis by SD is used to force a hydrological model. Simulated discharges reproduce historical values reasonably well. Next, the dynamical and statistical approaches are compared using the Météo-France ARPEGE general circulation model in a variable resolution configuration (resolution around 60 km over France). The ARPEGE simulation is downscaled using the two methodologies, and hydrological simulations are performed. Regarding downscaled temperature and precipitation, the statistical approach is more efficient in reproducing the temporal and spatial autocorrelation properties. The simulated river discharges from the two approaches are nevertheless very similar: the two methods reproduce well the seasonal cycle and the daily distribution of streamflows. Finally, the results of the study are discussed from a practical impact study perspective. Copyright © 2007 Royal Meteorological Society.},
	number = {12},
	journal = {International Journal of Climatology},
	author = {Boé, J. and Terray, L. and Habets, F. and Martin, E.},
	month = oct,
	year = {2007},
	keywords = {Climate change, Statistical downscaling, Bias correction, Dynamical downscaling, Hydrological impacts, Regional climate},
	pages = {1643--1655},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/45DYLMW6/Intl Journal of Climatology - 2007 - Bo - Statistical and dynamical downscaling of the Seine basin climate for.pdf:application/pdf},
}

@techreport{gneiting_calibration_2014,
	address = {Reading, UK},
	title = {Calibration of {Medium}-{Range} {Weather} {Forecasts}},
	url = {http://www.ecmwf.int/publications/},
	abstract = {Statistical postprocessing techniques serve to improve the quality of numerical weather forecasts, as they seek to generate calibrated and sharp predictive distributions of future weather quantities. This document reviews the state of the art in statistical postprocessing, with focus on potential applications to the European Centre for Medium-Range Weather Forecasts (ECMWF)'s Integrated Forecasting System (IFS). At present, a recommended way to proceed is to apply well established, state of the art postprocessing techniques, such as nonhomogeneous regression or Bayesian model averaging , to each univariate weather quantity separately, with training data usefully augmented by reforecast datasets. Areas requiring further research are identified, in particular the suitable size and efficient use of reforecast datasets, and the generation and evaluation of probabilistic forecasts of combined events and spatio-temporal weather trajectories, thereby addressing spatial, temporal and cross-variable dependence structures.},
	institution = {Gneiting, Tilmann. Calibration of medium-range weather forecasts. Reading, UK: European Centre for Medium-Range Weather Forecasts},
	author = {Gneiting, Tilmann},
	year = {2014},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/LR8FBAQP/9607-calibration-medium-range-weather-forecasts.pdf:application/pdf},
}

@incollection{wilks_statistical_2019,
	title = {Statistical {Forecasting}},
	booktitle = {Statistical {Methods} in the {Atmospheric} {Sciences}},
	publisher = {Elsevier},
	author = {Wilks, Daniel S.},
	year = {2019},
	doi = {10.1016/b978-0-12-815823-4.00007-9},
	pages = {235--312},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/FJ8MHWKV/3-s2.0-B9780128158234000079-main.pdf:application/pdf},
}

@incollection{doswell_severe_2001,
	title = {Severe {Convective} {Storms}—{An} {Overview}},
	abstract = {In general, convection, refers to the transport of some property by fluid movement, most often with reference to heat transport. As such, it is one of the three main processes by which heat is transported: radiation, conduction, and convection. Meteorologists...},
	booktitle = {Severe {Convective} {Storms}},
	publisher = {American Meteorological Society},
	author = {Doswell, Charles A.},
	year = {2001},
	doi = {10.1007/978-1-935704-06-5_1},
	pages = {1--26},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/HK9FQ2F9/Overview_Chapter.pdf:application/pdf},
}

@techreport{woodhams_d-r74-storm_2022,
	title = {D-{R7}.4-{Storm} predictability in the context of {CP} {Ensembles}},
	url = {https://projects.},
	author = {Woodhams, Beth J and Birch, Cathryn E},
	year = {2022},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/BLJ8MIB4/deliverable_R7_4.pdf:application/pdf},
}

@article{brier_verification_1950,
	title = {{VERIFICATION} {OF} {FORECASTS} {EXPRESSED} {IN} {TERMS} {OF} {PROBABILITY}},
	volume = {78},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/10.1175/1520-0493(1950)078<0001:VOFEIT>2.0.CO;2},
	doi = {10.1175/1520-0493(1950)078<0001:VOFEIT>2.0.CO;2},
	number = {1},
	journal = {Monthly Weather Review},
	author = {BRIER, GLENN W.},
	month = jan,
	year = {1950},
	pages = {1--3},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/H5PVW67W/1520-0493-1520-0493_1950_078_0001_vofeit_2_0_co_2 (1).pdf:application/pdf},
}

@techreport{waggoner_lecture_2017,
	title = {Lecture 23 {Proper} {Scoring} {Rules} and {Prediction} {Markets}},
	abstract = {Today we look at the question: How can we incentivize an agent or group of agents to make an accurate prediction? This is actually a simpler question than most of the mechanism-design settings considered in this class so far: our agents won't be getting items, only reporting predictions and receiving payments based on their accuracy.},
	author = {Waggoner, Bo},
	year = {2017},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/HHQJF2KK/lect23.pdf:application/pdf},
}

@article{carvalho_overview_2016,
	title = {An overview of applications of proper scoring rules},
	volume = {13},
	issn = {15458504},
	doi = {10.1287/deca.2016.0337},
	abstract = {We present a study on the evolution of publications about applications of proper scoring rules. Specifically, we consider articles reporting the use of proper scoring rules when either measuring the accuracy of forecasts or for inducing honest reporting of private information within a certain context. Our analysis of a data set containing 201 articles published between 1950 and 2015 suggests that there has been a tremendous increase in the number of published articles about proper scoring rules over the years. Moreover, the weather/climate, prediction markets, psychology, and energy domains are the four most popular application areas. After providing some insights on how proper scoring rules are applied in different domains, we analyze the publication outlets where the articles in our data set were published. In this regard, we find that an increasing number of articles are now being published in conference proceedings related to artificial intelligence, as opposed to traditional academic journals. We conclude this review by suggesting that the wisdom-of-crowds phenomenon might be a driving force behind the recent popularity of proper scoring rules.},
	number = {4},
	journal = {Decision Analysis},
	author = {Carvalho, Arthur},
	month = dec,
	year = {2016},
	note = {Publisher: INFORMS Inst.for Operations Res.and the Management Sciences},
	keywords = {Forecasting, Forecast evaluation, Incentive engineering, Proper scoring rules},
	pages = {223--242},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/WPR88D57/Carvalho16.pdf:application/pdf},
}

@article{gneiting_strictly_2007,
	title = {Strictly proper scoring rules, prediction, and estimation},
	volume = {102},
	issn = {01621459},
	doi = {10.1198/016214506000001437},
	abstract = {Scoring rules assess the quality of probabilistic forecasts, by assigning a numerical score based on the predictive distribution and on the event or value that materializes. A scoring rule is proper if the forecaster maximizes the expected score for an observation drawn from the distribution F if he or she issues the probabilistic forecast F, rather than G ≠ F. It is strictly proper if the maximum is unique. In prediction problems, proper scoring rules encourage the forecaster to make careful assessments and to be honest. In estimation problems, strictly proper scoring rules provide attractive loss and utility functions that can be tailored to the problem at hand. This article reviews and develops the theory of proper scoring rules on general probability spaces, and proposes and discusses examples thereof. Proper scoring rules derive from convex functions and relate to information measures, entropy functions, and Bregman divergences. In the case of categorical variables, we prove a rigorous version of the Savage representation. Examples of scoring rules for probabilistic forecasts in the form of predictive densities include the logarithmic, spherical, pseudospherical, and quadratic scores. The continuous ranked probability score applies to probabilistic forecasts that take the form of predictive cumulative distribution functions. It generalizes the absolute error and forms a special case of a new and very general type of score, the energy score. Like many other scoring rules, the energy score admits a kernel representation in terms of negative definite functions, with links to inequalities of Hoeffding type, in both univariate and multivariate settings. Proper scoring rules for quantile and interval forecasts are also discussed. We relate proper scoring rules to Bayes factors and to cross-validation, and propose a novel form of cross-validation known as random-fold cross-validation. A case study on probabilistic weather forecasts in the North American Pacific Northwest illustrates the importance of propriety. We note optimum score approaches to point and quantile estimation, and propose the intuitively appealing interval score as a utility function in interval estimation that addresses width as well as coverage. © 2007 American Statistical Association.},
	number = {477},
	journal = {Journal of the American Statistical Association},
	author = {Gneiting, Tilmann and Raftery, Adrian E.},
	month = mar,
	year = {2007},
	keywords = {Bayes factor, Bregman divergence, Brier score, Coherent, Continuous ranked probability score, Cross-validation, Entropy, Kernel score, Loss function, Minimum contrast estimation, Negative definite function},
	pages = {359--378},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/HIX7SYGJ/Gneiting2007jasa.pdf:application/pdf},
}

@techreport{hernandez-orallo_unified_2012,
	title = {A {Unified} {View} of {Performance} {Metrics}: {Translating} {Threshold} {Choice} into {Expected} {Classification} {Loss} {C}` esar {Ferri}},
	abstract = {Many performance metrics have been introduced in the literature for the evaluation of classification performance, each of them with different origins and areas of application. These metrics include accuracy, unweighted accuracy, the area under the ROC curve or the ROC convex hull, the mean absolute error and the Brier score or mean squared error (with its decomposition into refinement and calibration). One way of understanding the relations among these metrics is by means of variable operating conditions (in the form of misclassification costs and/or class distributions). Thus, a metric may correspond to some expected loss over different operating conditions. One dimension for the analysis has been the distribution for this range of operating conditions, leading to some important connections in the area of proper scoring rules. We demonstrate in this paper that there is an equally important dimension which has so far received much less attention in the analysis of performance metrics. This dimension is given by the decision rule, which is typically implemented as a threshold choice method when using scoring models. In this paper, we explore many old and new threshold choice methods: fixed, score-uniform, score-driven, rate-driven and optimal, among others. By calculating the expected loss obtained with these threshold choice methods for a uniform range of operating conditions we give clear interpretations of the 0-1 loss, the absolute error, the Brier score, the AUC and the refinement loss respectively. Our analysis provides a comprehensive view of performance metrics as well as a systematic approach to loss minimisation which can be summarised as follows: given a model, apply the threshold choice methods that correspond with the available information about the operating condition, and compare their expected losses. In order to assist in this procedure we also derive several connections between the aforementioned performance metrics, and we highlight the role of calibration in choosing the threshold choice method.},
	author = {Hernández-Orallo, José and Flach PETERFLACH, Peter},
	year = {2012},
	note = {Publication Title: Journal of Machine Learning Research
Volume: 13},
	keywords = {Brier score, area under the ROC curve (AUC), calibration loss, classification performance metrics, cost-sensitive evaluation, operating condition, refinement loss},
	pages = {2813--2869},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/EHUGTP39/hernandez-orallo12a.pdf:application/pdf},
}

@article{villani_celso_nodate,
	title = {Celso {Augusto} {Guimarães} {Santos} {STATISTICAL} {APPROACHES} {VERSUS} {WEATHER} {GENERATOR} {TO} {DOWNSCALE} {RCM} {OUTPUTS} {TO} {POINT} {SCALE}: {A} {COMPARISON} {OF} {PERFORMANCES}},
	volume = {8},
	url = {https://www.jstor.org/stable/10.2307/26203419},
	doi = {10.2307/26203419},
	number = {2},
	journal = {Journal of Urban and Environmental Engineering},
	author = {Villani, Veronica and Rianna, Guido and Mercogliano, Paola and Zollo, Alessandra Lucia and Schiano, Pasquale},
	pages = {142--154},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/T46BQKMB/26203419.pdf:application/pdf},
}

@book{barry_atmosphere_2009,
	title = {Atmosphere, {Weather} and {Climate}},
	isbn = {978-0-203-87102-7},
	publisher = {Routledge},
	author = {Barry, Roger G. and Chorley, Richard J},
	month = oct,
	year = {2009},
	doi = {10.4324/9780203871027},
}

@article{roca_comparing_2010,
	title = {Comparing satellite and surface rainfall products over {West} {Africa} at meteorologically relevant scales during the {AMMA} campaign using error estimates},
	volume = {49},
	issn = {15588424},
	doi = {10.1175/2009JAMC2318.1},
	abstract = {Monsoon rainfall is central to the climate of West Africa, and understanding its variability is a challenge for which satellite rainfall products could be well suited to contribute to. Their quality in this region has received less attention than elsewhere. The focus is set on the scales associated with atmospheric variability, and a meteorological benchmark is set up with ground-based observations from the African Monsoon Multidisciplinary Analysis (AMMA) program. The investigation is performed at various scales of accumulation using four gauge networks. The seasonal cycle is analyzed using 10-day-averaged products, the synoptic-scale variability is analyzed using daily means, and the diurnal cycle of rainfall is analyzed at the seasonal scale using a composite and at the diurnal scale using 3-hourly accumulations. A novel methodology is introduced that accounts for the errors associated with the areal-time rainfall averages. The errors from both satellite and ground rainfall data are computed using dedicated techniques that come down to an estimation of the sampling errors associated to these measurements. The results show that the new generation of combined infrared-microwave (IR-MW) satellite products is describing the rain variability similarly to ground measurements. At the 10-day scale, all products reveal high regional and seasonal skills. The day-to-day comparison indicates that some products perform better than others, whereas all of them exhibit high skills when the spectral band of African easterly waves is considered. The seasonal variability of the diurnal scale as well as its relative daily importance is only captured by some products. Plans for future extensive intercomparison exercises are briefly discussed. © 2010 American Meteorological Society.},
	number = {4},
	journal = {Journal of Applied Meteorology and Climatology},
	author = {Roca, Rémy and Chambon, Philippe and Jobard, Isabelle and Kirstetter, Pierre Emmanuel and Gosset, Marielle and Bergés, Jean Claude},
	year = {2010},
	note = {Publisher: American Meteorological Society},
	pages = {715--731},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/98NG748Q/1558-8432-2009jamc2318.1.pdf:application/pdf},
}

@article{wainwright_extreme_2021,
	title = {Extreme rainfall in {East} {Africa}, {October} 2019–{January} 2020 and context under future climate change},
	volume = {76},
	issn = {0043-1656},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/wea.3824},
	doi = {10.1002/wea.3824},
	number = {1},
	journal = {Weather},
	author = {Wainwright, Caroline M. and Finney, Declan L. and Kilavi, Mary and Black, Emily and Marsham, John H.},
	month = jan,
	year = {2021},
	keywords = {★},
	pages = {26--31},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/GSN7T42Z/Weather - 2020 - Wainwright - Extreme rainfall in East Africa  October 2019 January 2020 and context under future climate.pdf:application/pdf},
}

@article{hendon_diurnal_1993,
	title = {The diurnal cycle of tropical convection},
	volume = {98},
	issn = {01480227},
	doi = {10.1029/93jd00525},
	abstract = {The diurnal cycle of tropical convection is investigated with global cloud imagery constructed from 11μm radiance measurements taken aboard six satellites. To isolate deep convective activity from other processes which cause diurnal fluctuations in longwave radiance, an index of deep convective activity is constructed by thresholding to brightness temperatures less than 230 K. Significant diurnal amplitude of deep convection is found only over tropical landmasses. Over the tropical oceans the diurnal cycle is weak and is barely discernible from the background red spectrum of convective variance. Oceanic convection exhibits a systematic diurnal fluctuation with maximum intensity in the early morning. Nocturnal subsidence along the cloud-free equator is postulated to play a role in forcing diurnal variation in the intertropical convergence zones. Other mechanisms are also implied to contribute as a similar early morning maximum in deep convection is seen even where no adjoining cloud-free regions occur. -from Authors},
	number = {D9},
	journal = {Journal of Geophysical Research},
	author = {Hendon, H. H. and Woodberry, K.},
	year = {1993},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/VN9ETVZQ/Journal of Geophysical Research  Atmospheres - 20 September 1993 - Hendon - The diurnal cycle of tropical convection.pdf:application/pdf},
}

@incollection{wilks_parametric_2019,
	title = {Parametric {Probability} {Distributions}},
	booktitle = {Statistical {Methods} in the {Atmospheric} {Sciences}},
	publisher = {Elsevier},
	author = {Wilks, Daniel S.},
	year = {2019},
	doi = {10.1016/b978-0-12-815823-4.00004-3},
	pages = {77--141},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/GAA229C5/3-s2.0-B9780128158234000043-main.pdf:application/pdf},
}

@article{holthuijzen_robust_2022,
	title = {Robust bias-correction of precipitation extremes using a novel hybrid empirical quantile-mapping method: {Advantages} of a linear correction for extremes},
	volume = {149},
	issn = {14344483},
	doi = {10.1007/s00704-022-04035-2},
	abstract = {High-resolution, daily precipitation climate products that realistically represent extremes are critical for evaluating local-scale climate impacts. A popular bias-correction method, empirical quantile mapping (EQM), can generally correct distributional discrepancies between simulated climate variables and observed data but can be highly sensitive to the choice of calibration period and is prone to overfitting. In this study, we propose a hybrid bias-correction method for precipitation, EQM-LIN, which combines the efficacy of EQM for correcting lower quantiles, with a robust linear correction for upper quantiles. We apply both EQM and EQM-LIN to historical daily precipitation data simulated by a regional climate model over a region in the northeastern USA. We validate our results using a five-fold cross-validation and quantify performance of EQM and EQM-LIN using skill score metrics and several climatological indices. As part of a high-resolution downscaling and bias-correction workflow, EQM-LIN significantly outperforms EQM in reducing mean, and especially extreme, daily distributional biases present in raw model output. EQM-LIN performed as good or better than EQM in terms of bias-correcting standard climatological indices (e.g., total annual rainfall, frequency of wet days, total annual extreme rainfall). In addition, our study shows that EQM-LIN is particularly resistant to overfitting at extreme tails and is much less sensitive to calibration data, both of which can reduce the uncertainty of bias-correction at extremes.},
	number = {1-2},
	journal = {Theoretical and Applied Climatology},
	author = {Holthuijzen, Maike and Beckage, Brian and Clemins, Patrick J. and Higdon, Dave and Winter, Jonathan M.},
	month = jul,
	year = {2022},
	note = {Publisher: Springer},
	pages = {863--882},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/KU4YYDCL/s00704-022-04035-2 (1).pdf:application/pdf},
}

@article{qian_projecting_2021,
	title = {Projecting health impacts of future temperature: {A} comparison of quantile‐mapping bias‐correction methods},
	volume = {18},
	issn = {16604601},
	doi = {10.3390/ijerph18041992},
	abstract = {Health impact assessments of future environmental exposures are routinely conducted to quantify population burdens associated with the changing climate. It is well‐recognized that simulations from climate models need to be bias‐corrected against observations to estimate future expo-sures. Quantile mapping (QM) is a technique that has gained popularity in climate science because of its focus on bias‐correcting the entire exposure distribution. Even though improved bias‐correc-tion at the extreme tails of exposure may be particularly important for estimating health burdens, the application of QM in health impact projection has been limited. In this paper we describe and apply five QM methods to estimate excess emergency department (ED) visits due to projected changes in warm‐season minimum temperature in Atlanta, USA. We utilized temperature projections from an ensemble of regional climate models in the North American‐Coordinated Regional Climate Downscaling Experiment (NA‐CORDEX). Across QM methods, we estimated consistent increase in ED visits across climate model ensemble under RCP 8.5 during the period 2050 to 2099. We found that QM methods can significantly reduce between‐model variation in health impact projections (50–70\% decreases in between‐model standard deviation). Particularly, the quantile delta mapping approach had the largest reduction and is recommended also because of its ability to preserve model‐projected absolute temporal changes in quantiles.},
	number = {4},
	journal = {International Journal of Environmental Research and Public Health},
	author = {Qian, Weijia and Chang, Howard H.},
	month = feb,
	year = {2021},
	pmid = {33670819},
	note = {Publisher: MDPI AG},
	keywords = {Climate change, Bias‐correction, Emergency department visits, Health impact, Quantile mapping, Temperature},
	pages = {1--12},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/KEKP63RP/ijerph-18-01992.pdf:application/pdf},
}

@article{gudmundsson_quantile_2012,
	title = {Quantile mapping {Hydrology} and {Earth} {System} {Sciences} {Discussions} {Technical} {Note}: {Downscaling} {RCM} precipitation to the station scale using quantile mapping-a comparison of methods {Quantile} mapping},
	volume = {9},
	url = {www.hydrol-earth-syst-sci-discuss.net/9/6185/2012/},
	doi = {10.5194/hessd-9-6185-2012},
	abstract = {The impact of climate change on water resources is usually assessed at the local scale. However, regional climate models (RCM) are known to exhibit systematic biases in precipitation. Hence, RCM simulations need to be post-processed in order to produce reliable estimators of local scale climate. A popular post-processing approach is 5 quantile mapping (QM), which is designed to adjust the distribution of modeled data, such that it matches observed climatologies. However, the diversity of suggested QM methods renders the selection of optimal techniques difficult and hence there is a need for clarification. In this paper, QM methods are reviewed and classified into: (1) distribution derived transformations, (2) parametric transformations and (3) nonparametric 10 transformations; each differing with respect to their underlying assumptions. A real world application, using observations of 82 precipitation stations in Norway, showed that nonparametric transformations have the highest skill in systematically reducing biases in RCM precipitation.},
	journal = {Hydrol. Earth Syst. Sci. Discuss},
	author = {Gudmundsson, L and Bremnes, J B and Haugen, J E and Skaugen, T Engen},
	year = {2012},
	pages = {6185--6201},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/77JUMICC/hessd-9-6185-2012 (1).pdf:application/pdf},
}

@article{chamberlain_forecasting_2014,
	title = {Forecasting storms over {Lake} {Victoria} using a high resolution model},
	volume = {21},
	issn = {14698080},
	doi = {10.1002/met.1403},
	abstract = {Lake Victoria in East Africa is one of the world's largest freshwater lakes and is used on a daily basis by thousands of fishermen. Each year, severe storms on the lake cause multiple boating accidents which often result in fatalities. Recent initiatives have seen an effort to reduce accidents by issuing storm warnings when severe weather is expected. Here the Met Office global Unified Model is evaluated along with a 4km limited-area model which has been set up to assist forecasters in the region to issue these warnings. Findings indicate the 4km model is capable of producing more realistic strong wind speeds and rain rates than the global model. Case studies relating to fatal boating accidents on 1March and 4March2012, showed improved warning signals of severe storms in the 4km model compared to the global model. Objective comparisons between model and observations were conducted on 2months of data. An objective method was used to determine 'storm'/'no storm' in the model forecasts. These were then compared against cloud top temperature from IR satellite and lightning data from the arrival time difference (ATD) radio ground network to determine whether each model was successful at forecasting storm/calm events. The 4km model was able to capture more storm hits (thus had fewer storm misses), but also gained more false alarm events. Overall, the objective analysis showed that both models had some predictive skill and both were an improvement on a persistence forecast. © 2013 Royal Meteorological Society.},
	number = {2},
	journal = {Meteorological Applications},
	author = {Chamberlain, J. M. and Bain, C. L. and Boyd, D. F.A. and Mccourt, K. and Butcher, T. and Palmer, S.},
	year = {2014},
	note = {Publisher: John Wiley and Sons Ltd},
	keywords = {Forecasting, Lake Victoria, Limited area model, Met Office, Tropical thunderstorms, Uganda},
	pages = {419--430},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/PVRQ6EGX/Meteorological Applications - 2013 - Chamberlain - Forecasting storms over Lake Victoria using a high resolution model.pdf:application/pdf},
}

@article{wheeler_convectively_1999,
	title = {Convectively {Coupled} {Equatorial} {Waves}: {Analysis} of {Clouds} and {Temperature} in the {Wavenumber}–{Frequency} {Domain}},
	volume = {56},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/10.1175/1520-0469(1999)056<0374:CCEWAO>2.0.CO;2},
	doi = {10.1175/1520-0469(1999)056<0374:CCEWAO>2.0.CO;2},
	abstract = {A wavenumber-frequency spectrum analysis is performed for all longitudes in the domain 15S-15N using a long (18 years) twice-daily record of satellite-observed outgoing longwave radiation (OLR), a good proxy for deep tropical convection. The broad nature of the spectrum is red in both zonal wavenumber and frequency. By removing an estimated background spectrum, numerous statistically significant spectral peaks are isolated. Some of the peaks correspond quite well to the dispersion relations of the equatorially trapped wave modes of shallow water theory with implied equivalent depths in the range of 12-50 m. Cross-spectrum analysis with the satellite-based microwave sounding unit deep-layer temperature data shows that these spectral peaks in the OLR are ''coupled'' with this dynamical field. The equivalent depths of the convectively coupled waves are shallower than those typical of equatorial waves uncoupled with convection. Such a small equivalent depth is thought to be a result of the interaction between convection and the dynamics. The convectively coupled equatorial waves identified correspond to the Kelvin, n 1 equatorial Rossby, mixed Rossby-gravity, n 0 eastward inertio-gravity, n 1 westward inertio-gravity (WIG), and n 2 WIG waves. Additionally, the Madden-Julian oscillation and tropical depression-type disturbances are present in the OLR spectra. These latter two features are unlike the convectively coupled equatorial waves due to their location away from the equatorial wave dispersion curves in the wavenumber-frequency domain. Extraction of the different convectively coupled disturbances in the time-longitude domain is performed by filtering the OLR dataset for very specific zonal wavenumbers and frequencies. The geographical distribution of the variance of these filtered data gives further evidence that some of the spectral peaks correspond to particular equatorial wave modes. The results have implications for the cumulus parameterization problem, for the excitation of equatorial waves in the lower stratosphere, and for extended-range forecasting in the Tropics.},
	number = {3},
	journal = {Journal of the Atmospheric Sciences},
	author = {Wheeler, Matthew and Kiladis, George N.},
	month = feb,
	year = {1999},
	pages = {374--399},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/XAZH4SJN/1520-0469-1520-0469_1999_056_0374_ccewao_2.0.co_2.pdf:application/pdf},
}

@article{lin_tropical_2006,
	title = {Tropical {Intraseasonal} {Variability} in 14 {IPCC} {AR4} {Climate} {Models}. {Part} {I}: {Convective} {Signals}},
	volume = {19},
	issn = {1520-0442},
	url = {http://journals.ametsoc.org/doi/10.1175/JCLI3735.1},
	doi = {10.1175/JCLI3735.1},
	abstract = {{\textless}p{\textgreater}This study evaluates the tropical intraseasonal variability, especially the fidelity of Madden–Julian oscillation (MJO) simulations, in 14 coupled general circulation models (GCMs) participating in the Intergovernmental Panel on Climate Change (IPCC) Fourth Assessment Report (AR4). Eight years of daily precipitation from each model’s twentieth-century climate simulation are analyzed and compared with daily satellite-retrieved precipitation. Space–time spectral analysis is used to obtain the variance and phase speed of dominant convectively coupled equatorial waves, including the MJO, Kelvin, equatorial Rossby (ER), mixed Rossby–gravity (MRG), and eastward inertio–gravity (EIG) and westward inertio–gravity (WIG) waves. The variance and propagation of the MJO, defined as the eastward wavenumbers 1–6, 30–70-day mode, are examined in detail.{\textless}/p{\textgreater}},
	number = {12},
	urldate = {2023-02-20},
	journal = {Journal of Climate},
	author = {Lin, Jia-Lin and Kiladis, George N. and Mapes, Brian E. and Weickmann, Klaus M. and Sperber, Kenneth R. and Lin, Wuyin and Wheeler, Matthew C. and Schubert, Siegfried D. and Del Genio, Anthony and Donner, Leo J. and Emori, Seita and Gueremy, Jean-Francois and Hourdin, Frederic and Rasch, Philip J. and Roeckner, Erich and Scinocca, John F.},
	month = jun,
	year = {2006},
	pages = {2665--2690},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/8ZS9MCUB/1520-0442-jcli3735.1.pdf:application/pdf},
}

@article{ruane_6-hour_2007,
	title = {6-{Hour} to 1-year variance of five global precipitation sets},
	volume = {11},
	issn = {10873562},
	doi = {10.1175/EI225.1},
	abstract = {Three-hourly time series of precipitation from three highresolution precipitation products [Tropical Rainfall Measuring Mission (TRMM) algorithm 3B-42, the Climate Prediction Center's morphing method (CMORPH), and the Precipitation Estimation from Remotely Sensed Information Using Artificial Neural Networks (PERSIANN)] and two reanalyses are examined for their frequency characteristics using broad and narrow variance categories. After isolating the diurnally forced peaks (at 24, 12, 8, and 6 h), the power spectra are divided into comprehensive broad bands comprising the annual (∼80 days-1 yr), intraseasonal (20 to ∼80 days), slow (6-20 days) and fast (36 h-6 days) synoptic, and high-frequency (6-36 h) periods. Global maps accounting for 100\% of precipitation's variance are analyzed to identify unique regional behaviors. Annual variability is strongest over regions affected by the seasonal migration of the intertropical convergence zone, as well as over monsoonal regions. The intraseasonal band displays off-equatorial evidence of the Madden-Julian oscillation (MJO), particularly in the Indian Ocean, but the MJO's rainfall is partially manifested in the slow synoptic band and at higher frequencies. The fast synoptic band is particularly strong over the oceans, while high-frequency variability is enhanced over land by more extreme surface gradients. Diurnal variance is strongest at low latitudes and is pronounced over regions with well-known diurnal circulations, including mountains and coastlines. Interproduct and intermodel differences also indicate biases of the precipitation product algorithms and convective parameterizations, including a strong bias toward low-frequency variability in the relaxed Arakawa-Schubert parameterization employed by one of the reanalyses, as well as increased white-spectral characteristics over land in the precipitation products.},
	number = {11},
	journal = {Earth Interactions},
	author = {Ruane, Alex C. and Roads, John O.},
	year = {2007},
	note = {Publisher: American Meteorological Society},
	keywords = {Model comparison, Precipitation, Diurnal effects, Intraseasonal variability, Madden-julian oscillation},
	pages = {1--29},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/52SDGPSM/1087-3562-ei225.1.pdf:application/pdf},
}

@article{kim_tropical_2013,
	title = {Tropical precipitation variability and convectively coupled equatorial waves on submonthly time scales in reanalyses and {TRMM}},
	volume = {26},
	issn = {08948755},
	doi = {10.1175/JCLI-D-12-00353.1},
	abstract = {Tropical precipitation characteristics are investigated using the Tropical Rainfall Measuring Mission (TRMM) 3-hourly estimates, and the result is compared with five reanalyses including the European Centre for Medium-Range Weather Forecasts (ECMWF) Interim Re-Analysis (ERA-Interim), Modern Era Retrospective Analysis for Research and Applications (MERRA), National Centers for Environmental Prediction (NCEP)-National Center for Atmospheric Research (NCAR) reanalysis (NCEP1), NCEP-U.S. Department of Energy (DOE) reanalysis (NCEP2), and NCEP-Climate Forecast System Reanalysis (CFSR). Precipitation characteristics are evaluated in terms of the mean, convectively coupled equatorial wave activity, frequency characteristics, diurnal cycle, and seasonality of regional precipitation variability associated with submonthly scale waves. Generally the latest reanalyses such as ERA-Interim, MERRA, and CFSR show better performances than NCEP1 and NCEP2. However, all the reanalyses are still different from observations. Besides the positive mean bias in the reanalyses, a spectral analysis revealed that the reanalyses have overreddened spectra with persistent rainfall. MERRA has the most persistent rainfall, and CFSR appears to have the most realistic variability. The diurnal cycle in NCEP1 is extremely exaggerated relative to TRMM. The low-frequency waves with the period longer than 3 days are relatively well represented in ERAInterim, MERRA, and CFSR, but all the reanalyses have significant deficiencies in representing convectively coupled equatorial waves and variability in the high-frequency range. © 2013 American Meteorological Society.},
	number = {10},
	journal = {Journal of Climate},
	author = {Kim, Ji Eun and Joan Alexander, M.},
	month = may,
	year = {2013},
	pages = {3013--3030},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/J94DEI3S/1520-0442-jcli-d-12-00353.1.pdf:application/pdf},
}

@article{noauthor_normal_nodate,
	title = {On normal approximations for the non-central {F}-distribution},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/8LA8562T/09Apr2013021506On normal approximations for the non-central F-distribution.pdf:application/pdf},
}

@incollection{stensrud_convective_2013,
	title = {Convective parameterizations},
	booktitle = {Parameterization {Schemes}},
	publisher = {Cambridge University Press},
	author = {Stensrud, David J.},
	month = sep,
	year = {2013},
	doi = {10.1017/cbo9780511812590.007},
	pages = {185--259},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/KY6Q9ZW4/convective_parameterizations.pdf:application/pdf},
}

@article{schwarz_frequency_2021,
	title = {On the {Frequency} {Bias} of {Generative} {Models}},
	volume = {34},
	url = {https://github.com/},
	abstract = {The key objective of Generative Adversarial Networks (GANs) is to generate new data with the same statistics as the provided training data. However, multiple recent works show that state-of-the-art architectures yet struggle to achieve this goal. In particular, they report an elevated amount of high frequencies in the spectral statistics which makes it straightforward to distinguish real and generated images. Explanations for this phenomenon are controversial: While most works attribute the artifacts to the generator, other works point to the discriminator. We take a sober look at those explanations and provide insights on what makes proposed measures against high-frequency artifacts effective. To achieve this, we first independently assess the architectures of both the generator and discriminator and investigate if they exhibit a frequency bias that makes learning the distribution of high-frequency content particularly problematic. Based on these experiments, we make the following four observations: 1) Different upsampling operations bias the generator towards different spectral properties. 2) Checkerboard artifacts introduced by upsampling cannot explain the spectral discrepancies alone as the generator is able to compensate for these artifacts. 3) The discriminator does not struggle with detecting high frequencies per se but rather struggles with frequencies of low magnitude. 4) The downsampling operations in the discriminator can impair the quality of the training signal it provides. In light of these findings, we analyze proposed measures against high-frequency artifacts in state-of-the-art GAN training but find that none of the existing approaches can fully resolve spectral artifacts yet. Our results suggest that there is great potential in improving the discriminator and that this could be key to match the distribution of the training data more closely.},
	journal = {Advances in Neural Information Processing Systems},
	author = {Schwarz, Katja and Liao, Yiyi and Geiger, Andreas},
	year = {2021},
	pages = {18126--18136},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/Q34XS44L/Schwarz2021NEURIPS.pdf:application/pdf},
}

@article{dezfuli_validation_2017,
	title = {Validation of {IMERG} {Precipitation} in {Africa}},
	volume = {18},
	url = {https://doi.org/10.1175/},
	doi = {10.1175/JHM-D-17-0139.s1},
	abstract = {Understanding of hydroclimatic processes in Africa has been hindered by the lack of in situ precipitation measurements. Satellite-based observations, in particular, the TRMM Multisatellite Precipitation Analysis (TMPA) have been pivotal to filling this void. The recently released Integrated Multisatellite Retrievals for GPM (IMERG) project aims to continue the legacy of its predecessor, TMPA, and provide higher-resolution data. Here, IMERG-V04A precipitation data are validated using in situ observations from the Trans-African Hydro-Meteorological Observatory (TAHMO) project. Various evaluation measures are examined over a select number of stations in West and East Africa. In addition, continent-wide comparisons are made between IMERG and TMPA. The results show that the performance of the satellite-based products varies by season, region, and the evaluation statistics. The precipitation diurnal cycle is relatively better captured by IMERG than TMPA. Both products exhibit a better agreement with gauge data in East Africa and humid West Africa than in the southern Sahel. However, a clear advantage for IMERG is not apparent in detecting the annual cycle. Although all gridded products used here reasonably capture the annual cycle, some differences are evident during the short rains in East Africa. Direct comparison between IMERG and TMPA over the entire continent reveals that the similarity between the two products is also regionally heterogeneous. Except for Zimbabwe and Madagascar, where both satellite-based observations present a good agreement, the two products generally have their largest differences over mountainous regions. IMERG seems to have achieved a reduction in the positive bias evident in TMPA over Lake Victoria.},
	number = {10},
	journal = {Journal of Hydrometeorology},
	author = {Dezfuli, Amin K and Ichoku, Charles M and Huffman, George J and Mohr, Karen I and Selker, John S and De Giesen, Nick Van and Hochreutener, Rebecca and Annor, Frank O},
	year = {2017},
	pages = {2817--2825},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/XASYFAED/1525-7541-jhm-d-17-0139_1.pdf:application/pdf},
}

@article{woodhams_what_2018,
	title = {What is the added value of a convection-permitting model for forecasting extreme rainfall over tropical {East} {Africa}?},
	volume = {146},
	issn = {15200493},
	doi = {10.1175/MWR-D-17-0396.1},
	abstract = {Forecasting convective rainfall in the tropics is a major challenge for numerical weather prediction. The use of convection-permitting (CP) forecast models in the tropics has lagged behind the midlatitudes, despite the great potential of such models in this region. In the scientific literature, there is very little evaluation of CP models in the tropics, especially over an extended time period. This paper evaluates the prediction of convective storms for a period of 2 years in the Met Office operational CP model over East Africa and the global operational forecast model. A novel localized form of the fractions skill score is introduced, which shows variation in model skill across the spatial domain. Overall, the CP model and the global model both outperform a 24-h persistence forecast. The CP model shows greater skill than the global model, in particular on subdaily time scales and for storms over land. Forecasts over Lake Victoria are also improved in the CP model, with an increase in hit rate of up to 20\%. Contrary to studies in the midlatitudes, the skill of both models shows a large dependence on the time of day and comparatively little dependence on the forecast lead time within a 48-h forecast. Although these results provide more motivation for forecasters to use the CP model to produce subdaily forecasts with increased detail, there is a clear need for more in situ observations for data assimilation into the models and for verification. A move toward ensemble forecasting could have further benefits.},
	number = {9},
	journal = {Monthly Weather Review},
	author = {Woodhams, Beth J. and Birch, Cathryn E. and Marsham, John H. and Bain, Caroline L. and Roberts, Nigel M. and Boyd, Douglas F.A.},
	month = sep,
	year = {2018},
	note = {Publisher: American Meteorological Society},
	keywords = {★, Model evaluation/performance, Rainfall, Africa, Cloud resolving models, Inland seas/lakes, Regional models},
	pages = {2757--2780},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/ITU2I3DD/mwr-d-17-0396.1.pdf:application/pdf},
}

@article{macleod_drivers_2021,
	title = {Drivers and {Subseasonal} {Predictability} of {Heavy} {Rainfall} in {Equatorial} {East} {Africa} and {Relationship} with {Flood} {Risk}},
	volume = {22},
	url = {https://doi.org/10.1175/JHM-D-20-},
	doi = {10.1175/JHM-D-20},
	abstract = {Equatorial East Africa (EEA) suffers from significant flood risks. These can be mitigated with preemptive action; however, currently available early warnings are limited to a few days' lead time. Extending warnings using subseasonal climate forecasts could open a window for more extensive preparedness activity. However, before these forecasts can be used, the basis of their skill and relevance for flood risk must be established. Here we demonstrate that subseasonal forecasts are particularly skillful over EEA. Forecasts can skillfully anticipate weekly upper-quintile rainfall within a season, at lead times of 2 weeks and beyond. We demonstrate the link between the Madden-Julian oscillation (MJO) and extreme rainfall events in the region, and confirm that leading forecast models accurately represent the EEA teleconnection to the MJO. The relevance of weekly rainfall totals for fluvial flood risk in the region is investigated using a long record of streamflow from the Nzoia River in western Kenya. Both heavy rainfall and high antecedent rainfall conditions are identified as key drivers of flood risk, with upper-quintile weekly rainfall shown to skillfully discriminate flood events. We additionally evaluate GloFAS global flood forecasts for the Nzoia basin. Though these are able to anticipate some flooding events with several weeks lead time, analysis suggests action based on these would result in a false alarm more than 50\% of the time. Overall, these results build on the scientific evidence base that supports the use of subseasonal forecasts in EEA, and activities to advance their use are discussed.},
	number = {4},
	journal = {Journal of Hydrometeorology},
	author = {Macleod, David A and Dankers, Rutger and Graham, Richard and Guigma, Kiswendsida and Jenkins, Luke and Todd, Martin C and Kiptum, Augustine and Kilavi, Mary and Njogu, Andrew and Mwangi, Emmah},
	year = {2021},
	keywords = {Forecast verification/skill, Africa, Madden-Julian oscillation, Flood events},
	pages = {887--903},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/69ZL78TZ/1525-7541-JHM-D-20-0211.1.pdf:application/pdf},
}

@article{engel_extreme_nodate,
	title = {Extreme {Precipitation} in the {West} {African} {Cities} of {Dakar} and {Ouagadougou}: {Atmo}-spheric {Dynamics} and {Implications} for {Flood} {Risk} {Assessments}},
	url = {https://doi.org/10.1175/JHM-D-16-0218.s1.},
	doi = {10.1175/JHM-D-16-0218.s1},
	abstract = {Two extreme, high-impact events of heavy rainfall and severe floods in West African urban areas (Ouagadougou on 1 September 2009 and Dakar on 26 August 2012) are investigated with respect to their atmospheric causes and statistical return periods. In terms of the synoptic-convective dynamics, the Ouagadougou case is truly extraordinary. A succession of two slow-moving African easterly waves (AEWs) caused record-breaking values of tropospheric moisture. The second AEW, one of the strongest in recent decades, provided the synoptic forcing for the nighttime genesis of mesoscale convective systems (MCSs). Ouagadougou was hit by two MCSs within 6 h, as the strong convergence and rotation in the AEW-related vortex allowed a swift moisture refueling. An AEW was also instrumental in the overnight development of MCSs in the Dakar case, but neither the AEW vortex nor the tropospheric moisture content was as exceptional as in the Ouagadougou case. Tropical Rainfall Measuring Mission (TRMM) 3B42 precipitation data show some promise in estimating centennial return values (RVs) using the ''peak over threshold'' approach with a generalized Pareto distribution fit, although indications for errors in estimating extreme rainfall over the arid Sahel are found. In contrast, the Precipitation Estimation from Remotely Sensed Information Using Artificial Neural Networks-Climate Data Record (PERSIANN-CDR) dataset seems less suitable for this purpose despite the longer record. Notably, the Ouagadougou event demonstrates that highly unusual dynamical developments can create extremes well outside of RV estimates from century-long rainfall observations. Future research will investigate whether such developments may become more frequent in a warmer climate.},
	author = {Engel, Thomas and Fink, Andreas H and Knippertz, Peter and Pante, Gregor and Bliefernicht, Jan},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/ZXCABDAX/1525-7541-jhm-d-16-0218_1.pdf:application/pdf},
}

@article{haiden_intercomparison_2012,
	title = {Intercomparison of global model precipitation forecast skill in 2010/11 using the {SEEPS} score},
	volume = {140},
	issn = {00270644},
	doi = {10.1175/MWR-D-11-00301.1},
	abstract = {Precipitation forecasts from five global numerical weather prediction (NWP) models are verified against rain gauge observations using the new stable equitable error in probability space (SEEPS) score. It is based on a 3 × 3 contingency table and measures the ability of a forecast to discriminate between "dry," "light precipitation," and "heavy precipitation." In SEEPS, the threshold defining the boundary between the light and heavy categories varies systematically with precipitation climate. Results obtained for SEEPS are compared to those of more well-known scores, and are broken down with regard to individual contributions from the contingency table. It is found that differences in skill between the models are consistent for different scores, but are small compared to seasonal and geographical variations, which themselves can be largely ascribed to the varying prevalence of deep convection. Differences between the tropics and extratropics are quite pronounced. SEEPS scores at forecast day 1 in the tropics are similar to those at day 6 in the extratropics. It is found that the model ranking is robust with respect to choices in the score computation. The issue of observation representativeness is addressed using a "quasi-perfect model" approach. Results suggest that just under one-half of the current forecast error at day 1 in the extratropics can be attributed to the fact that gridbox values are verified against point observations. © 2012 American Meteorological Society.},
	number = {8},
	journal = {Monthly Weather Review},
	author = {Haiden, Thomas and Rodwell, Mark J. and Richardson, David S. and Okagaki, Akira and Robinson, Tom and Hewson, Tim},
	month = aug,
	year = {2012},
	keywords = {Forecast verification},
	pages = {2720--2733},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/TATQFVP4/1520-0493-mwr-d-11-00301.1.pdf:application/pdf},
}

@article{rasp_neural_2018,
	title = {Neural {Networks} for {Postprocessing} {Ensemble} {Weather} {Forecasts}},
	volume = {146},
	url = {https://doi.org/10.1175/MWR-D-18-},
	doi = {10.1175/MWR-D-18},
	abstract = {Ensemble weather predictions require statistical postprocessing of systematic errors to obtain reliable and accurate probabilistic forecasts. Traditionally, this is accomplished with distributional regression models in which the parameters of a predictive distribution are estimated from a training period. We propose a flexible alternative based on neural networks that can incorporate nonlinear relationships between arbitrary predictor variables and forecast distribution parameters that are automatically learned in a data-driven way rather than requiring prespecified link functions. In a case study of 2-m temperature forecasts at surface stations in Germany, the neural network approach significantly outperforms benchmark postprocessing methods while being computationally more affordable. Key components to this improvement are the use of auxiliary pre-dictor variables and station-specific information with the help of embeddings. Furthermore, the trained neural network can be used to gain insight into the importance of meteorological variables, thereby challenging the notion of neural networks as uninterpretable black boxes. Our approach can easily be extended to other statistical postprocessing and forecasting problems. We anticipate that recent advances in deep learning combined with the ever-increasing amounts of model and observation data will transform the postprocessing of numerical weather forecasts in the coming decade.},
	number = {11},
	journal = {Monthly Weather Review},
	author = {Rasp, Stephan and Lerch, Sebastian},
	year = {2018},
	pages = {3885--3900},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/VLHXLHIS/1520-0493-mwr-d-18-0187.1.pdf:application/pdf},
}

@techreport{huffman_nasa_2018,
	title = {{NASA} {Global} {Precipitation} {Measurement} ({GPM}) {Integrated} {Multi}-{satellitE} {Retrievals} for {GPM} ({IMERG}) {Prepared} for: {Global} {Precipitation} {Measurement} ({GPM}) {National} {Aeronautics} and {Space} {Administration} ({NASA})},
	url = {https://pmm.nasa.gov/sites/default/files/imce/times_allsat.jpg},
	author = {Huffman, Georg J and Bolvin, David T and Braithwaite, Dan and Hsu, Kuolin and Joyce, Robert and Kidd, Christopher and Nelkin, Eric J and Sorooshian, S and Tan, J and Xie, Pingping},
	month = feb,
	year = {2018},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/44RFCDFJ/IMERG_ATBD_V5.2.pdf:application/pdf},
}

@article{bechtold_representing_2014,
	title = {Representing equilibrium and nonequilibrium convection in large-scale models},
	volume = {71},
	issn = {00224928},
	doi = {10.1175/JAS-D-13-0163.1},
	abstract = {A new diagnostic convective closure, which is dependent on convective available potential energy (CAPE), is derived under the quasi-equilibrium assumption for the free troposphere subject to boundary layer forcing. The closure involves a convective adjustment time scale for the free troposphere and a coupling coefficient between the free troposphere and the boundary layer based on different time scales over land and ocean. Earlier studies with the ECMWF Integrated Forecasting System (IFS) have already demonstrated the model's ability to realistically represent tropical convectively coupled waves and synoptic variability with use of the "standard" CAPE closure, given realistic entrainment rates. A comparison of low-resolution seasonal integrations and high-resolution short-range forecasts against complementary satellite and radar data shows that with the extended CAPE closure it is also possible, independent of model resolution and time step, to realistically represent nonequilibrium convection such as the diurnal cycle of convection and the convection tied to advective boundary layers, although representing the late night convection over land remains a challenge.Amore in-depth regional analysis of the diurnal cycle and the closure is provided for the continental United States and particularly Africa, including comparison with data from satellites and a cloud-resolving model (CRM). Consequences for global numerical weather prediction (NWP) are not only a better phase representation of convection, but also better forecasts of its spatial distribution and local intensity. © 2014 American Meteorological Society.},
	number = {2},
	journal = {Journal of the Atmospheric Sciences},
	author = {Bechtold, Peter and Semane, Noureddine and Lopez, Philippe and Chaboureau, Jean Pierre and Beljaars, Anton and Bormann, Niels},
	month = feb,
	year = {2014},
	keywords = {★},
	pages = {734--753},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/7VGN3DZJ/1520-0469-jas-d-13-0163.1.pdf:application/pdf},
}

@article{noauthor_generalized_nodate,
	title = {Generalized {Additive} {Models} versus {Linear} {Regression} in {Generating} {Probabilistic} {MOS} {Forecasts} of {Aviation} {Weather} {Parameters}},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/I479GJDJ/1520-0434-1520-0434_1995_010_0669_gamvlr_2_0_co_2.pdf:application/pdf},
}

@article{sweeney_reducing_2013,
	title = {Reducing errors of wind speed forecasts by an optimal combination of post-processing methods},
	volume = {20},
	issn = {14698080},
	doi = {10.1002/met.294},
	abstract = {Seven adaptive approaches to post-processing wind speed forecasts are discussed and compared. Forecasts of the wind speed over 48 h are run at horizontal resolutions of 7 and 3 km for a domain centred over Ireland. Forecast wind speeds over a 2 year period are compared to observed wind speeds at seven synoptic stations around Ireland and skill scores calculated. Two automatic methods for combining forecast streams are applied. The forecasts produced by the combined methods give bias and root mean squared errors that are better than the numerical weather prediction forecasts at all station locations. One of the combined forecast methods results in skill scores that are equal to or better than all of its component forecast streams. This method is straightforward to apply and should prove beneficial in operational wind forecasting. © 2011 Royal Meteorological Society.},
	number = {1},
	journal = {Meteorological Applications},
	author = {Sweeney, Conor P. and Lynch, Peter and Nolan, Paul},
	year = {2013},
	note = {Publisher: John Wiley and Sons Ltd},
	keywords = {Numerical weather prediction, Adaptive post-processing, Artificial neural network, Kalman filter},
	pages = {32--40},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/26R7LPEU/Meteorological Applications - 2011 - Sweeney - Reducing errors of wind speed forecasts by an optimal combination of.pdf:application/pdf},
}

@article{li_development_2020,
	title = {Development of a postprocessing system of daily rainfall forecasts for seasonal crop prediction in {Australia}},
	volume = {141},
	issn = {14344483},
	doi = {10.1007/s00704-020-03268-3},
	abstract = {There is a need to postprocess seasonal rainfall forecasts from physical climate models to reduce bias, improve skill and restore daily variability for use as input for crop simulation at the farm scale. We develop an extended copula postprocessing (ECPP) method to deal with daily rainfall with numerous zero occurrences. By treating rainfall as a left-censored variable, we derive likelihood estimation and adjust simulation procedure with consideration of zero rainfall occurrences. In a case study for 50 representative agricultural stations in Australia, we test our method to postprocess daily rainfall forecasts with up to 186-day lead time. We demonstrate that the ECPP improves the overall forecast skill from raw rainfall forecasts and outperforms quantile mapping (QM) by checking various verification measures. Though the forecasts for daily amounts are hardly skilful except for the first few days, the forecasts for accumulated totals can be skilful from error averaging and propagating positive skill from short lead times. We also demonstrate that the ECPP can simulate rainfall forecasts with more realistic dry day distribution and daily rainfall intensity than QM. Further research directions including several opportunities to improve ECPP are discussed.},
	number = {3-4},
	journal = {Theoretical and Applied Climatology},
	author = {Li, Ming and Jin, Huidong},
	month = aug,
	year = {2020},
	note = {Publisher: Springer},
	keywords = {★, Copula, Rainfall forecast, censored data, Seasonal climate forecast, Statistical postprocessing},
	pages = {1331--1349},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/HS83E2QJ/s00704-020-03268-3.pdf:application/pdf},
}

@article{vannitsem_unified_2009,
	title = {A unified linear {Model} {Output} {Statistics} scheme for both deterministic and ensemble forecasts},
	volume = {135},
	issn = {00359009},
	doi = {10.1002/qj.491},
	abstract = {An extension of the classical linear Model Output Statistics (MOS) technique is proposed allowing for the post-processing of ensemble forecasts. In this new approach, the cost function on which the least square parameter estimation is based takes into account the presence of errors in both observations and model observables (referred to as Error-in-Variables MOS, EVMOS), unlike the classical linear MOS cost function whose implicit assumption is the absence of errors in the model observables. It allows for the maintenance of an appropriate variability for the corrected forecasts, even for long lead times and for providing a framework in which both deterministic and probabilistic forecasts can be corrected. The scheme is successfully tested for ensemble correction in the context of an idealized low-order chaotic system, the Lorenz atmospheric model, in the presence of model errors, and compared with a classical technique, known as the non-homogeneous Gaussian regression (NGR) method. The potential use of this approach is also briefly discussed. © 2009 Royal Meteorological Society.},
	number = {644},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Vannitsem, S.},
	month = oct,
	year = {2009},
	keywords = {★, EVMOS, NGR, Post-processing},
	pages = {1801--1815},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/2Y7JPG8D/Quart J Royal Meteoro Soc - 2009 - Vannitsem - A unified linear Model Output Statistics scheme for both deterministic and.pdf:application/pdf},
}

@article{ghil_extreme_2011,
	title = {Extreme events: {Dynamics}, statistics and prediction},
	volume = {18},
	issn = {10235809},
	doi = {10.5194/npg-18-295-2011},
	abstract = {We review work on extreme events, their causes and consequences, by a group of European and American researchers involved in a three-year project on these topics. The review covers theoretical aspects of time series analysis and of extreme value theory, as well as of the deterministic modeling of extreme events, via continuous and discrete dynamic models. The applications include climatic, seismic and socio-economic events, along with their prediction. Two important results refer to (i) the complementarity of spectral analysis of a time series in terms of the continuous and the discrete part of its power spectrum; and (ii) the need for coupled modeling of natural and socio-economic systems. Both these results have implications for the study and prediction of natural hazards and their human impacts. © 2011 Author(s).},
	number = {3},
	journal = {Nonlinear Processes in Geophysics},
	author = {Ghil, M. and Yiou, P. and Hallegatte, S. and Malamud, B. D. and Naveau, P. and Soloviev, A. and Friederichs, P. and Keilis-Borok, V. and Kondrashov, D. and Kossobokov, V. and Mestre, O. and Nicolis, C. and Rust, H. W. and Shebalin, P. and Vrac, M. and Witt, A. and Zaliapin, I.},
	year = {2011},
	pages = {295--350},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/TGVGE4SZ/npg-18-295-2011.pdf:application/pdf},
}

@article{maurer_bias_2014,
	title = {Bias correction can modify climate model simulated precipitation changes without adverse effect on the ensemble mean},
	volume = {18},
	issn = {10275606},
	doi = {10.5194/hess-18-915-2014},
	abstract = {When applied to remove climate model biases in precipitation, quantile mapping can in some settings modify the simulated difference in mean precipitation between two eras. This has important implications when the precipitation is used to drive an impacts model that is sensitive to changes in precipitation. The tendency of quantile mapping to alter model-predicted changes is demonstrated using synthetic precipitation distributions and elucidated with a simple theoretical analysis, which shows that the alteration of model-predicted changes can be controlled by the ratio of model to observed variance. To further evaluate the effects of quantile mapping in a more realistic setting, we use daily precipitation output from 11 atmospheric general circulation models (AGCMs), forced by observed sea surface temperatures, over the conterminous United States to compare precipitation differences before and after quantile mapping bias correction. The effectiveness of the bias correction is not assessed, only its effect on precipitation differences. The change in seasonal mean (winter, DJF, and summer, JJA) precipitation between two historical periods is compared to examine whether the bias correction tends to amplify or diminish an AGCM's simulated precipitation change. In some cases the trend modification can be as large as the original simulated change, though the areas where this occurs varies among AGCMs so the ensemble median shows smaller trend modification. Results show that quantile mapping improves the correspondence with observed changes in some locations and degrades it in others. While not representative of a future where natural precipitation variability is much smaller than that due to external forcing, these results suggest that at least for the next several decades the influence of quantile mapping on seasonal precipitation trends does not systematically degrade projected differences. © 2014 Author (s).},
	number = {3},
	journal = {Hydrology and Earth System Sciences},
	author = {Maurer, E. P. and Pierce, D. W.},
	month = mar,
	year = {2014},
	pages = {915--925},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/HASCVZAK/hess-18-915-2014.pdf:application/pdf},
}

@article{watt-meyer_correcting_2021,
	title = {Correcting {Weather} and {Climate} {Models} by {Machine} {Learning} {Nudged} {Historical} {Simulations}},
	volume = {48},
	issn = {19448007},
	doi = {10.1029/2021GL092555},
	abstract = {Due to limited resolution and inaccurate physical parameterizations, weather and climate models consistently develop biases compared to the observed atmosphere. Using the FV3GFS model at coarse resolution, we propose a method of machine learning corrective tendencies from a hindcast simulation nudged toward observational analysis. We show that a random forest can predict the nudging tendencies from this hindcast simulation with moderate skill using only the model state as input. This random forest is then coupled to FV3GFS, adding corrective tendencies of temperature, specific humidity and horizontal winds at each timestep. The coupled model shows no signs of instability in year-long simulations and has significant reductions in short-term forecast error for 500 hPa height, surface pressure and near-surface temperature. Furthermore, the root mean square error of the annual-mean precipitation is reduced by about 20\%. Biases of other variables remain similar or in some cases, like upper-atmospheric temperature, increase in the year-long simulations.},
	number = {15},
	journal = {Geophysical Research Letters},
	author = {Watt-Meyer, Oliver and Brenowitz, Noah D. and Clark, Spencer K. and Henn, Brian and Kwa, Anna and McGibbon, Jeremy and Perkins, W. Andre and Bretherton, Christopher S.},
	month = aug,
	year = {2021},
	note = {Publisher: John Wiley and Sons Inc},
	keywords = {machine learning, weather prediction, bias correction, climate modeling, hybrid physics-ML, parameterization},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/EL9DR8CW/Geophysical Research Letters - 2021 - Watt‐Meyer - Correcting Weather and Climate Models by Machine Learning Nudged.pdf:application/pdf},
}

@article{sloughter_probabilistic_2007,
	title = {Probabilistic quantitative precipitation forecasting using bayesian model averaging},
	volume = {135},
	issn = {00270644},
	doi = {10.1175/MWR3441.1},
	abstract = {Bayesian model averaging (BMA) is a statistical way of postprocessing forecast ensembles to create predictive probability density functions (PDFs) for weather quantities. It represents the predictive PDF as a weighted average of PDFs centered on the individual bias-corrected forecasts, where the weights are posterior probabilities of the models generating the forecasts and reflect the forecasts' relative contributions to predictive skill over a training period. It was developed initially for quantities whose PDFs can be approximated by normal distributions, such as temperature and sea level pressure. BMA does not apply in its original form to precipitation, because the predictive PDF of precipitation is nonnormal in two major ways: it has a positive probability of being equal to zero, and it is skewed. In this study BMA is extended to probabilistic quantitative precipitation forecasting. The predictive PDF corresponding to one ensemble member is a mixture of a discrete component at zero and a gamma distribution. Unlike methods that predict the probability of exceeding a threshold, BMA gives a full probability distribution for future precipitation. The method was applied to daily 48-h forecasts of 24-h accumulated precipitation in the North American Pacific Northwest in 2003-04 using the University of Washington mesoscale ensemble. It yielded predictive distributions that were calibrated and sharp. It also gave probability of precipitation forecasts that were much better calibrated than those based on consensus voting of the ensemble members. It gave better estimates of the probability of high-precipitation events than logistic regression on the cube root of the ensemble mean. © 2007 American Meteorological Society.},
	number = {9},
	journal = {Monthly Weather Review},
	author = {Sloughter, J. Mc Lean and Raftery, Adrian E. and Gneiting, Tilmann and Fraley, Chris},
	month = sep,
	year = {2007},
	pages = {3209--3220},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/UFBTAKBI/1520-0493-mwr3441.1.pdf:application/pdf},
}

@article{han_deep_2021,
	title = {A {Deep} {Learning} {Method} for {Bias} {Correction} of {ECMWF} 24–240 h {Forecasts}},
	volume = {38},
	issn = {18619533},
	doi = {10.1007/s00376-021-0215-y},
	abstract = {Correcting the forecast bias of numerical weather prediction models is important for severe weather warnings. The refined grid forecast requires direct correction on gridded forecast products, as opposed to correcting forecast data only at individual weather stations. In this study, a deep learning method called CU-net is proposed to correct the gridded forecasts of four weather variables from the European Centre for Medium-Range Weather Forecast Integrated Forecasting System global model (ECMWF-IFS): 2-m temperature, 2-m relative humidity, 10-m wind speed, and 10-m wind direction, with a forecast lead time of 24 h to 240 h in North China. First, the forecast correction problem is transformed into an image-to-image translation problem in deep learning under the CU-net architecture, which is based on convolutional neural networks. Second, the ECMWF-IFS forecasts and ECMWF reanalysis data (ERA5) from 2005 to 2018 are used as training, validation, and testing datasets. The predictors and labels (ground truth) of the model are created using the ECMWF-IFS and ERA5, respectively. Finally, the correction performance of CU-net is compared with a conventional method, anomaly numerical correction with observations (ANO). Results show that forecasts from CU-net have lower root mean square error, bias, mean absolute error, and higher correlation coefficient than those from ANO for all forecast lead times from 24 h to 240 h. CU-net improves upon the ECMWF-IFS forecast for all four weather variables in terms of the above evaluation metrics, whereas ANO improves upon ECMWF-IFS performance only for 2-m temperature and relative humidity. For the correction of the 10-m wind direction forecast, which is often difficult to achieve, CU-net also improves the correction performance.},
	number = {9},
	journal = {Advances in Atmospheric Sciences},
	author = {Han, Lei and Chen, Mingxuan and Chen, Kangkai and Chen, Haonan and Zhang, Yanbiao and Lu, Bing and Song, Linye and Qin, Rui},
	month = sep,
	year = {2021},
	note = {Publisher: Science Press},
	keywords = {bias correction, Numerical weather prediction, deep learning, ECMWF},
	pages = {1444--1459},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/JACHQELS/s00376-021-0215-y.pdf:application/pdf},
}

@article{wang_universal_2002,
	title = {A universal image quality index},
	volume = {9},
	issn = {10709908},
	doi = {10.1109/97.995823},
	abstract = {We propose a new universal objective image quality index, which is easy to calculate and applicable to various image processing applications. Instead of using traditional error summation methods, the proposed index is designed by modeling any image distortion as a combination of three factors: loss of correlation, luminance distortion, and contrast distortion. Although the new index is mathematically defined and no human visual system model is explicitly employed, our experiments on various image distortion types indicate that it performs significantly better than the widely used distortion metric mean squared error. Demonstrative images and an efficient MATLAB implementation of the algorithm are available online at http://anchovy.ece.utexas.edu/{\textasciitilde}zwang/research/quality\_index/demo.html.},
	number = {3},
	journal = {IEEE Signal Processing Letters},
	author = {Wang, Zhou and Bovik, Alan C.},
	month = mar,
	year = {2002},
	keywords = {Human visual system (HVS), Image quality measurement, Mean squared error (MSE)},
	pages = {81--84},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/AFHGA8VK/A_universal_image_quality_index.pdf:application/pdf},
}

@article{teutschbein_bias_2012,
	title = {Bias correction of regional climate model simulations for hydrological climate-change impact studies: {Review} and evaluation of different methods},
	volume = {456-457},
	issn = {00221694},
	doi = {10.1016/j.jhydrol.2012.05.052},
	abstract = {Despite the increasing use of regional climate model (RCM) simulations in hydrological climate-change impact studies, their application is challenging due to the risk of considerable biases. To deal with these biases, several bias correction methods have been developed recently, ranging from simple scaling to rather sophisticated approaches. This paper provides a review of available bias correction methods and demonstrates how they can be used to correct for deviations in an ensemble of 11 different RCM-simulated temperature and precipitation series. The performance of all methods was assessed in several ways: At first, differently corrected RCM data was compared to observed climate data. The second evaluation was based on the combined influence of corrected RCM-simulated temperature and precipitation on hydrological simulations of monthly mean streamflow as well as spring and autumn flood peaks for five catchments in Sweden under current (1961-1990) climate conditions. Finally, the impact on hydrological simulations based on projected future (2021-2050) climate conditions was compared for the different bias correction methods. Improvement of uncorrected RCM climate variables was achieved with all bias correction approaches. While all methods were able to correct the mean values, there were clear differences in their ability to correct other statistical properties such as standard deviation or percentiles. Simulated streamflow characteristics were sensitive to the quality of driving input data: Simulations driven with bias-corrected RCM variables fitted observed values better than simulations forced with uncorrected RCM climate variables and had more narrow variability bounds. © 2012 Elsevier B.V.},
	journal = {Journal of Hydrology},
	author = {Teutschbein, Claudia and Seibert, Jan},
	month = aug,
	year = {2012},
	keywords = {Hydrology, Downscaling, RCM, Bias correction, HBV, Streamflow},
	pages = {12--29},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/RR64KP8B/1-s2.0-S0022169412004556-main.pdf:application/pdf},
}

@article{gutierrez_intercomparison_2019,
	title = {An intercomparison of a large ensemble of statistical downscaling methods over {Europe}: {Results} from the {VALUE} perfect predictor cross-validation experiment},
	volume = {39},
	issn = {10970088},
	doi = {10.1002/joc.5462},
	abstract = {VALUE is an open European collaboration to intercompare downscaling approaches for climate change research, focusing on different validation aspects (marginal, temporal, extremes, spatial, process-based, etc.). Here we describe the participating methods and first results from the first experiment, using “perfect” reanalysis (and reanalysis-driven regional climate model (RCM)) predictors to assess the intrinsic performance of the methods for downscaling precipitation and temperatures over a set of 86 stations representative of the main climatic regions in Europe. This study constitutes the largest and most comprehensive to date intercomparison of statistical downscaling methods, covering the three common downscaling approaches (perfect prognosis, model output statistics—including bias correction—and weather generators) with a total of over 50 downscaling methods representative of the most common techniques. Overall, most of the downscaling methods greatly improve (reanalysis or RCM) raw model biases and no approach or technique seems to be superior in general, because there is a large method-to-method variability. The main factors most influencing the results are the seasonal calibration of the methods (e.g., using a moving window) and their stochastic nature. The particular predictors used also play an important role in cases where the comparison was possible, both for the validation results and for the strength of the predictor–predictand link, indicating the local variability explained. However, the present study cannot give a conclusive assessment of the skill of the methods to simulate regional future climates, and further experiments will be soon performed in the framework of the EURO-CORDEX initiative (where VALUE activities have merged and follow on). Finally, research transparency and reproducibility has been a major concern and substantive steps have been taken. In particular, the necessary data to run the experiments are provided at http://www.value-cost.eu/data and data and validation results are available from the VALUE validation portal for further investigation: http://www.value-cost.eu/validationportal.},
	number = {9},
	journal = {International Journal of Climatology},
	author = {Gutiérrez, J. M. and Maraun, D. and Widmann, M. and Huth, R. and Hertig, E. and Benestad, R. and Roessler, O. and Wibig, J. and Wilcke, R. and Kotlarski, S. and San Martín, D. and Herrera, S. and Bedia, J. and Casanueva, A. and Manzanas, R. and Iturbide, M. and Vrac, M. and Dubrovsky, M. and Ribalaygua, J. and Pórtoles, J. and Räty, O. and Räisänen, J. and Hingray, B. and Raynaud, D. and Casado, M. J. and Ramos, P. and Zerenner, T. and Turco, M. and Bosshard, T. and Štěpánek, P. and Bartholy, J. and Pongracz, R. and Keller, D. E. and Fischer, A. M. and Cardoso, R. M. and Soares, P. M.M. and Czernecki, B. and Pagé, C.},
	month = jul,
	year = {2019},
	note = {Publisher: John Wiley and Sons Ltd},
	keywords = {★, validation, downscaling, CORDEX, bias adjustment, model output statistics, perfect prognosis, reproducibility, weather generators},
	pages = {3750--3785},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/ZFNLDFY4/Intl Journal of Climatology - 2018 - Guti rrez - An intercomparison of a large ensemble of statistical downscaling methods.pdf:application/pdf},
}

@article{glahn_use_1972,
	title = {The {Use} of {Model} {Output} {Statistics} ({MOS}) in {Objective} {Weather} {Forecasting}},
	volume = {11},
	number = {8},
	journal = {Journal of Applied Meteorology and Climatology},
	author = {Glahn, Harry R and Lowry, Dale A},
	year = {1972},
	pages = {1203--1211},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/JBUVT6ZH/0021-8952-1520-0450_1972_011_1203_tuomos_2_0_co_2.pdf:application/pdf},
}

@techreport{gneiting_calibrated_2005,
	title = {Calibrated {Probabilistic} {Forecasting} {Using} {Ensemble} {Model} {Output} {Statistics} and {Minimum} {CRPS} {Estimation}},
	abstract = {Ensemble prediction systems typically show positive spread-error correlation, but they are subject to forecast bias and dispersion errors, and are therefore uncalibrated. This work proposes the use of ensemble model output statistics (EMOS), an easy-to-implement postprocessing technique that addresses both forecast bias and underdispersion and takes into account the spread-skill relationship. The technique is based on multiple linear regression and is akin to the superensemble approach that has traditionally been used for deterministic-style forecasts. The EMOS technique yields probabilistic forecasts that take the form of Gaussian predictive probability density functions (PDFs) for continuous weather variables and can be applied to gridded model output. The EMOS predictive mean is a bias-corrected weighted average of the ensemble member forecasts, with coefficients that can be interpreted in terms of the relative contributions of the member models to the ensemble, and provides a highly competitive deterministic-style forecast. The EMOS predictive variance is a linear function of the ensemble variance. For fitting the EMOS coefficients, the method of minimum continuous ranked probability score (CRPS) estimation is introduced. This technique finds the coefficient values that optimize the CRPS for the training data. The EMOS technique was applied to 48-h forecasts of sea level pressure and surface temperature over the North American Pacific Northwest in spring 2000, using the University of Washington mesoscale ensemble. When compared to the bias-corrected ensemble, deterministic-style EMOS forecasts of sea level pressure had root-mean-square error 9\% less and mean absolute error 7\% less. The EMOS predictive PDFs were sharp, and much better calibrated than the raw ensemble or the bias-corrected ensemble.},
	author = {Gneiting, Tilmann and Raftery, Adrian E and Westveld Iii, Anton H and Goldman, Tom},
	year = {2005},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/8THHR6DW/1520-0493-mwr2904.1.pdf:application/pdf},
}

@inproceedings{wu_image_2016,
	title = {Image quality assessment based on {Structure} {Similarity}},
	isbn = {978-1-5090-2708-8},
	doi = {10.1109/ICSPCC.2016.7753620},
	abstract = {Image Structure Similarity (SSIM) and its extended versions have been successfully used in image quality assessment. In this paper, we propose a similarity metric to evaluate image quality by extracting image sparse structure from natural scene image. A sparse dictionary trained on the data contains the basic elements for representing sparse structures, and it is insensitive to different databases. The sparse structure similarity of testing image pairs is calculated with this dictionary. The final score of image quality is obtained by counting the changed number of elements in sparse structure vector between distorted image and reference image. Experiments demonstrate that the proposed method could assess image quality effectively and outperform existing SSIM based methods.},
	booktitle = {{ICSPCC} 2016 - {IEEE} {International} {Conference} on {Signal} {Processing}, {Communications} and {Computing}, {Conference} {Proceedings}},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Wu, Jun and Li, Huifang and Xia, Zhaoqiang},
	month = nov,
	year = {2016},
	keywords = {dictionary learning, full-reference assessment, Image quality, sparse structure},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/4QWZXZDT/Image_quality_assessment_based_on_Structure_Similarity.pdf:application/pdf},
}

@inproceedings{wang_multi-scale_2003,
	title = {Multi-scale structural similarity for image quality assessment},
	volume = {2},
	doi = {10.1109/acssc.2003.1292216},
	abstract = {The structural similarity image quality paradigm is based on the assumption that the human visual system is highly adapted for extracting structural information from the scene, and therefore a measure of structural similarity can provide a good approximation to perceived image quality. This paper proposes a multi-scale structural similarity method, which supplies more flexibility than previous single-scale methods in incorporating the variations of viewing conditions. We develop an image synthesis method to calibrate the parameters that define the relative importance of different scales. Experimental comparisons demonstrate the effectiveness of the proposed method.},
	booktitle = {Conference {Record} of the {Asilomar} {Conference} on {Signals}, {Systems} and {Computers}},
	author = {Wang, Zhou and Simoncelli, Eero P. and Bovik, Alan C.},
	year = {2003},
	note = {ISSN: 10586393},
	pages = {1398--1402},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/P3DPTG8K/Multiscale_structural_similarity_for_image_quality_assessment.pdf:application/pdf},
}

@techreport{rio_inequalities_nodate,
	title = {{INEQUALITIES} {AND} {LIMIT} {THEOREMS} {FOR} {WEAKLY} {DEPENDENT} {SEQUENCES}},
	author = {Rio, Emmanuel},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/C7SWUP3S/ILTWDS.pdf:application/pdf},
}

@article{wang_evaluation_2017,
	title = {Evaluation of the {GPM} {IMERG} satellite-based precipitation products and the hydrological utility},
	volume = {196},
	issn = {01698095},
	doi = {10.1016/j.atmosres.2017.06.020},
	abstract = {Pre-occupation evaluation of latest generation satellite-based precipitation products (SPPs) is an essential step before the massive scale use. Taking the Beijiang River Basin as the case study, we used nine statistical evaluation indices and the Variable Infiltration Capacity (VIC) distributed hydrological model to quantitatively evaluate the performance and the hydrological utility of three Global Precipitation Measurement (GPM) Integrated Multi-satellitE Retrievals for GPM (IMERG) products: the near-real-time “Early” run and “Late” run IMERG products (IMERG-E and IMERG-L), and the post-real-time “Final” run IMERG product (IMERG-F) over south China during 2014–2015, with the last-generation Tropical Rainfall Measurement Mission (TRMM) Multi-satellite Precipitation Analysis (TMPA) 3B42-V7 product as comparison. The IMERG-F presents satisfactory accuracy with high correlation coefficient (CC = 0.63) and low relative bias (0.92\%), while the IMERG-E and IMERG-L performs relatively poorly featuring low correlation (with CC of 0.49 and 0.52 respectively) with the ground observations. All of the three IMERG products present apparently higher probability of detection (POD, 0.64–0.67) but have higher false alarm ratio (FAR, ≧ 0.14) than the 3B42-V7. The hydrological simulation under scenario I (model calibrated by the gauge observations) shows that, the IMERG-F, with a high Nash–Sutcliffe coefficient of efficiency (NSCE) of 0.742, presents better hydrological performance than the 3B42-V7; the IMERG-E and IMERG-L perform poorly for the whole simulation period with NSCE lower than 0.35 and relative bias higher than 28\% while perform satisfactorily during the flood season with apparently higher NSCE of 0.750 and 0.733 respectively. The hydrological simulation under scenario II (model calibrated by the 3B42-V7) shows that the performance of all the IMERG products was significantly improved. Generally, the IMERG-F has high accuracy and good hydrological utility, while the IMERG-E and IMERG-L products have satisfactory hydrological utility during the flood season and thus have great potential for the real-time application such as flood forecasting. The late-run IMERG-L presents little improvement in performance comparing with the early-run IMERG-E, therefore, the timelier IMERG-E is recommended to be firstly considered.},
	journal = {Atmospheric Research},
	author = {Wang, Zhaoli and Zhong, Ruida and Lai, Chengguang and Chen, Jiachao},
	month = nov,
	year = {2017},
	note = {Publisher: Elsevier Ltd},
	keywords = {GPM IMERG, Hydrological utility, Satellite-based precipitation product, The Beijiang River Basin, Variable Infiltration Capacity model},
	pages = {151--163},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/NQ47QSCD/1-s2.0-S0169809517302715-main.pdf:application/pdf},
}

@article{tang_evaluation_2016,
	title = {Evaluation of {GPM} {Day}-1 {IMERG} and {TMPA} {Version}-7 legacy products over {Mainland} {China} at multiple spatiotemporal scales},
	volume = {533},
	issn = {00221694},
	doi = {10.1016/j.jhydrol.2015.12.008},
	abstract = {The post-real time product of Day-1 Integrated Multi-satellitE Retrievals for Global Precipitation Measurement (IMERG) is evaluated over Mainland China from April to December 2014 at the hourly timescale, against data from hourly ground-based observations. In addition, the IMERG product is compared with its predecessor-the Version-7 post-real-time 3B42 (3B42V7) product of Tropical Rainfall Measuring Mission (TRMM) Multisatellite Precipitation Analysis (TMPA) at its original 3-hourly and then daily timescales for the same period. All the products are cross-evaluated at gridded, regional, and national scales. Results show that: (1) the Day-1 IMERG shows appreciably better performance than 3B42V7 at both sub-daily and daily timescales, and all the three spatial scales. The gap between the two products is more significant at the sub-daily resolution; (2) Out of the six sub-regions of China, IMERG especially performs better than 3B42V7 at the mid- and high-latitudes, as well as relatively dry climate regions; (3) IMERG can better reproduce the probability density function (PDF) in terms of precipitation intensity, particularly in the low ranges; and (4) although IMERG better captures the precipitation diurnal variability, both products have room to further improve their capability, particularly in the dry climate and high-latitude regions. This study is among the earliest evaluation and comparison of IMERG and 3B42V7 products, which could be valuable in providing reference for the development of IMERG algorithms, associated global products, and various applications as well.},
	journal = {Journal of Hydrology},
	author = {Tang, Guoqiang and Ma, Yingzhao and Long, Di and Zhong, Lingzhi and Hong, Yang},
	month = feb,
	year = {2016},
	note = {Publisher: Elsevier B.V.},
	keywords = {Precipitation, TRMM, GPM, IMERG},
	pages = {152--167},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/EV6585I3/1-s2.0-S0022169415009476-main.pdf:application/pdf},
}

@article{sylla_uncertainties_2013,
	title = {Uncertainties in daily rainfall over {Africa}: {Assessment} of gridded observation products and evaluation of a regional climate model simulation},
	volume = {33},
	issn = {08998418},
	doi = {10.1002/joc.3551},
	abstract = {We intercompare three gridded observed daily rainfall datasets over Africa (FEWS (Famine Early Warning System), GPCP (Global Precipitation Climatology Project) and TRMM (Tropical Rainfall Measuring Mission)) in order to assess uncertainties in observation products towards the evaluation of the performance of a Regional Climate Model (RegCM3) in simulating daily precipitation characteristics over a domain encompassing the whole African continent. We find that different observation products exhibit substantial systematic differences in mean rainfall, but especially in higher order daily precipitation statistics, such as frequency of wet days, precipitation intensity and extremes as well as maximum length of wet and dry spells. For example, FEWS shows mostly higher frequency and lower intensity events than TRMM and GPCP. Thus, the different datasets provide quite different representations of daily precipitation behavior. As a result, although RegCM3 captures pretty well the monsoon rainband evolution and exhibits a representation of daily precipitation statistics within the range of the observations, it performs differently with respect to the various products. For instance, it simulates more intense but less frequent events over East and Southern Africa than in FEWS and vice versa compared to TRMM. We thus highlight the uncertainty in observations as a key factor preventing a rigorous and unambiguous evaluation of climate models over Africa. Improving the quality and consistency of observation products is thus paramount for a better understanding of the response of African climate to global warming. © 2012 Royal Meteorological Society.},
	number = {7},
	journal = {International Journal of Climatology},
	author = {Sylla, M. B. and Giorgi, F. and Coppola, E. and Mariotti, L.},
	month = jun,
	year = {2013},
	keywords = {Daily rainfall, Higher order statistics, Observation products, Regional climate model evaluation, Uncertainties},
	pages = {1805--1817},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/ADI6BHXB/Intl Journal of Climatology - 2012 - Sylla - Uncertainties in daily rainfall over Africa  assessment of gridded observation.pdf:application/pdf},
}

@article{blanchard_multi-scale_2022,
	title = {A {Multi}-{Scale} {Deep} {Learning} {Framework} for {Projecting} {Weather} {Extremes}},
	url = {http://arxiv.org/abs/2210.12137},
	abstract = {Weather extremes are a major societal and economic hazard, claiming thousands of lives and causing billions of dollars in damage every year. Under climate change, their impact and intensity are expected to worsen significantly. Unfortunately, general circulation models (GCMs), which are currently the primary tool for climate projections, cannot characterize weather extremes accurately. To address this, we present a multi-resolution deep-learning framework that, firstly, corrects a GCM's biases by matching low-order and tail statistics of its output with observations at coarse scales; and secondly, increases the level of detail of the debiased GCM output by reconstructing the finer scales as a function of the coarse scales. We use the proposed framework to generate statistically realistic realizations of the climate over Western Europe from a simple GCM corrected using observational atmospheric reanalysis. We also discuss implications for probabilistic risk assessment of natural disasters in a changing climate.},
	author = {Blanchard, Antoine and Parashar, Nishant and Dodov, Boyko and Lessig, Christian and Sapsis, Themistoklis},
	month = oct,
	year = {2022},
	note = {arXiv: 2210.12137},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/8YDB5QIV/2210.12137.pdf:application/pdf},
}

@article{murphy_hedging_1973,
	title = {Hedging and {Skill} {Scores} for {Probability} {Forecasts}},
	journal = {Journal of Applied Meteorology},
	author = {Murphy, Allan H},
	year = {1973},
	pages = {215--223},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/5YK9NEVX/0021-8952-1520-0450_1973_012_0215_hassfp_2_0_co_2.pdf:application/pdf},
}

@article{jolliffe_proper_2008,
	title = {Proper scores for probability forecasts can never be equitable},
	volume = {136},
	issn = {00270644},
	doi = {10.1175/2007MWR2194.1},
	abstract = {Verification is an important part of any forecasting system. It is usually achieved by computing the value of some measure or score that indicates how good the forecasts are. Many possible verification measures have been proposed, and to choose between them a number of desirable properties have been defined. For probability forecasts of a binary event, two of the best known of these properties are propriety and equitability. A proof that the two properties are incompatible for a wide class of verification measures is given in this paper, after briefly reviewing the two properties and some recent attempts to improve properties for the well-known Brier skill score. © 2008 American Meteorological Society.},
	number = {4},
	journal = {Monthly Weather Review},
	author = {Jolliffe, Ian T. and Stephenson, David B.},
	month = apr,
	year = {2008},
	keywords = {★},
	pages = {1505--1510},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/HDSJSX46/Proper_Scores_for_Probability_Forecasts_Can_Never_.pdf:application/pdf},
}

@article{weusthoff_assessing_2010,
	title = {Assessing the benefits of convection-permitting models by neighborhood verification: {Examples} from {MAP} {D}-{PHASE}},
	volume = {138},
	issn = {00270644},
	doi = {10.1175/2010MWR3380.1},
	abstract = {High-resolution numerical weather prediction (NWP) models produce more detailed precipitation structures but the real benefit is probably the more realistic statistics gained with the higher resolution and not the information on the specific grid point. By evaluating three model pairs, each consisting of a high-resolution NWP system resolving convection explicitly and its low-resolution-driving model with parameterized convection, on different spatial scales and for different thresholds, this paper addresses the question of whether high-resolution models really perform better than their driving lower-resolution counterparts. The model pairs are evaluated by means of two fuzzy verification methods-upscaling (UP) and fractions skill score (FSS)-for the 6 months of the D-PHASE Operations Period and in a highly complex terrain. Observations are provided by the Swiss radar composite and the evaluation is restricted to the area covered by the Swiss radar stations. The high-resolution models outperform or equal the performance of their respective lower-resolution driving models. The differences between the models are significant and robust against small changes in the verification settings. An evaluation based on individual months shows that high-resolution models give better results, particularly with regard to convective, more localized precipitation events. © 2010 American Meteorological Society.},
	number = {9},
	journal = {Monthly Weather Review},
	author = {Weusthoff, Tanja and Ament, Felix and Arpagaus, Marco and Rotach, Mathias W.},
	month = sep,
	year = {2010},
	pages = {3418--3433},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/X3EMPVD8/1520-0493-2010mwr3380.1.pdf:application/pdf},
}

@article{hemri_trends_2014,
	title = {Trends in the predictive performance of raw ensemble weather forecasts},
	volume = {41},
	issn = {19448007},
	doi = {10.1002/2014GL062472},
	abstract = {This study applies statistical postprocessing to ensemble forecasts of near-surface temperature, 24 h precipitation totals, and near-surface wind speed from the global model of the European Centre for Medium-Range Weather Forecasts (ECMWF). The main objective is to evaluate the evolution of the difference in skill between the raw ensemble and the postprocessed forecasts. Reliability and sharpness, and hence skill, of the former is expected to improve over time. Thus, the gain by postprocessing is expected to decrease. Based on ECMWF forecasts from January 2002 to March 2014 and corresponding observations from globally distributed stations, we generate postprocessed forecasts by ensemble model output statistics (EMOS) for each station and variable. Given the higher average skill of the postprocessed forecasts, we analyze the evolution of the difference in skill between raw ensemble and EMOS. This skill gap remains almost constant over time indicating that postprocessing will keep adding skill in the foreseeable future. Key Points Evolution of raw ensemble forecast skillFuture benefits from statistical postprocessingGlobal distribution of forecast skill development},
	number = {24},
	journal = {Geophysical Research Letters},
	author = {Hemri, S. and Scheuerer, M. and Pappenberger, F. and Bogner, K. and Haiden, T.},
	month = dec,
	year = {2014},
	note = {Publisher: Blackwell Publishing Ltd},
	keywords = {★, EMOS, ensemble weather forecasts, model verification, statistical postprocessing},
	pages = {9197--9205},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/QNKPIIPH/Geophysical Research Letters - 2014 - Hemri - Trends in the predictive performance of raw ensemble weather forecasts.pdf:application/pdf},
}

@article{mittermaier_how_2019,
	title = {How interpolation and resolution can affect verification scores: {A} study based on the {Fractions} {Skill} {Score}},
	volume = {28},
	issn = {16101227},
	doi = {10.1127/metz/2018/0890},
	abstract = {The Fractions Skill Score (FSS) has been used to routinely verify six-hourly UK precipitation forecasts since early 2008. For a 17-month period between May 2011 and September 2012 precipitation forecasts from the 4-km version of the Met Office Unified Model (UK4) were evaluated against two versions of radar-rainfall analyses, the 5-km product which had existed for many years, and a new 1-km product created using a revised algorithm. The standard practice is to interpolate the model forecast to the observation grid. This paper looks at the combined impact of the resolution of the verifying grid and interpolation on the magnitude of the FSS for six-hour accumulations. The 90th percentile threshold FSS mean scores based on the 1-km grid are higher for the 5-km neighbourhood. The 5- and 1-km verification grid scores are closest for the 25-km neighbourhood. For larger neighbourhoods there are several lead times and times of the day where the 5-km grid mean score is higher. In a cumulative sense the 1-km grid 90th percentile threshold FSS is 10-15 \% higher for the 5-km neighbourhood. This is relative to the 5-km grid score and based on a 180-day running mean. Individual score differences are significant at the 5 \% level. It suggests that the same 4-km model forecasts downscaled to a 1-km grid, and evaluated over a 5-km neighbourhood, score better than when upscaled (slightly) to a 5-km grid, which is close to the model grid scale. For the 25-km neighbourhood the cumulative relative score difference is reduced to less than ±3 \% in the 180-day running means, though the differences for some lead times and times of day are significant at the 10 \% level. The same trend is present for 51 and 101-km neighbourhoods, with an increasing number of lead times and times of day having a 5-km grid score which is higher. The choices made at the outset regarding interpolation and the detail (or lack thereof) in a verifying data set are influential enough to be non-neglible. For a spatial score such as the FSS the impact changes with neighbourhood size.},
	number = {3},
	journal = {Meteorologische Zeitschrift},
	author = {Mittermaier, Marion P.},
	year = {2019},
	note = {Publisher: Gebruder Borntraeger Verlagsbuchhandlung},
	keywords = {Verification, Resolution, Fractions Skill Score, Interpolation},
	pages = {181--192},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/7VN9RTGS/metz_Vol_28_No_3_p181-192_How_interpolation_and_resolution_can_affect_verification_scores_A_study_based_on_the_Fractions_Skill_Score_89356.pdf:application/pdf},
}

@article{romine_model_2013,
	title = {Model bias in a continuously cycled assimilation system and its influence on convection-permitting forecasts},
	volume = {141},
	issn = {00270644},
	doi = {10.1175/MWR-D-12-00112.1},
	abstract = {During the spring 2011 season, a real-time continuously cycled ensemble data assimilation system using the Advanced Research version of the Weather Research and Forecasting Model (WRF) coupled with the Data Assimilation Research Testbed toolkit provided initial and boundary conditions for deterministic convectionpermitting forecasts, also usingWRF, over the eastern two-thirds of the conterminousUnited States (CONUS). In this study the authors evaluate the mesoscale assimilation systemand the convection-permitting forecasts, at 15-and 3-km grid spacing, respectively. Experiments employing different physics options within the continuously cycled ensemble data assimilation systemare shown to lead to differences in the meanmesoscale analysis characteristics. Convection-permitting forecasts with a fixed model configuration are initialized from these physics-varied analyses, as well as control runs from 0.5° Global Forecast System (GFS) analysis. Systematic bias in the analysis background influences the analysis fit to observations, and when this analysis initializes convection-permitting forecasts, the forecast skill is degraded as bias in the analysis background increases. Moreover, differences in mean error characteristics associated with each physical parameterization suite lead to unique errors of spatial, temporal, and intensity aspects of convection-permitting rainfall forecasts. Observation bias by platform type is also shown to impact the analysis quality. © 2013 American Meteorological Society.},
	number = {4},
	journal = {Monthly Weather Review},
	author = {Romine, Glen S. and Schwartz, Craig S. and Snyder, Chris and Anderson, Jeff L. and Weisman, Morris L.},
	month = apr,
	year = {2013},
	pages = {1263--1284},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/3JMTV8RY/1520-0493-mwr-d-12-00112.1.pdf:application/pdf},
}

@article{ayzel_rainnet_2020,
	title = {{RainNet} v1.0: {A} convolutional neural network for radar-based precipitation nowcasting},
	volume = {13},
	issn = {19919603},
	doi = {10.5194/gmd-13-2631-2020},
	abstract = {In this study, we present RainNet, a deep convolutional neural network for radar-based precipitation nowcasting. Its design was inspired by the U-Net and SegNet families of deep learning models, which were originally designed for binary segmentation tasks. RainNet was trained to predict continuous precipitation intensities at a lead time of 5min, using several years of quality-controlled weather radar composites provided by the German Weather Service (DWD). That data set covers Germany with a spatial domain of 900 km×900km and has a resolution of 1km in space and 5min in time. Independent verification experiments were carried out on 11 summer precipitation events from 2016 to 2017. In order to achieve a lead time of 1h, a recursive approach was implemented by using RainNet predictions at 5min lead times as model inputs for longer lead times. In the verification experiments, trivial Eulerian persistence and a conventional model based on optical flow served as benchmarks. The latter is available in the rainymotion library and had previously been shown to outperform DWD's operational nowcasting model for the same set of verification events. RainNet significantly outperforms the benchmark models at all lead times up to 60min for the routine verification metrics mean absolute error (MAE) and the critical success index (CSI) at intensity thresholds of 0.125, 1, and 5mm h-1. However, rainymotion turned out to be superior in predicting the exceedance of higher intensity thresholds (here 10 and 15mm h-1). The limited ability of RainNet to predict heavy rainfall intensities is an undesirable property which we attribute to a high level of spatial smoothing introduced by the model. At a lead time of 5min, an analysis of power spectral density confirmed a significant loss of spectral power at length scales of 16km and below. Obviously, RainNet had learned an optimal level of smoothing to produce a nowcast at 5min lead time. In that sense, the loss of spectral power at small scales is informative, too, as it reflects the limits of predictability as a function of spatial scale. Beyond the lead time of 5min, however, the increasing level of smoothing is a mere artifact-an analogue to numerical diffusion-that is not a property of RainNet itself but of its recursive application. In the context of early warning, the smoothing is particularly unfavorable since pronounced features of intense precipitation tend to get lost over longer lead times. Hence, we propose several options to address this issue in prospective research, including an adjustment of the loss function for model training, model training for longer lead times, and the prediction of threshold exceedance in terms of a binary segmentation task. Furthermore, we suggest additional input data that could help to better identify situations with imminent precipitation dynamics. The model code, pretrained weights, and training data are provided in open repositories as an input for such future studies.},
	number = {6},
	journal = {Geoscientific Model Development},
	author = {Ayzel, Georgy and Scheffer, Tobias and Heistermann, Maik},
	month = jun,
	year = {2020},
	note = {Publisher: Copernicus GmbH},
	pages = {2631--2644},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/XG4WQX3F/e589ad2925416b136025597f8b34ab824b35.pdf:application/pdf},
}

@article{ravuri_skilful_2021-1,
	title = {Skilful precipitation nowcasting using deep generative models of radar},
	volume = {597},
	issn = {14764687},
	doi = {10.1038/s41586-021-03854-z},
	abstract = {Precipitation nowcasting, the high-resolution forecasting of precipitation up to two hours ahead, supports the real-world socioeconomic needs of many sectors reliant on weather-dependent decision-making1,2. State-of-the-art operational nowcasting methods typically advect precipitation fields with radar-based wind estimates, and struggle to capture important non-linear events such as convective initiations3,4. Recently introduced deep learning methods use radar to directly predict future rain rates, free of physical constraints5,6. While they accurately predict low-intensity rainfall, their operational utility is limited because their lack of constraints produces blurry nowcasts at longer lead times, yielding poor performance on rarer medium-to-heavy rain events. Here we present a deep generative model for the probabilistic nowcasting of precipitation from radar that addresses these challenges. Using statistical, economic and cognitive measures, we show that our method provides improved forecast quality, forecast consistency and forecast value. Our model produces realistic and spatiotemporally consistent predictions over regions up to 1,536 km × 1,280 km and with lead times from 5–90 min ahead. Using a systematic evaluation by more than 50 expert meteorologists, we show that our generative model ranked first for its accuracy and usefulness in 89\% of cases against two competitive methods. When verified quantitatively, these nowcasts are skillful without resorting to blurring. We show that generative nowcasting can provide probabilistic predictions that improve forecast value and support operational utility, and at resolutions and lead times where alternative methods struggle.},
	number = {7878},
	journal = {Nature},
	author = {Ravuri, Suman and Lenc, Karel and Willson, Matthew and Kangin, Dmitry and Lam, Remi and Mirowski, Piotr and Fitzsimons, Megan and Athanassiadou, Maria and Kashem, Sheleem and Madge, Sam and Prudden, Rachel and Mandhane, Amol and Clark, Aidan and Brock, Andrew and Simonyan, Karen and Hadsell, Raia and Robinson, Niall and Clancy, Ellen and Arribas, Alberto and Mohamed, Shakir},
	month = sep,
	year = {2021},
	pmid = {34588668},
	note = {arXiv: 2104.00954
Publisher: Nature Research},
	pages = {672--677},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/Q4ZDEXBC/s41586-021-03854-z.pdf:application/pdf},
}

@article{bousquet_analysis_2006,
	title = {Analysis of scale dependence of quantitative precipitation forecast verification: {A} case-study over the {Mackenzie} river basin},
	volume = {132},
	issn = {00359009},
	doi = {10.1256/qj.05.154},
	abstract = {Six-hour rainfall accumulations derived from radar observations collected during a 3-day summertime precipitation event over central Alberta (Canada) are used to assess the performance of a regional Canadian numerical weather prediction system for quantitative precipitation forecast verification. We show that radar data provide a simple and efficient way to significantly reduce model phase errors associated with misplacement of predicted precipitation patterns. Using wavelet analysis, we determine that the limiting spatial scale of predictability of the model is about six times its grid resolution for 6 h accumulated fields. The use of longer accumulation periods is shown to smooth out forecast errors that may have resulted from slight phase or time shift errors but does not change the limiting scale of predictability. The scale decomposition of the mean-square forecast error also reveals that scales which cannot be accurately reproduced by the model account for about 20\% of the total error. Using classical continuous and categorical scores, we show that significantly better model performance can be achieved by smoothing out wavelengths that cannot be predicted. © Royal Meteorological Society, 2006.},
	number = {620},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Bousquet, Olivier and Lin, Charles A. and Zawadzki, Isztar},
	month = oct,
	year = {2006},
	keywords = {Numerical weather prediction (NWP) systems, Quantitative precipitation forecast (QPF), Radar, Wavelet transform},
	pages = {2107--2125},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/D8YDP72Z/Quart J Royal Meteoro Soc - 2007 - Bousquet - Analysis of scale dependence of quantitative precipitation forecast.pdf:application/pdf},
}

@inproceedings{mason_understanding_2008,
	title = {Understanding forecast verification statistics},
	volume = {15},
	doi = {10.1002/met.51},
	abstract = {Although there are numerous reasons for performing a verification analysis, there are usually two general questions that are of interest: are the forecasts good, and can we be confident that the estimate of forecast quality is not misleading? When calculating a verification score, it is not usually obvious how the score can answer either of these questions. Some procedures for attempting to answer the questions are reviewed, with particular focus on p-values and confidence intervals. P-values are shown to be rather unhelpful in answering either question, especially when applied to probabilistic verification scores, and confidence intervals are to be preferred. However, confidence intervals cannot reveal biases in the value of a score that arises from an inadequate experimental design for testing on truly out-of-sample observations. Some specific problems with cross validation are highlighted. Finally, in the interests of increasing the insight into forecast strengths and weaknesses and in pointing towards methods for improving forecast quality, a plea is made for a more discriminating selection of verification procedures than has been adopted to date. Copyright © 2008 Royal Meteorological Society.},
	booktitle = {Meteorological {Applications}},
	publisher = {John Wiley and Sons Ltd},
	author = {Mason, Simon J.},
	year = {2008},
	note = {Issue: 1
ISSN: 14698080},
	keywords = {Bootstrap, Cross validation, Effectiveness, Equitability, Locality, P-values, Permutation, Propriety},
	pages = {31--40},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/UMLT5UK4/Meteorological Applications - 2008 - Mason - Understanding forecast verification statistics.pdf:application/pdf},
}

@article{mittermaier_long-term_2013,
	title = {A long-term assessment of precipitation forecast skill using the {Fractions} {Skill} {Score}},
	volume = {20},
	issn = {14698080},
	doi = {10.1002/met.296},
	abstract = {The Fractions Skill Score (FSS) is a spatial verification metric routinely computed in the operational verification suite. It enables the comparison of forecasts of different resolutions against a common spatial truth (radar rainfall analyses) in such a way that high-resolution forecasts are not penalized for representativeness errors that arise from the 'double penalty' problem. Officially Met Office model precipitation forecast accuracy is monitored using the Equitable Threat Score (ETS) at gauge locations. These precipitation scores form part of a basket of measures assessing six surface parameters known as the UK index, which forms the basis for making decisions regarding model upgrades (especially over the UK). It is used to monitor the impact of continuous model improvements. This framework and the methodology underlying it, is less appropriate for high-resolution forecasts for reasons as described above. For precipitation forecasts in particular, a new framework for long-term monitoring is necessary and the FSS provides such a potential framework. This paper provides an objective critique of FSS results to date. It has been shown that the 'convection-permitting' (4 km) Unified Model (MetUM) forecasts are better than the 12 km MetUM (significant at the 5\% level). The scale at which the models have sufficient practical skill is typically 10 km better for the high-resolution forecasts, and are better at forecasting afternoon convection exceeding 4 mm (6 h)-1. The use of frequency (percentile) thresholds is recommended because of the implicit bias removal this approach provides, as any rain in a forecast period is treated as 'the event of interest'. © 2011 British Crown Copyright, the Met Office.},
	number = {2},
	journal = {Meteorological Applications},
	author = {Mittermaier, Marion and Roberts, Nigel and Thompson, Simon A.},
	year = {2013},
	note = {Publisher: John Wiley and Sons Ltd},
	keywords = {High-resolution NWP, Long-term monitoring against radar, Spatial verification methods, precipitation},
	pages = {176--186},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/3RMS8LHC/Meteorological Applications - 2011 - Mittermaier - A long‐term assessment of precipitation forecast skill using the.pdf:application/pdf},
}

@article{fierro_impact_2015,
	title = {Impact of storm-scale lightning data assimilation on {WRF}-{ARW} precipitation forecasts during the 2013 warm season over the contiguous {United} {States}},
	volume = {143},
	issn = {15200493},
	doi = {10.1175/MWR-D-14-00183.1},
	abstract = {This work evaluates the performance of a recently developed cloud-scale lightning data assimilation technique implemented within the Weather Research and Forecasting Model running at convection-allowing scales (4-km grid spacing). Data provided by the Earth Networks Total Lightning Network for the contiguous United States (CONUS) were assimilated in real time over 67 days spanning the 2013 warm season (May-July). The lightning data were assimilated during the first 2 h of simulations each day. Bias-corrected, neighborhood-based, equitable threat scores (BC-ETSs) were the chief metric used to quantify the skill of the forecasts utilizing this assimilation scheme. Owing to inferior observational data quality over mountainous terrain, this evaluation focused on the eastern two-thirds of the United States. During the first 3 h following the assimilation (i.e., 3-h forecasts), all the simulations suffered from a high wet bias in forecasted accumulated precipitation (APCP), particularly for the lightning assimilation run (LIGHT). Forecasts produced by LIGHT, however, had a noticeable, statistically significant (α = 0.05) improvement over those by the control run (CTRL) up to 6 h into the forecast with BC-ETS differences often exceeding 0.4. This improvement was seen independently of the APCP threshold (ranging from 2.5 to 50 mm) and the neighborhood radius (ranging from 0 to 40 km) selected. Past 6 h of the forecast, the APCP fields from LIGHT progressively converged to that of CTRL probably due to the longer-term evolution being bounded by the large-scale model environment. Thus, this computationally inexpensive lightning assimilation scheme shows considerable promise for routinely improving short-term (≤6 h) forecasts of high-impact weather by convection-allowing forecast models.},
	number = {3},
	journal = {Monthly Weather Review},
	author = {Fierro, Alexandre O. and Clark, Adam J. and Mansell, Edward R. and Macgorman, Donald R. and Dembek, Scott R. and Ziegler, Conrad L.},
	year = {2015},
	note = {Publisher: American Meteorological Society},
	keywords = {Model evaluation/performance, Numerical weather prediction/forecasting, Cloud resolving models, Cloud microphysics, Data assimilation, Lightning},
	pages = {757--777},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/56R3EX8Q/1520-0493-mwr-d-14-00183.1.pdf:application/pdf},
}

@article{woodhams_what_2018-1,
	title = {What is the added value of a convection-permitting model for forecasting extreme rainfall over tropical {East} {Africa}?},
	volume = {146},
	issn = {15200493},
	doi = {10.1175/MWR-D-17-0396.1},
	abstract = {Forecasting convective rainfall in the tropics is a major challenge for numerical weather prediction. The use of convection-permitting (CP) forecast models in the tropics has lagged behind the midlatitudes, despite the great potential of such models in this region. In the scientific literature, there is very little evaluation of CP models in the tropics, especially over an extended time period. This paper evaluates the prediction of convective storms for a period of 2 years in the Met Office operational CP model over East Africa and the global operational forecast model. A novel localized form of the fractions skill score is introduced, which shows variation in model skill across the spatial domain. Overall, the CP model and the global model both outperform a 24-h persistence forecast. The CP model shows greater skill than the global model, in particular on subdaily time scales and for storms over land. Forecasts over Lake Victoria are also improved in the CP model, with an increase in hit rate of up to 20\%. Contrary to studies in the midlatitudes, the skill of both models shows a large dependence on the time of day and comparatively little dependence on the forecast lead time within a 48-h forecast. Although these results provide more motivation for forecasters to use the CP model to produce subdaily forecasts with increased detail, there is a clear need for more in situ observations for data assimilation into the models and for verification. A move toward ensemble forecasting could have further benefits.},
	number = {9},
	journal = {Monthly Weather Review},
	author = {Woodhams, Beth J. and Birch, Cathryn E. and Marsham, John H. and Bain, Caroline L. and Roberts, Nigel M. and Boyd, Douglas F.A.},
	month = sep,
	year = {2018},
	note = {Publisher: American Meteorological Society},
	keywords = {Model evaluation/performance, Rainfall, Africa, Cloud resolving models, Inland seas/lakes, Regional models},
	pages = {2757--2780},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/EBRXJXTV/1520-0493-mwr-d-17-0396.1.pdf:application/pdf},
}

@article{nachamkin_applying_2015,
	title = {Applying a neighborhood fractions sampling approach as a diagnostic tool},
	volume = {143},
	issn = {15200493},
	doi = {10.1175/MWR-D-14-00411.1},
	abstract = {The fractions skill score (FSS) belongs to a class of spatial neighborhood techniques that measures forecast skill from samples of gridded forecasts and observations at increasing spatial scales. Each sample contains the fraction of the predicted and observed quantities that exist above a threshold value. Skill is gauged by the rate that the observed and predicted fractions converge with increasing scale. In this study, neighborhood sampling is applied to diagnose the performance of high-resolution (1.67 km) precipitation forecasts over central Florida. Reliability diagrams derived from the spatial fractions indicate that the FSS can be influenced by small, low-predictability events. Further tests indicate the FSS is subtly affected by samples from points on and near the grid boundaries. Inclusion of these points tends to reduce the magnitude and sensitivity of the FSS, especially at large scales. An attempt to mine data from the set of neighborhood fractions was moderately successful at obtaining descriptive information about the precipitation fields. The width of the distribution of the fractions at each scale provided information concerning forecast resolution and sharpness. The rate at which the distribution of the fractions converged toward the domain mean with increasing scale was found to be sensitive to the uniformity of coverage of precipitation through the domain. Generally, the 6-h forecasts possessed greater spatial skill than those at 12 h. High-FSS values at 12 h were mostly associated with evenly distributed precipitation patterns, while the 6-h forecasts also performed well for several nonuniform cases.},
	number = {11},
	journal = {Monthly Weather Review},
	author = {Nachamkin, Jason E. and Schmidt, Jerome},
	year = {2015},
	note = {Publisher: American Meteorological Society},
	keywords = {Forecast verification/skill, Mesoscale forecasting},
	pages = {4736--4749},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/SCIVANX3/1520-0493-mwr-d-14-00411.1.pdf:application/pdf},
}

@techreport{faggian_fast_2015,
	title = {Fast calculation of the fractions skill score},
	abstract = {The forecast verification metric known as the Fractions Skill Score (FSS) is typicallycomputed using sliding window operators, which can be computationally expensive. A keycomponent of the score is the computation of fractional event frequencies, which is equivalent to a weighted summation of sub-grids (windows) commonly realized as a convolutionoperation. An alternative approach is to use "summed area tables", which have been used incomputer graphics as a means to quickly compute summations of sub-grids in texture fields.In this paper we describe how a summed area table can effectively reduce the computationtime of the FSS while also allowing the score to generalize to include the time dimension.We demonstrate the methodology on idealized cases from the Spatial Verification MethodsInter-comparison Project and explore the properties of the score on a high-resolution NWPdataset.},
	author = {Faggian, Nathan and Roux, Belinda and Steinle, Peter and Ebert, Beth},
	year = {2015},
	note = {Publication Title: MAUSAM
Volume: 66
Issue: 3},
	keywords = {NWP, Fractions skill score (FSS)},
	pages = {457--466},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/G8NYKRI2/555-Research Papers-1876-1-10-20210507.pdf:application/pdf},
}

@article{simecek-beatty_oil_2021,
	title = {Oil spill forecast assessment using {Fractions} {Skill} {Score}},
	volume = {164},
	issn = {0025326X},
	doi = {10.1016/j.marpolbul.2021.112041},
	journal = {Marine Pollution Bulletin},
	author = {Simecek-Beatty, Debra and Lehr, William J.},
	month = mar,
	year = {2021},
	pages = {112041},
}

@article{manzato_behaviour_2017,
	title = {Behaviour of verification measures for deterministic binary forecasts with respect to random changes and thresholding},
	volume = {143},
	issn = {1477870X},
	doi = {10.1002/qj.3050},
	abstract = {There are many possible verification measures when deterministic binary forecasts are made. In deciding which to use, various properties of the measures are of interest. One type of property explores what happens when certain types of change are made to the forecasts. In this article, two types of change and their effects on various verification measures are examined. Underlying some desirable properties of measures, such as propriety, equitability and consistency, is the desire that it should be impossible to improve the value, or expected value, of a measure by changing the original forecast from the forecaster's ‘true belief’. This behaviour is often called ‘hedging’. Among the types of change that ought not to lead to improved forecasts are random changes of subsets of the true binary forecasts. The effect of such changes is discussed here. A second type of change examined here arises when a continuous forecast is thresholded to produce the binary forecast. When this type of ‘thresholding’ is practiced a posteriori, it can be seen as a fine-tuning of the forecasting system, in order to improve its verification performance. In the thresholding framework, one can optimize some verification performance measures with respect to others. In particular, this article discusses the optimization of bias and of the Peirce skill score.},
	number = {705},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Manzato, Agostino and Jolliffe, Ian},
	month = apr,
	year = {2017},
	note = {Publisher: John Wiley and Sons Ltd},
	keywords = {★, forecast verification, bias, binary classifiers, hedging, Peirce skill score, posterior probability},
	pages = {1903--1915},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/XIIE4EF5/Quart J Royal Meteoro Soc - 2017 - Manzato - Behaviour of verification measures for deterministic binary forecasts with.pdf:application/pdf},
}

@article{mittermaier_meta_2021,
	title = {A “{Meta}” {Analysis} of the {Fractions} {Skill} {Score}: {The} {Limiting} {Case} and {Implications} for {Aggregation}},
	volume = {149},
	issn = {0027-0644},
	doi = {10.1175/mwr-d-18-0106.1},
	abstract = {The fractions skill score (FSS) is arguably one of the most popular spatial verification metrics in use today. The fraction of grid points exceeding a threshold within a forecast and observed field neighborhood are examined to compute a score. By definition a perfect forecast has an FSS of 1, and a “no skill” forecast has a score of 0. It is shown that the denominator defines the score’s characteristics. The FSS is undefined for instances in which both the forecast and the observed field do not exceed a threshold. In the limiting case, the FSS for a perfect null (zero) forecast is also undefined, unless a threshold of  0 is used, in which case it would be 1 (i.e., perfect). Furthermore the FSS is 0 if either the forecast or the observed field does not exceed a threshold. This symmetry means it cannot differentiate between what are traditionally referred to as false alarms or misses. Additional supplementary information is required. The FSS is greater than 0 if and only if there are values exceeding a given threshold in both the forecast and the observed field. The magnitude of an overall score computed over many forecasts is sensitive to the pooling method. Zero scores are nontrivial. Excluding them implies excluding all situations associated with false alarms or misses. Omitting near-zero scores is a more credible decision, but only if it can be proven that these are related to spurious artifacts in the observed field. To avoid ambiguity the components of the FSS should be aggregated separately for computing an overall score for most applications and purposes.},
	number = {10},
	journal = {Monthly Weather Review},
	author = {Mittermaier, M. P.},
	month = feb,
	year = {2021},
	note = {Publisher: American Meteorological Society},
	pages = {3491--3504},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/X7KCK3QF/1520-0493-MWR-D-18-0106.1.pdf:application/pdf},
}

@article{wolff_beyond_2014,
	title = {Beyond the basics: {Evaluating} model-based precipitation forecasts using traditional, spatial, and object-based methods},
	volume = {29},
	issn = {15200434},
	doi = {10.1175/WAF-D-13-00135.1},
	abstract = {While traditional verification methods are commonly used to assess numerical model quantitative precipitation forecasts (QPFs) using a grid-to-grid approach, they generally offer little diagnostic information or reasoning behind the computed statistic. On the other hand, advanced spatial verification techniques, such as neighborhood and object-based methods, can provide more meaningful insight into differences between forecast and observed features in terms of skill with spatial scale, coverage area, displacement, orientation, and intensity. To demonstrate the utility of applying advanced verification techniques to mid- and coarseresolution models, the Developmental Testbed Center (DTC) applied several traditional metrics and spatial verification techniques to QPFs provided by the Global Forecast System (GFS) and operational North American Mesoscale Model (NAM). Along with frequency bias and Gilbert skill score (GSS) adjusted for bias, both the fractions skill score (FSS) and Method for Object-Based Diagnostic Evaluation (MODE) were utilized for this study with careful consideration given to how these methods were applied and how the results were interpreted. By illustrating the types of forecast attributes appropriate to assess with the spatial verification techniques, this paper provides examples of how to obtain advanced diagnostic information to help identify what aspects of the forecast are or are not performing well.},
	number = {6},
	journal = {Weather and Forecasting},
	author = {Wolff, Jamie K. and Harrold, Michelle and Fowler, Tressa and Gotway, John Halley and Nance, Louisa and Brown, Barbara G.},
	year = {2014},
	note = {Publisher: American Meteorological Society},
	keywords = {Forecast verification/skill, Model comparison, ★, Model evaluation/performance},
	pages = {1451--1472},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/FGI5DA2Q/1520-0434-waf-d-13-00135_1.pdf:application/pdf},
}

@article{marsham_role_2013,
	title = {The role of moist convection in the {West} {African} monsoon system: {Insights} from continental-scale convection-permitting simulations},
	volume = {40},
	issn = {00948276},
	doi = {10.1002/grl.50347},
	abstract = {Predicting the West African monsoon (WAM) remains a major challenge for weather and climate models. We compare multiday continental-scale simulations of the WAM that explicitly resolve moist convection with simulations which parameterize convection. Simulations with the same grid spacing but differing representations of convection isolate the impact of the representation of convection. The more realistic explicit convection gives greater latent and radiative heating farther north, with latent heating later in the day. This weakens the Sahel-Sahara pressure gradient and the monsoon flow, delaying its diurnal cycle and changing interactions between the monsoon and boundary layer convection. In explicit runs, cold storm outflows provide a significant component of the monsoon flux. In an operational global model, biases resemble those in our parameterized case. Improved parameterizations of convection that better capture storm structures, their diurnal cycle, and rainfall intensities will therefore substantially improve predictions of the WAM and coupled aspects of the Earth system. Key PointsSimulations of West African Monsoon with explicit and parameterized convectionMore realistic explicit convection weakens monsoon and delays diurnal cycleCold storm outflows are a significant component of the monsoon in explicit runs ©2013. American Geophysical Union. All Rights Reserved.},
	number = {9},
	journal = {Geophysical Research Letters},
	author = {Marsham, John H. and Dixon, Nick S. and Garcia-Carreras, Luis and Lister, Grenville M.S. and Parker, Douglas J. and Knippertz, Peter and Birch, Cathryn E.},
	month = may,
	year = {2013},
	keywords = {★, cold-pool outflows, Explicit and parameterized convection, Moist convection, West African monsoon},
	pages = {1843--1849},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/BD25L9R2/Geophysical Research Letters - 2013 - Marsham - The role of moist convection in the West African monsoon system  Insights.pdf:application/pdf},
}

@article{ebert_progress_2013,
	title = {Progress and challenges in forecast verification},
	volume = {20},
	issn = {14698080},
	doi = {10.1002/met.1392},
	abstract = {Verification scientists and practitioners came together at the 5th International Verification Methods Workshop in Melbourne, Australia, in December2011 to discuss methods for evaluating forecasts within a wide variety of applications. Progress has been made in many areas including improved verification reporting, wider use of diagnostic verification, development of new scores and techniques for difficult problems, and evaluation of forecasts for applications using meteorological information. There are many interesting challenges, particularly the improvement of methods to verify high resolution ensemble forecasts, seamless predictions spanning multiple spatial and temporal scales, and multivariate forecasts. Greater efforts are needed to make best use of new observations, forge greater links between data assimilation and verification, and develop better and more intuitive forecast verification products for end-users. © 2013 Royal Meteorological Society.},
	number = {2},
	journal = {Meteorological Applications},
	author = {Ebert, E. and Wilson, L. and Weigel, A. and Mittermaier, M. and Nurmi, P. and Gill, P. and Göber, M. and Joslyn, S. and Brown, B. and Fowler, T. and Watkins, A.},
	year = {2013},
	note = {Publisher: John Wiley and Sons Ltd},
	keywords = {★, Forecast verification, Challenges, Evaluation},
	pages = {130--139},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/SBZXQBCD/Meteorological Applications - 2013 - Ebert - Progress and challenges in forecast verification.pdf:application/pdf},
}

@article{harvey_spatial_2016,
	title = {Spatial evaluation of volcanic ash forecasts using satellite observations},
	volume = {16},
	issn = {16807324},
	doi = {10.5194/acp-16-861-2016},
	abstract = {The decision to close airspace in the event of a volcanic eruption is based on hazard maps of predicted ash extent. These are produced using output from volcanic ash transport and dispersion (VATD) models. In this paper the fractions skill score has been used for the first time to evaluate the spatial accuracy of VATD simulations relative to satellite retrievals of volcanic ash. This objective measure of skill provides more information than traditional point-by-point metrics, such as success index and Pearson correlation coefficient, as it takes into the account spatial scale over which skill is being assessed. The FSS determines the scale over which a simulation has skill and can differentiate between a "near miss" and a forecast that is badly misplaced. The idealized scenarios presented show that even simulations with considerable displacement errors have useful skill when evaluated over neighbourhood scales of 200-700 (km)2. This method could be used to compare forecasts produced by different VATDs or using different model parameters, assess the impact of assimilating satellite-retrieved ash data and evaluate VATD forecasts over a long time period.},
	number = {2},
	journal = {Atmospheric Chemistry and Physics},
	author = {Harvey, N. J. and Dacre, H. F.},
	month = jan,
	year = {2016},
	note = {Publisher: Copernicus GmbH},
	pages = {861--872},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/KXNT92JR/c1571e016f1364f32b19cd9ffaaa61c4754f.pdf:application/pdf},
}

@article{skok_analysis_2016,
	title = {Analysis of {Fractions} {Skill} {Score} properties for random precipitation fields and {ECMWF} forecasts},
	volume = {142},
	issn = {1477870X},
	doi = {10.1002/qj.2849},
	abstract = {The Fractions Skill Score (FSS) is a spatial verification measure that is used for assessing the performance of precipitation forecasts from numerical weather prediction models. Previous studies have shown that the FSS is able to give a direct measure of the error in the placement of the rain. This article takes the approach further and derives analytical expressions and uses Monte-Carlo simulations for randomly positioned observed and forecast rainfall to reveal further characteristics of the FSS in both infinite and bounded domains. It reveals that the definition of an FSS value that determines the minimum scale at which a forecast should be deemed ‘useful’ (useful forecast criteria) is a meaningful concept and shows how this value increases with increasing fractional rainfall coverage. A study of real forecast data is also presented using 8 years of European Centre for Medium-Range Weather Forecasts (ECMWF) model forecasts, out to a lead time of 9 days, over domains of differing sizes covering parts of Europe and North Africa. The FSS is examined using different strategies for dealing with the domain boundary and is compared with the analytical study. The findings give practical guidance on how to use the FSS. For most situations a FSS value of {\textgreater}0.5 serves as a good indicator of a useful forecast. The choice of domain size for rainfall forecast verification should consider the typical spatial errors of the forecast. For a domain that is large compared to the typical spatial error, the boundaries have little adverse affect, but this is not the case if the spatial errors start to become comparable to the size of the domain. The evaluation of ECMWF forecasts reveals the extent of the spatial errors that emerge for medium-range forecasts and show the value of verifying those forecasts using the FSS over an appropriately sized region.},
	number = {700},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Skok, Gregor and Roberts, Nigel},
	month = oct,
	year = {2016},
	note = {Publisher: John Wiley and Sons Ltd},
	keywords = {precipitation, verification, Fractions Skill Score, FSS},
	pages = {2599--2610},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/9A2V6TM3/Quart J Royal Meteoro Soc - 2016 - Skok - Analysis of Fractions Skill Score properties for random precipitation fields and.pdf:application/pdf},
}

@article{mittermaier_intercomparison_2010,
	title = {Intercomparison of spatial forecast verification methods: {Identifying} skillful spatial scales using the fractions skill score},
	volume = {25},
	issn = {08828156},
	doi = {10.1175/2009WAF2222260.1},
	abstract = {The fractions skill score (FSS) was one of the measures that formed part of the Intercomparison of Spatial Forecast Verification Methods project. The FSS was used to assess a common dataset that consisted of real and perturbed Weather Research and Forecasting (WRF) model precipitation forecasts, as well as geometric cases. These datasets are all based on the NCEP 240 grid, which translates to approximately 4-km resolution over the contiguous United States. The geometric cases showed that the FSS can provide a truthful assessment of displacement errors and forecast skill. In addition, the FSS can be used to determine the scale at which an acceptable level of skill is reached and this usage is perhaps more helpful than interpreting the actual FSS value. This spatial-scale approach is becoming more popular for monitoring operational forecast performance. The study also shows how the FSS responds to forecast bias.Amore biased forecast always gives lower FSS values at large scales and usually at smaller scales. It is possible, however, for a more biased forecast to give a higher score at smaller scales, when additional rain overlaps the observed rain. However, given a sufficiently large sample of forecasts, a more biased forecast system will score lower. The use of percentile thresholds can remove the impacts of the bias. When the proportion of the domain that is "wet" (the wet-area ratio) is small, subtle differences introduced through near-threshold misses can lead to large changes in FSS magnitude in individual cases (primarily because the bias is changed). Reliable statistics for small wet-area ratios require a larger sample of forecasts. Care needs to be taken in the choice of verification domain. For high-resolution models, the domain should be large enough to encompass the length scale of the typical mesoscale forcing (e.g., upper-level troughs or squall lines). If the domain is too large, the wet-area ratios will always be small. If the domain is too small, fluctuations in the wet-area ratio can be large and larger spatial errors may be missed. The FSS is a good measure of the spatial accuracy of precipitation forecasts. Different methods are needed to determine other patterns of behavior. © 2010 American Meteorological Society.},
	number = {1},
	journal = {Weather and Forecasting},
	author = {Mittermaier, Marion and Roberts, Nigel},
	month = feb,
	year = {2010},
	pages = {343--354},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/VYNFAH23/1520-0434-2009waf2222260_1.pdf:application/pdf},
}

@article{skok_analysis_2015,
	title = {Analysis of {Fraction} {Skill} {Score} properties for a displaced rainband in a rectangular domain},
	volume = {22},
	issn = {14698080},
	doi = {10.1002/met.1478},
	abstract = {A compact analytical expression of the Fraction Skill Score (FSS) is derived for a case with a single displaced rainband in a rectangular domain. The rainband is oriented parallel to the border and displaced perpendicularly to its orientation. An analytical solution is used to determine some of the properties of the FSS which might also be applicable in other cases. The solution is independent of the length of the rainband (it is valid also for a displaced rainy grid point). The position of the borders perpendicular to the rainband orientation does not influence the FSS value. The position of the other two borders does however influence the FSS value in a complex way; moving a border closer to the rainbands can either increase or decrease the FSS value depending on the location of the borders. FSS is shown to be a monotonically increasing function of the neighbourhood size (regardless of the position of the borders). If the FSS value for a displacement that is half the neighbourhood size is used to define a 'useful' FSS value then the usefulness criterion is somewhat different than presented in the original FSS paper (there is no dependence on the frequency of the observations/forecasts). 'Useful' FSS values are always {\textgreater}1/2 but depend on the position of the borders and the size of the displacement.},
	number = {3},
	journal = {Meteorological Applications},
	author = {Skok, Gregor},
	month = jul,
	year = {2015},
	note = {Publisher: John Wiley and Sons Ltd},
	keywords = {Precipitation, Verification, Fraction Skill Score, Rainband},
	pages = {477--484},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/BT3TJJW6/Meteorological Applications - 2014 - Skok - Analysis of Fraction Skill Score properties for a displaced rainband in a.pdf:application/pdf},
}

@article{skok_estimating_2018,
	title = {Estimating the displacement in precipitation forecasts using the {Fractions} {Skill} {Score}},
	volume = {144},
	issn = {1477870X},
	doi = {10.1002/qj.3212},
	abstract = {The Fractions Skill Score (FSS) is a popular spatial verification metric commonly used for precipitation verification. In this study we focus on analysing the ability of FSS to provide meaningful information about the displacement between precipitation in one field compared to another. A simple overlap-adjusted use of the FSS is introduced and a number of relevant idealized cases are analysed that show that the FSS can indeed be used to determine displacement in a meaningful way. It was found that the displacement provided by the FSS is directly related to the true displacements of precipitation but with larger contiguous precipitation objects having a much larger influence. Overall, the displacement provided via the FSS compares well with the average distance to the closest neighbouring precipitation object (assuming the objects are of similar size). It is recommended that the user should use a frequency (percentile) threshold when focussing on spatial differences unless biases are known to be small and adopt the overlap-adjusted variant of the FSS displacement. If the frequency bias is very large the FSS-derived displacements become less reliable. The same is true of any spatial comparison. A recipe for the use of the FSS for determining displacements is provided.},
	number = {711},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Skok, Gregor and Roberts, Nigel},
	month = jan,
	year = {2018},
	note = {Publisher: John Wiley and Sons Ltd},
	keywords = {precipitation, spatial displacement, verification, Fractions Skill Score, FSS},
	pages = {414--425},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/X5WNJHWD/Quart J Royal Meteoro Soc - 2017 - Skok - Estimating the displacement in precipitation forecasts using the Fractions Skill.pdf:application/pdf},
}

@article{roberts_scale-selective_2008,
	title = {Scale-selective verification of rainfall accumulations from high-resolution forecasts of convective events},
	volume = {136},
	issn = {00270644},
	doi = {10.1175/2007MWR2123.1},
	abstract = {The development of NWP models with grid spacing down to ∼1 km should produce more realistic forecasts of convective storms. However, greater realism does not necessarily mean more accurate precipitation forecasts. The rapid growth of errors on small scales in conjunction with preexisting errors on larger scales may limit the usefulness of such models. The purpose of this paper is to examine whether improved model resolution alone is able to produce more skillful precipitation forecasts on useful scales, and how the skill varies with spatial scale. A verification method will be described in which skill is determined from a comparison of rainfall forecasts with radar using fractional coverage over different sized areas. The Met Office Unified Model was run with grid spacings of 12, 4, and 1 km for 10 days in which convection occurred during the summers of 2003 and 2004. All forecasts were run from 12-km initial states for a clean comparison. The results show that the 1-km model was the most skillful over all but the smallest scales (approximately {\textless}10-15 km). A measure of acceptable skill was defined; this was attained by the 1-km model at scales around 40-70 km, some 10-20 km less than that of the 12-km model. The biggest improvement occurred for heavier, more localized rain, despite it being more difficult to predict. The 4-km model did not improve much on the 12-km model because of the difficulties of representing convection at that resolution, which was accentuated by the spinup from 12-km fields.},
	number = {1},
	journal = {Monthly Weather Review},
	author = {Roberts, Nigel M. and Lean, Humphrey W.},
	month = jan,
	year = {2008},
	pages = {78--97},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/BXRBA6BU/1520-0493-2007mwr2123.1.pdf:application/pdf},
}

@article{vogel_skill_2018,
	title = {Skill of {Global} {Raw} and {Postprocessed} {Ensemble} {Predictions} of {Rainfall} over {Northern} {Tropical} {Africa}},
	volume = {33},
	url = {https://doi.org/10.1175/WAF-D-17-},
	doi = {10.1175/WAF-D-17},
	abstract = {Accumulated precipitation forecasts are of high socioeconomic importance for agriculturally dominated societies in northern tropical Africa. In this study, the performance of nine operational global ensemble prediction systems (EPSs) is analyzed relative to climatology-based forecasts for 1-5-day accumulated precipitation based on the monsoon seasons during 2007-14 for three regions within northern tropical Africa. To assess the full potential of raw ensemble forecasts across spatial scales, state-of-the-art statistical post-processing methods were applied in the form of Bayesian model averaging (BMA) and ensemble model output statistics (EMOS), and results were verified against station and spatially aggregated, satellite-based gridded observations. Raw ensemble forecasts are uncalibrated and unreliable, and often underperform relative to climatology, independently of region, accumulation time, monsoon season, and ensemble. The differences between raw ensemble and climatological forecasts are large and partly stem from poor prediction for low precipitation amounts. BMA and EMOS postprocessed forecasts are calibrated, reliable, and strongly improve on the raw ensembles but, somewhat disappointingly, typically do not outperform climatology. Most EPSs exhibit slight improvements over the period 2007-14, but overall they have little added value compared to climatology. The suspicion is that parameterization of convection is a potential cause for the sobering lack of ensemble forecast skill in a region dominated by mesoscale convective systems.},
	number = {2},
	journal = {Weather and Forecasting},
	author = {Vogel, Peter and Knippertz, Peter and Fink, Andreas H and Schlueter, Andreas},
	year = {2018},
	pages = {369--388},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/RSLRK2V5/1520-0434-waf-d-17-0127_1.pdf:application/pdf},
}

@article{nicholson_climate_2017,
	title = {Climate and climatic variability of rainfall over eastern {Africa}},
	volume = {55},
	number = {3},
	journal = {Reviews of Geophysics},
	author = {Nicholson, Sharon E},
	year = {2017},
	pages = {590--635},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/3CGACJPZ/sadfasdfasdfsadf.pdf:application/pdf},
}

@article{ahijevych_application_2009,
	title = {Application of spatial verification methods to idealized and {NWP}-gridded precipitation forecasts},
	volume = {24},
	issn = {08828156},
	doi = {10.1175/2009WAF2222298.1},
	abstract = {Several spatial forecast verification methods have been developed that are suited for high-resolution precipitation forecasts. They can account for the spatial coherence of precipitation and give credit to a forecast that does not necessarily match the observation at any particular grid point. The methods were grouped into four broad categories (neighborhood, scale separation, features based, and field deformation) for the Spatial Forecast Verification Methods Intercomparison Project (ICP). Participants were asked to apply their new methods to a set of artificial geometric and perturbed forecasts with prescribed errors, and a set of real forecasts of convective precipitation on a 4-km grid. This paper describes the intercomparison test cases, summarizes results from the geometric cases, and presents subjective scores and traditional scores from the real cases. All the new methods could detect bias error, and the features-based and field deformation methods were also able to diagnose displacement errors of precipitation features. The best approach for capturing errors in aspect ratio was field deformation. When comparing model forecasts with real cases, the traditional verification scores did not agree with the subjective assessment of the forecasts. © 2009 American Meteorological Society.},
	number = {6},
	journal = {Weather and Forecasting},
	author = {Ahijevych, David and Gilleland, Eric and Brown, Barbara G. and Ebert, Elizabeth E.},
	month = dec,
	year = {2009},
	pages = {1485--1497},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/64E4BXCN/1520-0434-2009waf2222298_1.pdf:application/pdf},
}

@inproceedings{casati_forecast_2008,
	title = {Forecast verification: {Current} status and future directions},
	volume = {15},
	doi = {10.1002/met.52},
	abstract = {Research and development of new verification strategies and reassessment of traditional forecast verification methods has received a groat deal of attention from the scientific community in the last decade. This scientific effort has arisen from the need to respond to changes encompassing several aspects of the verification process, such as the evolution of forecasting systems, or the desire for more meaningful verification approaches that address specific forecast user requirements. Verification techniques that account for the spatial structure and the presence of features in forecast fields, and which are designed specifically for high-resolution forecasts have been developed. The advent of ensemble forecasts has motivated the re-evaluation of some of the traditional scores and the development of new verification methods for probability forecasts. The expected climatological increase of extreme events and their potential socio-economical impacts have revitalized research studies addressing the challenges concerning extreme event verification. Verification issues encountered in the operational forecasting environment have been widely discussed, verification needs for different user communities have been identified, and models to assess the forecast value for specific users have been proposed. Proper verification practice and correct interpretation of verification statistics has been extensively promoted with recent publications and books, tutorials and workshops, and the development of open-source software and verification tools. This paper addresses some of the current issues in forecast verification, reviews some of the most recently developed verification techniques, and provides recommendations for future research. Copyright © 2008 Royal Meteorological Society and Crown in the right of Canada.},
	booktitle = {Meteorological {Applications}},
	publisher = {John Wiley and Sons Ltd},
	author = {Casati, Barbara and Wilson, L. J. and Stephenson, D. B. and Nurmi, P. and Ghelli, Anna and Pocernich, M. and Damrath, U. and Ebert, E. E. and Brown, B. G. and Mason, S.},
	year = {2008},
	note = {Issue: 1
ISSN: 14698080},
	keywords = {Extreme events verification, Operational verification, Probability forecasts and ensemble verification, Spatial verification approaches, User-oriented verification, Value, Verification packages},
	pages = {3--18},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/XCP4WXLY/Meteorological Applications - 2008 - Casati - Forecast verification  current status and future directions.pdf:application/pdf},
}

@article{wilkinson_technique_2017,
	title = {A technique for verification of convection-permitting {NWP} model deterministic forecasts of lightning activity},
	volume = {32},
	issn = {15200434},
	doi = {10.1175/WAF-D-16-0106.1},
	abstract = {This manuscript introduces a new technique for evaluating lightning forecasts from convection-permitting models. In recent years, numerical weather prediction models at the convection-permitting scales (horizontal grid resolutions of 1-5 km) have been able to produce realistic-looking forecasts of lightning activity when compared with observations. However, it is challenging to assess what value these forecasts add above standard large-scale indices. Examining this problem, it is found that existing skill scores and neighborhood verification methods are unable to cope with both the double-penalty effect and the model's variable frequency bias. A displacement distance and a quasi-symmetric distance score are introduced based on the distance between the model and the observations, the latter showing any improvement the forecast has over a completely "hedged" forecast. This can be combined with a domain-improved contingency table and comparisons between modeled and observed lightning flashes to evaluate the forecast performance in three important dimensions: coverage, distance, and intensity. The verification metric is illustrated with a single case, which shows that the convective-scale U.K. variable resolution model (UKV) delivers improved forecasts compared with the large-scale indices in both coverage and distance. Additionally, a month-long analysis is performed, which reveals that the coverage of lightning is in good agreement with the observations; lightning is displaced by the model by a distance on the order of 50-75 km, but the model overpredicts the lightning intensity by at least a factor of 6 after observational detection efficiencies have been considered.},
	number = {1},
	journal = {Weather and Forecasting},
	author = {Wilkinson, Jonathan M.},
	year = {2017},
	note = {Publisher: American Meteorological Society},
	keywords = {Forecast verification/skill, Numerical weather prediction/forecasting, Cloud microphysics, Lightning, Clouds, Convective storms},
	pages = {97--115},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/PCMWYUNK/1520-0434-waf-d-16-0106_1.pdf:application/pdf},
}

@article{noauthor_e3f74f77558daa5801da08ede29e8f36c8bc_nodate,
	title = {e3f74f77558daa5801da08ede29e8f36c8bc},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/EVPVMYAM/e3f74f77558daa5801da08ede29e8f36c8bc.pdf:application/pdf},
}

@article{yan_decoherence_2022,
	title = {Decoherence factor as a convolution: an interplay between a {Gaussian} and an exponential coherence loss},
	issn = {13672630},
	doi = {10.1088/1367-2630/ac9fe8},
	abstract = {We identify and investigate the origin and nature of the transition between Gaussian and exponential forms of decoherence: The decoherence factor (that controls the time dependence of the off-diagonal terms of the density matrix expressed in the pointer basis representation) is the convolution of the Fourier transforms of the spectral density and of the overlap (between the eigenstates the environment with and without couplings to the system). Spectral density alone tends to lead to the (approximately) Gaussian decay of coherence while the overlap alone results in a (largely) exponential decay. We show that these two contributions combine as a convolution, their relative importance controlled by the strength of the system- environment coupling. The resultant decoherence factor in the strong and weak coupling limits leads to predominantly Gaussian or exponential decay, respectively, as is demonstrated with two paradigmatic examples of decoherence—a spin-bath model and the quantum Brownian motion.},
	journal = {New Journal of Physics},
	author = {Yan, Bin and Zurek, Wojciech},
	month = nov,
	year = {2022},
	note = {arXiv: 2110.09463
Publisher: IOP Publishing},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/EBARFHWM/Yan_2022_New_J._Phys._24_113029.pdf:application/pdf},
}

@article{zepeda-arce_space-time_2000,
	title = {Space-time rainfall organization and its role in validating quantitative precipitation forecasts},
	volume = {105},
	issn = {01480227},
	doi = {10.1029/1999JD901087},
	abstract = {The scope of this paper is to introduce a suite of new multiscale statistical measures which can be used, in addition to traditional measures, to compare observed and model-predicted patterns for model validation. Recent research on analysis of observed precipitation patterns at a multitude of scales has revealed interesting spatial and spatiotemporal organizations which have often been related to physical properties of the storm environment. By testing whether this multiscale statistical organization is also reproduced in the model-predicted patterns or whether there are significant biases and disagreements in such comparisons is conjectured to hold promise for understanding model performance and guiding future model improvements. Results from application of the developed methodologies to the May 7-8, 1995, multisquall line storm over central Oklahoma are presented and discussed in light of the additional information gained by the new validation measures as compared to traditional measures. Copyright 2000 by the American Geophysical Union.},
	number = {D8},
	journal = {Journal of Geophysical Research Atmospheres},
	author = {Zepeda-Arce, Jesus and Foufoula-Georgiou, Efi and Droegemeier, Kelvin K.},
	month = apr,
	year = {2000},
	note = {Publisher: Blackwell Publishing Ltd},
	pages = {10129--10146},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/Q4TUQXWI/Journal of Geophysical Research  Atmospheres - 2000 - Zepeda‐Arce - Space‐time rainfall organization and its role in.pdf:application/pdf},
}

@article{marsigli_spatial_2008,
	title = {A spatial verification method applied to the evaluation of high-resolution ensemble forecasts},
	volume = {15},
	issn = {14698080},
	doi = {10.1002/met.65},
	abstract = {The verification of ensemble systems is being operationally carried out in several meteorological centres. However, the main operational ensemble systems have a coarser spatial resolution with respect to the deterministic runs. Only recently, high-resolution limited-area ensembles have started to be run on a regular basis. Their verification requires combining the usual probabilistic evaluation with the statistical verification techniques which are being developed for high-resolution model forecasts (1-10 km). These techniques permit to evaluate a deterministic forecast in a probabilistic manner, by taking into account the spatio-temporal distribution of the forecast at different scales. In this work, a spatial verification technique, called 'distributional method', is used to verify the Consortium for Small-scale MOdeling Limited-area Ensemble Prediction System (COSMO-LEPS) ensemble system, a mesoscale ensemble with 10 km horizontal resolution. The system is mainly designed to give probabilistic assistance in the forecast of severe weather, in particular of intense precipitation possibly leading to floods, hence verification is focused on the ability of the system in forecasting precipitation at high spatial resolution. The methodology is based on a comparison of forecasts and observations in terms of some parameters of their distributions, evaluated after the values are aggregated over boxes of selected size. In particular, performances in terms of average, a few percentiles and maximum forecast value in a box are considered. The system is compared against European Centre for Medium-Range Weather Forecasts Ensemble Prediction System (ECMWF EPS), addressing the issues of an intercomparison between a higher-resolution smaller-size ensemble and a lower-resolution larger-size one. Results show that when the forecast of the average amount of precipitation over an area is concerned, COSMO-LEPS is more skilful than the Ensemble Prediction System (EPS) only from the resolution point of view. Therefore, although not properly calibrated, it is more capable of distinguishing between events and non-events, especially for moderate and high precipitation. Furthermore, COSMO-LEPS has skill in forecasting the occurrence of precipitation peaks over an area, irrespective of the exact location. The analysis of the score behaviour as a function of the distribution parameter shows that EPS has the maximum skill in reproducing the central part of the observed precipitation distribution over an area of about 10 000 km2, while COSMO-LEPS is more skilful in reproducing the tail of the observed precipitation distribution. The problem of the predictability of precipitation at different spatial scales is also investigated, showing the role of different system resolutions. Copyright © 2008 Royal Meteorological Society.},
	number = {1},
	journal = {Meteorological Applications},
	author = {Marsigli, Chiara and Montani, Andrea and Paccangnella, Tiziana},
	month = mar,
	year = {2008},
	note = {Publisher: John Wiley and Sons Ltd},
	keywords = {Verification, Ensemble, High-resolution},
	pages = {125--143},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/49IF477K/Meteorological Applications - 2008 - Marsigli - A spatial verification method applied to the evaluation of high‐resolution.pdf:application/pdf},
}

@techreport{skok_supplementary_nodate,
	title = {Supplementary material to: {Analysis} of {Fractions} {Skill} {Score} properties for random precipitation fields and {ECMWF} forecasts},
	author = {Skok, Gregor and Roberts, Nigel},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/KKUJCGJF/qj2849-sup-0001-files1.pdf:application/pdf},
}

@article{murphy_general_1987,
	title = {A {General} {Framework} for {Forecast} {Verification}},
	volume = {115},
	journal = {Monthly Weather Review},
	author = {Murphy, Allan H and Winkler, Robert L},
	year = {1987},
	pages = {1330--1338},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/YI3LFX4M/1520-0493-1520-0493_1987_115_1330_agfffv_2_0_co_2 (1).pdf:application/pdf},
}

@article{tibshirani_estimating_2001,
	title = {Estimating the number of clusters in a data set via the gap statistic},
	volume = {63},
	issn = {13697412},
	doi = {10.1111/1467-9868.00293},
	abstract = {We propose a method (the 'gap statistic') for estimating the number of clusters (groups) in a set of data. The technique uses the output of any clustering algorithm (e.g. K-means or hierarchical), comparing the change in within-cluster dispersion with that expected under an appropriate reference null distribution. Some theory is developed for the proposal and a simulation study shows that the gap statistic usually outperforms other methods that have been proposed in the literature.},
	number = {2},
	journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
	author = {Tibshirani, Robert and Walther, Guenther and Hastie, Trevor},
	year = {2001},
	note = {Publisher: Blackwell Publishing Ltd},
	keywords = {Clustering, Groups, Hierarchy, K-means, Uniform distribution},
	pages = {411--423},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/7JRA9FS7/Journal of the Royal Statistical Society  Series B  Statistical Methodology - 2002 - Tibshirani - Estimating the number of.pdf:application/pdf},
}

@inproceedings{antonio_post-processing_2023,
	title = {Post-processing {East} {African} precipitation forecasts using a generative machine learning model},
	url = {https://warwick.ac.uk/fac/sci/statistics/news/fsds/},
	urldate = {2023-09-25},
	booktitle = {{CRiSM}  {Fusing} {Simulations} with {Data} {Science}},
	author = {Antonio, Bobby and McRae, Andrew and MacLeod, Dave and Cooper, Fenwick and Marsham, John and Aitchison, Laurence and Palmer, Tim and Watson, Peter},
	month = jul,
	year = {2023},
	file = {CRiSM-FSDS 2023:/Users/bobbyantonio/Zotero/storage/3ZI9YVHW/fsds.html:text/html},
}

@inproceedings{antonio_post-processing_2023-1,
	title = {Post-processing {East} {African} precipitation forecasts using a generative machine learning model},
	shorttitle = {{CI2023}},
	url = {https://cambridge-iccs.github.io/climate-informatics-2023/fulldetails.html},
	language = {en},
	urldate = {2023-09-25},
	booktitle = {12th {International} {Conference} on {Climate} {Informatics}, {University} of {Cambridge}},
	author = {Antonio, Bobby and McRae, Andrew and MacLeod, Dave and Cooper, Fenwick and Marsham, John and Aitchison, Laurence and Palmer, Tim and Watson, Peter},
	month = apr,
	year = {2023},
	note = {https://cambridge-iccs.github.io/climate-informatics-2023/fulldetails.html},
}

@inproceedings{antonio_improving_2023,
	title = {Improving post-processing of {East} {African} precipitation forecasts using a generative machine learning model},
	url = {https://meetingorganizer.copernicus.org/EGU23/EGU23-1365.html},
	language = {en},
	urldate = {2023-09-25},
	booktitle = {{EGU23} {General} {Assembly}, {NP5}.1 {Advances} in statistical post-processing, blending, and verification of deterministic and probabilistic forecasts},
	author = {Antonio, Bobby and McRae, Andrew and MacLeod, Dave and Cooper, Fenwick and Marsham, John and Aitchison, Laurence and Palmer, Tim and Watson, Peter},
	month = feb,
	year = {2023},
}

@misc{lessig_atmorep_2023,
	title = {{AtmoRep}: {A} stochastic model of atmosphere dynamics using large scale representation learning},
	shorttitle = {{AtmoRep}},
	url = {http://arxiv.org/abs/2308.13280},
	abstract = {The atmosphere affects humans in a multitude of ways, from loss of life due to adverse weather effects to long-term social and economic impacts on societies. Computer simulations of atmospheric dynamics are, therefore, of great importance for the well-being of our and future generations. Here, we propose AtmoRep, a novel, task-independent stochastic computer model of atmospheric dynamics that can provide skillful results for a wide range of applications. AtmoRep uses large-scale representation learning from artificial intelligence to determine a general description of the highly complex, stochastic dynamics of the atmosphere from the best available estimate of the system's historical trajectory as constrained by observations. This is enabled by a novel self-supervised learning objective and a unique ensemble that samples from the stochastic model with a variability informed by the one in the historical record. The task-independent nature of AtmoRep enables skillful results for a diverse set of applications without specifically training for them and we demonstrate this for nowcasting, temporal interpolation, model correction, and counterfactuals. We also show that AtmoRep can be improved with additional data, for example radar observations, and that it can be extended to tasks such as downscaling. Our work establishes that large-scale neural networks can provide skillful, task-independent models of atmospheric dynamics. With this, they provide a novel means to make the large record of atmospheric observations accessible for applications and for scientific inquiry, complementing existing simulations based on first principles.},
	urldate = {2023-09-25},
	publisher = {arXiv},
	author = {Lessig, Christian and Luise, Ilaria and Gong, Bing and Langguth, Michael and Stadler, Scarlet and Schultz, Martin},
	month = sep,
	year = {2023},
	note = {arXiv:2308.13280 [physics]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Physics - Atmospheric and Oceanic Physics, Physics - Computational Physics},
	file = {arXiv.org Snapshot:/Users/bobbyantonio/Zotero/storage/DS3TWQP6/2308.html:text/html;Full Text PDF:/Users/bobbyantonio/Zotero/storage/3DSHEJ6D/Lessig et al. - 2023 - AtmoRep A stochastic model of atmosphere dynamics.pdf:application/pdf},
}

@article{senior_convection-permitting_2021,
	title = {Convection-{Permitting} {Regional} {Climate} {Change} {Simulations} for {Understanding} {Future} {Climate} and {Informing} {Decision}-{Making} in {Africa}},
	volume = {102},
	issn = {0003-0007, 1520-0477},
	url = {https://journals.ametsoc.org/view/journals/bams/102/6/BAMS-D-20-0020.1.xml},
	doi = {10.1175/BAMS-D-20-0020.1},
	abstract = {Abstract Pan-Africa convection-permitting regional climate model simulations have been performed to study the impact of high resolution and the explicit representation of atmospheric moist convection on the present and future climate of Africa. These unique simulations have allowed European and African climate scientists to understand the critical role that the representation of convection plays in the ability of a contemporary climate model to capture climate and climate change, including many impact-relevant aspects such as rainfall variability and extremes. There are significant improvements in not only the small-scale characteristics of rainfall such as its intensity and diurnal cycle, but also in the large-scale circulation. Similarly, effects of explicit convection affect not only projected changes in rainfall extremes, dry spells, and high winds, but also continental-scale circulation and regional rainfall accumulations. The physics underlying such differences are in many cases expected to be relevant to all models that use parameterized convection. In some cases physical understanding of small-scale change means that we can provide regional decision-makers with new scales of information across a range of sectors. We demonstrate the potential value of these simulations both as scientific tools to increase climate process understanding and, when used with other models, for direct user applications. We describe how these ground-breaking simulations have been achieved under the U.K. Government’s Future Climate for Africa Programme. We anticipate a growing number of such simulations, which we advocate should become a routine component of climate projection, and encourage international coordination of such computationally and human-resource expensive simulations as effectively as possible.},
	language = {EN},
	number = {6},
	urldate = {2023-09-25},
	journal = {Bulletin of the American Meteorological Society},
	author = {Senior, Catherine A. and Marsham, John H. and Berthou, Ségolène and Burgin, Laura E. and Folwell, Sonja S. and Kendon, Elizabeth J. and Klein, Cornelia M. and Jones, Richard G. and Mittal, Neha and Rowell, David P. and Tomassini, Lorenzo and Vischel, Théo and Becker, Bernd and Birch, Cathryn E. and Crook, Julia and Dougill, Andrew J. and Finney, Declan L. and Graham, Richard J. and Hart, Neil C. G. and Jack, Christopher D. and Jackson, Lawrence S. and James, Rachel and Koelle, Bettina and Misiani, Herbert and Mwalukanga, Brenda and Parker, Douglas J. and Stratton, Rachel A. and Taylor, Christopher M. and Tucker, Simon O. and Wainwright, Caroline M. and Washington, Richard and Willet, Martin R.},
	month = jun,
	year = {2021},
	note = {Publisher: American Meteorological Society
Section: Bulletin of the American Meteorological Society},
	pages = {E1206--E1223},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/GLB3D3V7/Senior et al. - 2021 - Convection-Permitting Regional Climate Change Simu.pdf:application/pdf},
}

@article{scheuerer_variogram-based_2015,
	title = {Variogram-{Based} {Proper} {Scoring} {Rules} for {Probabilistic} {Forecasts} of {Multivariate} {Quantities}},
	volume = {143},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/143/4/mwr-d-14-00269.1.xml},
	doi = {10.1175/MWR-D-14-00269.1},
	abstract = {Abstract Proper scoring rules provide a theoretically principled framework for the quantitative assessment of the predictive performance of probabilistic forecasts. While a wide selection of such scoring rules for univariate quantities exists, there are only few scoring rules for multivariate quantities, and many of them require that forecasts are given in the form of a probability density function. The energy score, a multivariate generalization of the continuous ranked probability score, is the only commonly used score that is applicable in the important case of ensemble forecasts, where the multivariate predictive distribution is represented by a finite sample. Unfortunately, its ability to detect incorrectly specified correlations between the components of the multivariate quantity is somewhat limited. In this paper the authors present an alternative class of proper scoring rules based on the geostatistical concept of variograms. The sensitivity of these variogram-based scoring rules to incorrectly predicted means, variances, and correlations is studied in a number of examples with simulated observations and forecasts; they are shown to be distinctly more discriminative with respect to the correlation structure. This conclusion is confirmed in a case study with postprocessed wind speed forecasts at five wind park locations in Colorado.},
	language = {EN},
	number = {4},
	urldate = {2023-09-23},
	journal = {Monthly Weather Review},
	author = {Scheuerer, Michael and Hamill, Thomas M.},
	month = apr,
	year = {2015},
	note = {Publisher: American Meteorological Society
Section: Monthly Weather Review},
	pages = {1321--1334},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/3IMIDT7C/Scheuerer and Hamill - 2015 - Variogram-Based Proper Scoring Rules for Probabili.pdf:application/pdf},
}

@incollection{dinku_comparison_2010,
	address = {Dordrecht},
	title = {Comparison of {CMORPH} and {TRMM}-{3B42} over {Mountainous} {Regions} of {Africa} and {South} {America}},
	isbn = {978-90-481-2915-7},
	url = {https://doi.org/10.1007/978-90-481-2915-7_11},
	abstract = {Two satellite rainfall estimation algorithms, CMORPH and TMPA, are evaluated over two mountainous regions at daily accumulation and spatial resolution 0.25°. The evaluated TMPA products are TRMM-3B42 and TRMM-3B42RT. The first of the two validations region is located over the Ethiopian highlands in the Horn of Africa. The second is located over the highlands of Columbia in South America. Both sites are characterized by a very complex terrain. Relatively dense station networks over the two sites are used to validate the satellite products. The correlation coefficients between the reference gauge data and the satellite products were found to be low. Besides, the products underestimate both the occurrence and amount of rainfall over both validation sites. These were attributed, at least partly, to orographic warm rain process over the two regions. The performance over Colombia was better compared to that for Ethiopia. And CMORPH has exhibited better performance as compared to the two TRMM products.},
	language = {en},
	urldate = {2023-09-21},
	booktitle = {Satellite {Rainfall} {Applications} for {Surface} {Hydrology}},
	publisher = {Springer Netherlands},
	author = {Dinku, Tufa and Connor, Stephen J. and Ceccato, Pietro},
	editor = {Gebremichael, Mekonnen and Hossain, Faisal},
	year = {2010},
	doi = {10.1007/978-90-481-2915-7_11},
	keywords = {Satellite, Validation, Infrared, Passive microwave, Rainfall estimation},
	pages = {193--204},
}

@article{taylor_overview_2012,
	title = {An {Overview} of {CMIP5} and the {Experiment} {Design}},
	volume = {93},
	url = {https://journals.ametsoc.org/view/journals/bams/93/4/bams-d-11-00094.1.xml},
	doi = {10.1175/BAMS-D-11-00094.1},
	abstract = {The fifth phase of the Coupled Model Intercomparison Project (CMIP5) will produce a state-of-the- art multimodel dataset designed to advance our knowledge of climate variability and climate change. Researchers worldwide are analyzing the model output and will produce results likely to underlie the forthcoming Fifth Assessment Report by the Intergovernmental Panel on Climate Change. Unprecedented in scale and attracting interest from all major climate modeling groups, CMIP5 includes “long term” simulations of twentieth-century climate and projections for the twenty-first century and beyond. Conventional atmosphere–ocean global climate models and Earth system models of intermediate complexity are for the first time being joined by more recently developed Earth system models under an experiment design that allows both types of models to be compared to observations on an equal footing. Besides the longterm experiments, CMIP5 calls for an entirely new suite of “near term” simulations focusing on recent decades and the future to year 2035. These “decadal predictions” are initialized based on observations and will be used to explore the predictability of climate and to assess the forecast system's predictive skill. The CMIP5 experiment design also allows for participation of stand-alone atmospheric models and includes a variety of idealized experiments that will improve understanding of the range of model responses found in the more complex and realistic simulations. An exceptionally comprehensive set of model output is being collected and made freely available to researchers through an integrated but distributed data archive. For researchers unfamiliar with climate models, the limitations of the models and experiment design are described.},
	language = {EN},
	number = {4},
	urldate = {2023-09-21},
	journal = {Bulletin of the American Meteorological Society},
	author = {Taylor, Karl E. and Stouffer, Ronald J. and Meehl, Gerald A.},
	month = apr,
	year = {2012},
	note = {Publisher: American Meteorological Society
Section: Bulletin of the American Meteorological Society},
	pages = {485--498},
}

@article{ageet_validation_2022,
	title = {Validation of {Satellite} {Rainfall} {Estimates} over {Equatorial} {East} {Africa}},
	volume = {23},
	issn = {1525-7541, 1525-755X},
	url = {https://journals.ametsoc.org/view/journals/hydr/23/2/JHM-D-21-0145.1.xml},
	doi = {10.1175/JHM-D-21-0145.1},
	abstract = {Abstract Rain gauge data sparsity over Africa is known to impede the assessments of hydrometeorological risks and of the skill of numerical weather prediction models. Satellite rainfall estimates (SREs) have been used as surrogate fields for a long time and are continuously replaced by more advanced algorithms and new sensors. Using a unique daily rainfall dataset from 36 stations across equatorial East Africa for the period 2001–18, this study performs a multiscale evaluation of gauge-calibrated SREs, namely, IMERG, TMPA, CHIRPS, and MSWEP (v2.2 and v2.8). Skills were assessed from daily to annual time scales, for extreme daily precipitation, and for TMPA and IMERG near-real-time (NRT) products. Results show that 1) the SREs reproduce the annual rainfall pattern and seasonal rainfall cycle well, despite exhibiting biases of up to 9\%; 2) IMERG is the best for shorter temporal scales while MSWEPv2.2 and CHIRPS perform best at the monthly and annual time steps, respectively; 3) the performance of all the SREs varies spatially, likely due to an inhomogeneous degree of gauge calibration, with the largest variation seen in MSWEPv2.2; 4) all the SREs miss between 79\% (IMERG-NRT) and 98\% (CHIRPS) of daily extreme rainfall events recorded by the rain gauges; 5) IMERG-NRT is the best regarding extreme event detection and accuracy; and 6) for return values of extreme rainfall, IMERG, and MSWEPv2.2 have the least errors while CHIRPS and MSWEPv2.8 cannot be recommended. The study also highlights improvements of IMERG over TMPA, the decline in performance of MSWEPv2.8 compared to MSWEPv2.2, and the potential of SREs for flood risk assessment over East Africa.},
	language = {EN},
	number = {2},
	urldate = {2023-09-21},
	journal = {Journal of Hydrometeorology},
	author = {Ageet, Simon and Fink, Andreas H. and Maranan, Marlon and Diem, Jeremy E. and Hartter, Joel and Ssali, Andrew L. and Ayabagabo, Prosper},
	month = feb,
	year = {2022},
	note = {Publisher: American Meteorological Society
Section: Journal of Hydrometeorology},
	pages = {129--151},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/L3J64XHB/Ageet et al. - 2022 - Validation of Satellite Rainfall Estimates over Eq.pdf:application/pdf},
}

@article{rowell_causes_2018,
	title = {Causes of the {Uncertainty} in {Projections} of {Tropical} {Terrestrial} {Rainfall} {Change}: {East} {Africa}},
	volume = {31},
	issn = {0894-8755, 1520-0442},
	shorttitle = {Causes of the {Uncertainty} in {Projections} of {Tropical} {Terrestrial} {Rainfall} {Change}},
	url = {https://journals.ametsoc.org/view/journals/clim/31/15/jcli-d-17-0830.1.xml},
	doi = {10.1175/JCLI-D-17-0830.1},
	abstract = {Abstract Understanding the causes of regional climate projection uncertainty is a critical component toward establishing reliability of these projections. Here, four complementary experimental and decomposition techniques are synthesized to begin to understand which mechanisms differ most between models. These tools include a variety of multimodel ensembles, a decomposition of rainfall into tropics-wide or region-specific processes, and a separation of within-domain versus remote contributions to regional model projection uncertainty. Three East African regions are identified and characterized by spatially coherent intermodel projection behavior, which interestingly differs from previously identified regions of coherent interannual behavior. For the “Short Rains” regions, uncertainty in projected seasonal mean rainfall change is primarily due to uncertainties in the regional response to both the uniform and pattern components of SST warming (but not uncertainties in the global mean warming itself) and a small direct CO2 impact. These primarily derive from uncertain regional dynamics over both African and remote regions, rather than globally coherent (thermo)dynamics. For the “Long Rains” region, results are similar, except that uncertain atmospheric responses to a fixed SST pattern change are a little less important, and some key regional uncertainties are primarily located beyond Africa. The latter reflects the behavior of two outlying models that experience exceptional warming in the southern subtropical oceans, from which large lower-tropospheric moisture anomalies are advected by the mean flow to contribute to exceptional increases in the Long Rains totals. Further research could lead to a useful assessment of the reliability of these exceptional projections.},
	language = {EN},
	number = {15},
	urldate = {2023-09-21},
	journal = {Journal of Climate},
	author = {Rowell, David P. and Chadwick, Robin},
	month = aug,
	year = {2018},
	note = {Publisher: American Meteorological Society
Section: Journal of Climate},
	pages = {5977--5995},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/ZVLG2ZY6/Rowell and Chadwick - 2018 - Causes of the Uncertainty in Projections of Tropic.pdf:application/pdf},
}

@article{chapman_climate_2022,
	title = {Climate {Change} {Impacts} on {Extreme} {Rainfall} in {Eastern} {Africa} in a {Convection}-{Permitting} {Climate} {Model}},
	volume = {36},
	issn = {0894-8755, 1520-0442},
	url = {https://journals.ametsoc.org/view/journals/clim/36/1/JCLI-D-21-0851.1.xml},
	doi = {10.1175/JCLI-D-21-0851.1},
	abstract = {Abstract Climate change is expected to increase the frequency and intensity of rainfall extremes. Understanding future changes in rainfall is necessary for adaptation planning. Eastern Africa is vulnerable to rainfall extremes because of low adaptive capacity and high future population growth. Convection-permitting climate models have been found to better represent moderate (yearly) rainfall extremes than parameterized convection models, but there is limited analysis of rare extremes that occur less frequently than once per year. These events often have the largest socioeconomic impacts. We use extreme value theory and regional frequency analysis to quantify rare rainfall extremes over East Africa in a convection-permitting climate model (CP4A). We compare the results with its parameterized counterpart (P25), the Coordinated Regional Climate Downscaling Experiment for the African region (CORDEX-Africa) ensemble, and observations to understand how the convection parameterization impacts the results. We find that CP4A better matches observations than the parameterized models. With climate change, we find the parameterized convection models have unrealistically high changes in the shape parameter of the extreme value distribution, which controls the tail behavior (i.e., the most extreme events), leading to large increases in return levels of events with a return period of {\textgreater}20 years. This suggests that parameterized convection models may not be suitable for looking at relative changes in rare rainfall events with climate change and that convection-permitting models should be preferred for this type of work. With the more realistic CP4A, RCP8.5 end-of-century climate change leads to 1-in-100-yr events becoming 1-in-23-yr events, which will necessitate serious adaptation efforts to avoid devastating socioeconomic impacts. Significance Statement We use a new, high-resolution climate model to examine how rare extreme rainfall events in East Africa might change in the future with climate change and compare the results with those from standard-resolution climate models. We find that the standard-resolution models have unrealistically large increases in rainfall for events that occur less frequently than every 20 years. The high-resolution model is more realistic and is required to illustrate possible future changes in rare rainfall extremes. Extreme events will become more common with climate change, and in the more realistic model we show that a 1-in-100-yr event may become a 1-in-23-yr event by the end of the century if greenhouse gas emissions are not significantly reduced.},
	language = {EN},
	number = {1},
	urldate = {2023-09-21},
	journal = {Journal of Climate},
	author = {Chapman, Sarah and Bacon, James and Birch, Cathryn E. and Pope, Edward and Marsham, John H. and Msemo, Hellen and Nkonde, Edson and Sinachikupo, Kenneth and Vanya, Charles},
	month = dec,
	year = {2022},
	note = {Publisher: American Meteorological Society
Section: Journal of Climate},
	pages = {93--109},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/YTIQHL74/Chapman et al. - 2022 - Climate Change Impacts on Extreme Rainfall in East.pdf:application/pdf},
}

@misc{antonio_cgan_2023,
	title = {{cGAN}},
	copyright = {MIT},
	shorttitle = {Conditional {GAN}},
	url = {www.github.com/bobbyantonio/downscaling-cgan},
	urldate = {2023-09-21},
	author = {Antonio, Bobby},
	month = aug,
	year = {2023},
	note = {www.github.com/bobbyantonio/downscaling-cgan},
}

@article{kimani_assessment_2017,
	title = {An {Assessment} of {Satellite}-{Derived} {Rainfall} {Products} {Relative} to {Ground} {Observations} over {East} {Africa}},
	volume = {9},
	issn = {2072-4292},
	url = {https://research.utwente.nl/en/publications/an-assessment-of-satellite-derived-rainfall-products-relative-to-},
	doi = {10.3390/rs9050430},
	language = {English},
	number = {5},
	urldate = {2023-09-21},
	journal = {Remote sensing},
	author = {Kimani, M. W. and Hoedjes, Johannes Cornelis Bernardus and Su, Z.},
	year = {2017},
	note = {Publisher: MDPI},
	pages = {430},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/RHHMGE8E/Kimani et al. - 2017 - An Assessment of Satellite-Derived Rainfall Produc.pdf:application/pdf},
}

@techreport{wilson_forecast_2014,
	address = {Geneva, Switzerland},
	title = {Forecast {Verification} for the {African} {Severe} {Weather} {Forecasting} {Demonstration} {Projects}},
	institution = {World Meteorological Organization},
	author = {Wilson, Laurence},
	year = {2014},
	keywords = {SWFDP},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/ZGDSJEAQ/wmo_1132_en.pdf:application/pdf},
}

@misc{ecmwf_parameter_2023,
	title = {Parameter database},
	url = {https://codes.ecmwf.int/grib/param-db/},
	urldate = {2023-09-20},
	author = {ECMWF},
	month = feb,
	year = {2023},
	note = {https://codes.ecmwf.int/grib/param-db/, Accessed February 2023},
	file = {ECMWF | Parameter database:/Users/bobbyantonio/Zotero/storage/6XCFJYS7/param-db.html:text/html},
}

@book{maraun_statistical_2018,
	edition = {1},
	title = {Statistical {Downscaling} and {Bias} {Correction} for {Climate} {Research}},
	isbn = {978-1-107-06605-2 978-1-107-58878-3 978-1-107-68608-3},
	url = {https://www.cambridge.org/core/product/identifier/9781107588783/type/book},
	language = {en},
	urldate = {2023-09-20},
	publisher = {Cambridge University Press},
	author = {Maraun, Douglas and Widmann, Martin},
	month = jan,
	year = {2018},
	doi = {10.1017/9781107588783},
	file = {Maraun and Widmann - 2018 - Statistical Downscaling and Bias Correction for Cl.pdf:/Users/bobbyantonio/Zotero/storage/3FQTHTIU/Maraun and Widmann - 2018 - Statistical Downscaling and Bias Correction for Cl.pdf:application/pdf},
}

@article{gronquist_deep_2021,
	title = {Deep learning for post-processing ensemble weather forecasts},
	volume = {379},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2020.0092},
	doi = {10.1098/rsta.2020.0092},
	abstract = {Quantifying uncertainty in weather forecasts is critical, especially for predicting extreme weather events. This is typically accomplished with ensemble prediction systems, which consist of many perturbed numerical weather simulations, or trajectories, run in parallel. These systems are associated with a high computational cost and often involve statistical post-processing steps to inexpensively improve their raw prediction qualities. We propose a mixed model that uses only a subset of the original weather trajectories combined with a post-processing step using deep neural networks. These enable the model to account for non-linear relationships that are not captured by current numerical models or post-processing methods. Applied to the global data, our mixed models achieve a relative improvement in ensemble forecast skill (CRPS) of over 14\%. Furthermore, we demonstrate that the improvement is larger for extreme weather events on select case studies. We also show that our post-processing can use fewer trajectories to achieve comparable results to the full ensemble. By using fewer trajectories, the computational costs of an ensemble prediction system can be reduced, allowing it to run at higher resolution and produce more accurate forecasts.

This article is part of the theme issue ‘Machine learning for weather and climate modelling’.},
	number = {2194},
	urldate = {2023-09-20},
	journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Grönquist, Peter and Yao, Chengyuan and Ben-Nun, Tal and Dryden, Nikoli and Dueben, Peter and Li, Shigang and Hoefler, Torsten},
	month = feb,
	year = {2021},
	note = {Publisher: Royal Society},
	keywords = {deep learning, ensemble post-processing, extreme weather events, weather uncertainty quantification},
	pages = {20200092},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/9EWGBNX2/Grönquist et al. - 2021 - Deep learning for post-processing ensemble weather.pdf:application/pdf},
}

@article{yuval_stable_2020,
	title = {Stable machine-learning parameterization of subgrid processes for climate modeling at a range of resolutions},
	volume = {11},
	copyright = {2020 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-020-17142-3},
	doi = {10.1038/s41467-020-17142-3},
	abstract = {Global climate models represent small-scale processes such as convection using subgrid models known as parameterizations, and these parameterizations contribute substantially to uncertainty in climate projections. Machine learning of new parameterizations from high-resolution model output is a promising approach, but such parameterizations have been prone to issues of instability and climate drift, and their performance for different grid spacings has not yet been investigated. Here we use a random forest to learn a parameterization from coarse-grained output of a three-dimensional high-resolution idealized atmospheric model. The parameterization leads to stable simulations at coarse resolution that replicate the climate of the high-resolution simulation. Retraining for different coarse-graining factors shows the parameterization performs best at smaller horizontal grid spacings. Our results yield insights into parameterization performance across length scales, and they also demonstrate the potential for learning parameterizations from global high-resolution simulations that are now emerging.},
	language = {en},
	number = {1},
	urldate = {2023-09-20},
	journal = {Nature Communications},
	author = {Yuval, Janni and O’Gorman, Paul A.},
	month = jul,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Climate and Earth system modelling, Atmospheric dynamics},
	pages = {3295},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/BFGXL8SP/Yuval and O’Gorman - 2020 - Stable machine-learning parameterization of subgri.pdf:application/pdf},
}

@misc{noauthor_deep_nodate,
	title = {Deep learning to represent subgrid processes in climate models},
	url = {https://www.pnas.org/doi/10.1073/pnas.1810286115},
	language = {en},
	urldate = {2023-09-20},
	note = {ISBN: 9781810286112},
	file = {Snapshot:/Users/bobbyantonio/Zotero/storage/2HAQA7KY/pnas.html:text/html},
}

@article{krasnopolsky_using_2013,
	title = {Using {Ensemble} of {Neural} {Networks} to {Learn} {Stochastic} {Convection} {Parameterizations} for {Climate} and {Numerical} {Weather} {Prediction} {Models} from {Data} {Simulated} by a {Cloud} {Resolving} {Model}},
	volume = {2013},
	issn = {1687-7594, 1687-7608},
	url = {https://www.hindawi.com/journals/aans/2013/485913/},
	doi = {10.1155/2013/485913},
	abstract = {A novel approach based on the neural network (NN) ensemble technique is formulated and used for development of a NN stochastic convection parameterization for climate and numerical weather prediction (NWP) models. This fast parameterization is built based on learning from data simulated by a cloud-resolving model (CRM) initialized with and forced by the observed meteorological data available for 4-month boreal winter from November 1992 to February 1993. CRM-simulated data were averaged and processed to implicitly define a stochastic convection parameterization. This parameterization is learned from the data using an ensemble of NNs. The NN ensemble members are trained and tested. The inherent uncertainty of the stochastic convection parameterization derived following this approach is estimated. The newly developed NN convection parameterization has been tested in National Center of Atmospheric Research (NCAR) Community Atmospheric Model (CAM). It produced reasonable and promising decadal climate simulations for a large tropical Pacific region. The extent of the adaptive ability of the developed NN parameterization to the changes in the model environment is briefly discussed. This paper is devoted to a proof of concept and discusses methodology, initial results, and the major challenges of using the NN technique for developing convection parameterizations for climate and NWP models.},
	language = {en},
	urldate = {2023-09-20},
	journal = {Advances in Artificial Neural Systems},
	author = {Krasnopolsky, Vladimir M. and Fox-Rabinovitz, Michael S. and Belochitski, Alexei A.},
	month = may,
	year = {2013},
	pages = {1--13},
	file = {Krasnopolsky et al. - 2013 - Using Ensemble of Neural Networks to Learn Stochas.pdf:/Users/bobbyantonio/Zotero/storage/JPHYKD32/Krasnopolsky et al. - 2013 - Using Ensemble of Neural Networks to Learn Stochas.pdf:application/pdf},
}

@inproceedings{krasnopolsky_development_2010,
	title = {Development of neural network convection parameterizations for numerical climate and weather prediction models using cloud resolving model simulations},
	doi = {10.1109/IJCNN.2010.5596766},
	abstract = {A novel approach based on the neural network (NN) technique is formulated and used for development of a NN ensemble stochastic convection parameterization for numerical climate and weather prediction models. This fast parameterization is built based on data from Cloud Resolving Model (CRM) simulations initialized with TOGA-COARE data. CRM emulated data are averaged and projected onto the General Circulation Model (GCM) space of atmospheric states to implicitly define a stochastic convection parameterization. This parameterization is comprised as an ensemble of neural networks. The developed NNs are trained and tested. The inherent uncertainty of the stochastic convection parameterization derived in such a way is estimated. The major challenges of development of stochastic NN parameterizations are discussed based on our initial results.},
	booktitle = {The 2010 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	author = {Krasnopolsky, Vladimir M. and Fox-Rabinovitz, Michael S. and Belochitski, Alexei A.},
	month = jul,
	year = {2010},
	note = {ISSN: 2161-4407},
	keywords = {Artificial neural networks, Cooling, Electricity, Heating, Numerical models},
	pages = {1--8},
	file = {IEEE Xplore Abstract Record:/Users/bobbyantonio/Zotero/storage/BBSYS933/5596766.html:text/html;IEEE Xplore Full Text PDF:/Users/bobbyantonio/Zotero/storage/EI3I2HWM/Krasnopolsky et al. - 2010 - Development of neural network convection parameter.pdf:application/pdf},
}

@article{brenowitz_prognostic_2018,
	title = {Prognostic {Validation} of a {Neural} {Network} {Unified} {Physics} {Parameterization}},
	volume = {45},
	copyright = {©2018. American Geophysical Union. All Rights Reserved.},
	issn = {1944-8007},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2018GL078510},
	doi = {10.1029/2018GL078510},
	abstract = {Weather and climate models approximate diabatic and sub-grid-scale processes in terms of grid-scale variables using parameterizations. Current parameterizations are designed by humans based on physical understanding, observations, and process modeling. As a result, they are numerically efficient and interpretable, but potentially oversimplified. However, the advent of global high-resolution simulations and observations enables a more robust approach based on machine learning. In this letter, a neural network-based parameterization is trained using a near-global aqua-planet simulation with a 4-km resolution (NG-Aqua). The neural network predicts the apparent sources of heat and moisture averaged onto (160 km)2 grid boxes. A numerically stable scheme is obtained by minimizing the prediction error over multiple time steps rather than single one. In prognostic single-column model tests, this scheme matches both the fluctuations and equilibrium of NG-Aqua simulation better than the Community Atmosphere Model does.},
	language = {en},
	number = {12},
	urldate = {2023-09-20},
	journal = {Geophysical Research Letters},
	author = {Brenowitz, N. D. and Bretherton, C. S.},
	year = {2018},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/2018GL078510},
	keywords = {machine learning, neural network, cloud-resolving model, cumulus parameterization, single-column model},
	pages = {6289--6298},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/GUFC9H97/Brenowitz and Bretherton - 2018 - Prognostic Validation of a Neural Network Unified .pdf:application/pdf;Snapshot:/Users/bobbyantonio/Zotero/storage/NYDISQ2P/2018GL078510.html:text/html},
}

@misc{ecmwf_section_2023,
	title = {Section 2 {The} {ECMWF} {Integrated} {Forecasting} {System} - {IFS} - {Forecast} {User} {Guide} - {ECMWF} {Confluence} {Wiki}},
	url = {https://confluence.ecmwf.int/display/FUG/Section+2+The+ECMWF+Integrated+Forecasting+System+-+IFS},
	urldate = {2023-09-19},
	author = {ECMWF},
	month = sep,
	year = {2023},
	file = {Section 2 The ECMWF Integrated Forecasting System - IFS - Forecast User Guide - ECMWF Confluence Wiki:/Users/bobbyantonio/Zotero/storage/I7AE4FVJ/Section+2+The+ECMWF+Integrated+Forecasting+System+-+IFS.html:text/html},
}

@article{bryan_resolution_2003,
	title = {Resolution {Requirements} for the {Simulation} of {Deep} {Moist} {Convection}},
	volume = {131},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/131/10/1520-0493_2003_131_2394_rrftso_2.0.co_2.xml},
	doi = {10.1175/1520-0493(2003)131<2394:RRFTSO>2.0.CO;2},
	abstract = {Abstract The spatial resolution appropriate for the simulation of deep moist convection is addressed from a turbulence perspective. To provide a clear theoretical framework for the problem, techniques for simulating turbulent flows are reviewed, and the source of the subgrid terms in the Navier–Stokes equation is clarified. For decades, cloud-resolving models have used large-eddy simulation (LES) techniques to parameterize the subgrid terms. A literature review suggests that the appropriateness of using traditional LES closures for this purpose has never been established. Furthermore, examination of the assumptions inherent in these closures suggests that grid spacing on the order of 100 m may be required for the performance of cloud models to be consistent with their design. Based on these arguments, numerical simulations of squall lines were conducted with grid spacings between 1 km and 125 m. The results reveal that simulations with 1-km grid spacing do not produce equivalent squall-line structure and evolution as compared to the higher-resolution simulations. Details of the simulated squall lines that change as resolution is increased include precipitation amount, system phase speed, cloud depth, static stability values, the size of thunderstorm cells, and the organizational mode of convective overturning (e.g., upright towers versus sloped plumes). It is argued that the ability of the higher-resolution runs to become turbulent leads directly to the differences in evolution. There appear to be no systematic trends in specific fields as resolution is increased. For example, mean vertical velocity and rainwater values increase in magnitude with increasing resolution in some environments, but decrease with increasing resolution in other environments. The statistical properties of the simulated squall lines are still not converged between the 250- and 125-m runs. Several possible explanations for the lack of convergence are offered. Nevertheless, it is clear that simulations with O(1 km) grid spacing should not be used as benchmark or control solutions for resolution sensitivity studies. The simulations also support the contention that a minimum grid spacing of O(100 m) is required for traditional LES closures to perform appropriately for their design. Specifically, only simulations with 250- and 125-m grid spacing resolve an inertial subrange. In contrast, the 1-km simulations do not even reproduce the correct magnitude or scale of the spectral kinetic energy maximum. Furthermore, the 1-km simulations contain an unacceptably large amount of subgrid turbulence kinetic energy, and do not adequately resolve turbulent fluxes of total water. A guide to resolution requirements for the operational and research communities is proposed. The proposal is based primarily on the intended use of the model output. Even though simulations with O(1 km) grid spacing display behavior that is unacceptable for the model design, it is argued that these simulations can still provide valuable information to operational forecasters. For the research community, O(100 m) grid spacing is recommended for most applications, because a modeling system that is well founded should be desired for most purposes.},
	language = {EN},
	number = {10},
	urldate = {2023-09-19},
	journal = {Monthly Weather Review},
	author = {Bryan, George H. and Wyngaard, John C. and Fritsch, J. Michael},
	month = oct,
	year = {2003},
	note = {Publisher: American Meteorological Society
Section: Monthly Weather Review},
	pages = {2394--2416},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/RBBX35F9/Bryan et al. - 2003 - Resolution Requirements for the Simulation of Deep.pdf:application/pdf},
}

@article{houze_jr_mesoscale_2004,
	title = {Mesoscale convective systems},
	volume = {42},
	copyright = {Copyright 2004 by the American Geophysical Union.},
	issn = {1944-9208},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2004RG000150},
	doi = {10.1029/2004RG000150},
	abstract = {Mesoscale convective systems (MCSs) have regions of both convective and stratiform precipitation, and they develop mesoscale circulations as they mature. The upward motion takes the form of a deep-layer ascent drawn into the MCS in response to the latent heating and cooling in the convective region. The ascending layer overturns as it rises but overall retains a coherent layer structure. A middle level layer of inflow enters the stratiform region of the MCS from a direction determined by the large-scale flow and descends in response to diabatic cooling at middle-to-low levels. A middle level mesoscale convective vortex (MCV) develops in the stratiform region, prolongs the MCS, and may contribute to tropical cyclone development. The propagation of an MCS may have a discrete component but may further be influenced by waves and disturbances generated both in response to the MCS and external to the MCS. Waves of a larger scale may affect the propagation velocity by phase locking with the MCS in a cooperative mode. The horizontal scale of an MCS may be limited either by a balance between the formation rate of convective precipitation and dissipation of stratiform precipitation or by the Rossby radius of the MCV. The vertical redistribution of momentum by an MCS depends on the size of the stratiform region, while the net vertical profile of heating of the large-scale environment depends on the amount of stratiform rain. Regional variability of the stratiform rain from MCSs affects the large-scale circulation's response to MCS heating.},
	language = {en},
	number = {4},
	urldate = {2023-09-18},
	journal = {Reviews of Geophysics},
	author = {Houze Jr., Robert A.},
	year = {2004},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/2004RG000150},
	keywords = {precipitation, convective processes, mesoscale meteorology},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/MMJ93Z3E/Houze Jr. - 2004 - Mesoscale convective systems.pdf:application/pdf;Snapshot:/Users/bobbyantonio/Zotero/storage/ZVIAQKMN/2004RG000150.html:text/html},
}

@article{stratton_pan-african_2018,
	title = {A {Pan}-{African} {Convection}-{Permitting} {Regional} {Climate} {Simulation} with the {Met} {Office} {Unified} {Model}: {CP4}-{Africa}},
	volume = {31},
	issn = {0894-8755, 1520-0442},
	shorttitle = {A {Pan}-{African} {Convection}-{Permitting} {Regional} {Climate} {Simulation} with the {Met} {Office} {Unified} {Model}},
	url = {https://journals.ametsoc.org/view/journals/clim/31/9/jcli-d-17-0503.1.xml},
	doi = {10.1175/JCLI-D-17-0503.1},
	abstract = {Abstract A convection-permitting multiyear regional climate simulation using the Met Office Unified Model has been run for the first time on an Africa-wide domain. The model has been run as part of the Future Climate for Africa (FCFA) Improving Model Processes for African Climate (IMPALA) project, and its configuration, domain, and forcing data are described here in detail. The model [Pan-African Convection-Permitting Regional Climate Simulation with the Met Office UM (CP4-Africa)] uses a 4.5-km horizontal grid spacing at the equator and is run without a convection parameterization, nested within a global atmospheric model driven by observations at the sea surface, which does include a convection scheme. An additional regional simulation, with identical resolution and physical parameterizations to the global model, but with the domain, land surface, and aerosol climatologies of CP4-Africa, has been run to aid in the understanding of the differences between the CP4-Africa and global model, in particular to isolate the impact of the convection parameterization and resolution. The effect of enforcing moisture conservation in CP4-Africa is described and its impact on reducing extreme precipitation values is assessed. Preliminary results from the first five years of the CP4-Africa simulation show substantial improvements in JJA average rainfall compared to the parameterized convection models, with most notably a reduction in the persistent dry bias in West Africa, giving an indication of the benefits to be gained from running a convection-permitting simulation over the whole African continent.},
	language = {EN},
	number = {9},
	urldate = {2023-09-18},
	journal = {Journal of Climate},
	author = {Stratton, Rachel A. and Senior, Catherine A. and Vosper, Simon B. and Folwell, Sonja S. and Boutle, Ian A. and Earnshaw, Paul D. and Kendon, Elizabeth and Lock, Adrian P. and Malcolm, Andrew and Manners, James and Morcrette, Cyril J. and Short, Christopher and Stirling, Alison J. and Taylor, Christopher M. and Tucker, Simon and Webster, Stuart and Wilkinson, Jonathan M.},
	month = may,
	year = {2018},
	note = {Publisher: American Meteorological Society
Section: Journal of Climate},
	pages = {3485--3508},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/GBFTM29F/Stratton et al. - 2018 - A Pan-African Convection-Permitting Regional Clima.pdf:application/pdf},
}

@article{finney_effects_2020,
	title = {Effects of {Explicit} {Convection} on {Future} {Projections} of {Mesoscale} {Circulations}, {Rainfall}, and {Rainfall} {Extremes} over {Eastern} {Africa}},
	volume = {33},
	issn = {0894-8755, 1520-0442},
	url = {https://journals.ametsoc.org/view/journals/clim/33/7/jcli-d-19-0328.1.xml},
	doi = {10.1175/JCLI-D-19-0328.1},
	abstract = {Abstract Eastern Africa’s fast-growing population is vulnerable to changing rainfall and extremes. Using the first pan-African climate change simulations that explicitly model the rainfall-generating convection, we investigate both the climate change response of key mesoscale drivers of eastern African rainfall, such as sea and lake breezes, and the spatial heterogeneity of rainfall responses. The explicit model shows widespread increases at the end of the century in mean ({\textasciitilde}40\%) and extreme ({\textasciitilde}50\%) rain rates, whereas the sign of changes in rainfall frequency has large spatial heterogeneity (from −50\% to over +90\%). In comparison, an equivalent parameterized simulation has greater moisture convergence and total rainfall increase over the eastern Congo and less over eastern Africa. The parameterized model also does not capture 1) the large heterogeneity of changes in rain frequency; 2) the widespread and large increases in extreme rainfall, which result from increased rainfall per humidity change; and 3) the response of rainfall to the changing sea breeze, even though the sea-breeze change is captured. Consequently, previous rainfall projections are likely inadequate for informing many climate-sensitive decisions—for example, for infrastructure in coastal cities. We consider the physics revealed here and its implications to be relevant for many other vulnerable tropical regions, especially those with coastal convection.},
	language = {EN},
	number = {7},
	urldate = {2023-09-18},
	journal = {Journal of Climate},
	author = {Finney, Declan L. and Marsham, John H. and Rowell, David P. and Kendon, Elizabeth J. and Tucker, Simon O. and Stratton, Rachel A. and Jackson, Lawrence S.},
	month = apr,
	year = {2020},
	note = {Publisher: American Meteorological Society
Section: Journal of Climate},
	pages = {2701--2718},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/K7HZSU6F/Finney et al. - 2020 - Effects of Explicit Convection on Future Projectio.pdf:application/pdf},
}

@article{watson_applying_2019,
	title = {Applying {Machine} {Learning} to {Improve} {Simulations} of a {Chaotic} {Dynamical} {System} {Using} {Empirical} {Error} {Correction}},
	volume = {11},
	copyright = {©2019. The Authors.},
	issn = {1942-2466},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2018MS001597},
	doi = {10.1029/2018MS001597},
	abstract = {Dynamical weather and climate prediction models underpin many studies of the Earth system and hold the promise of being able to make robust projections of future climate change based on physical laws. However, simulations from these models still show many differences compared with observations. Machine learning has been applied to solve certain prediction problems with great success, and recently, it has been proposed that this could replace the role of physically-derived dynamical weather and climate models to give better quality simulations. Here, instead, a framework using machine learning together with physically-derived models is tested, in which it is learnt how to correct the errors of the latter from time step to time step. This maintains the physical understanding built into the models, while allowing performance improvements, and also requires much simpler algorithms and less training data. This is tested in the context of simulating the chaotic Lorenz '96 system, and it is shown that the approach yields models that are stable and that give both improved skill in initialized predictions and better long-term climate statistics. Improvements in long-term statistics are smaller than for single time step tendencies, however, indicating that it would be valuable to develop methods that target improvements on longer time scales. Future strategies for the development of this approach and possible applications to making progress on important scientific problems are discussed.},
	language = {en},
	number = {5},
	urldate = {2023-09-14},
	journal = {Journal of Advances in Modeling Earth Systems},
	author = {Watson, Peter A. G.},
	year = {2019},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/2018MS001597},
	keywords = {machine learning, neural network, Lorenz '96, modeling},
	pages = {1402--1417},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/B4MUL5M9/Watson - 2019 - Applying Machine Learning to Improve Simulations o.pdf:application/pdf;Snapshot:/Users/bobbyantonio/Zotero/storage/BEV8PRG5/2018MS001597.html:text/html},
}

@article{pohl_influence_2006,
	title = {Influence of the {Madden}–{Julian} {Oscillation} on {East} {African} rainfall. {I}: {Intraseasonal} variability and regional dependency},
	volume = {132},
	copyright = {Copyright © 2006 Royal Meteorological Society},
	issn = {1477-870X},
	shorttitle = {Influence of the {Madden}–{Julian} {Oscillation} on {East} {African} rainfall. {I}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1256/qj.05.104},
	doi = {10.1256/qj.05.104},
	abstract = {The influence of the Madden–Julian Oscillation (MJO) on rainfall amounts over Equatorial East Africa (Kenya and northern Tanzania) is analysed for the period 1979–95 at the intraseasonal (pentad) time-scale. The two rainy seasons (March to May and October to December) are considered. Intraseasonal wet events in East Africa are embedded in large-scale zonal circulation anomaly patterns along the equator, showing distinct eastward propagation. It is further found that these ‘wet’ events display a clear phasing with respect to the MJO cycle. This phasing is expressed as out-of-phase variations between the Highland and the coastal areas. Such a pattern is suggested to reflect different rain-causing mechanisms. MJO phases leading to wet spells in the western (Highland) region are those associated with the development of large-scale convection in the Africa/Indian Ocean region. These events are unambiguously related to deep convection, fuelled by low-level westerly moisture advection. MJO phases leading to wet spells in the eastern (coastal) region are often those associated with overall suppressed deep convection in the Africa/Indian Ocean region. However, these phases induce moisture advection from Indian Ocean. The possible role of stratiform rainfall or relatively shallow convection in the coastal wet spells observed in this phase is discussed. The contrasting rainfall conditions found in the two regions for the two opposite MJO phases are strongly correlated with the pressure gradient between the Indian and Atlantic Oceans. Copyright © 2006 Royal Meteorological Society},
	language = {en},
	number = {621},
	urldate = {2023-09-13},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Pohl, Benjamin and Camberlin, Pierre},
	year = {2006},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1256/qj.05.104},
	keywords = {Convective rainfall, Long rains, Short rains, Wet spells},
	pages = {2521--2539},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/7KKSQTRX/Pohl and Camberlin - 2006 - Influence of the Madden–Julian Oscillation on East.pdf:application/pdf;Snapshot:/Users/bobbyantonio/Zotero/storage/C473D2M9/qj.05.html:text/html},
}

@article{pohl_influence_2006-1,
	title = {Influence of the {Madden}–{Julian} {Oscillation} on {East} {African} rainfall: {II}. {March}–{May} season extremes and interannual variability},
	volume = {132},
	copyright = {Copyright © 2006 Royal Meteorological Society},
	issn = {1477-870X},
	shorttitle = {Influence of the {Madden}–{Julian} {Oscillation} on {East} {African} rainfall},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1256/qj.05.223},
	doi = {10.1256/qj.05.223},
	abstract = {The Madden–Julian Oscillation (MJO) was shown in Part I to have a significant impact on both East African rainy seasons at pentad time-scale. The case of the ‘long rains’ (March–May) is further examined by considering both shorter (daily) and longer (interannual) time-scales. Based on composite analyses, extreme daily rainfall events in the Highland (west) and in the coastal (east) regions of Equatorial East Africa (Kenya and Tanzania) are extracted. Low-level westerly wind anomalies are seen to accompany wet events in the west and easterly ones in the east. These opposite circulation anomalies preferentially occur at distinct phases of the MJO, which indicates that the latter has a major influence on rainfall at the daily time-scale. However, this influence undergoes significant year-to-year variations. It is found that the common variance between smoothed rainfall time series (5-day low-pass filter) and MJO indices varies from 5\% to 53\% in the Highland region. Significantly lower air temperatures in the upper troposphere are recorded during the MJO cycles that present the highest common variance with East African rainfall. Such a cooling is seen to be related to the Kelvin wave propagation in the upper layers which favours upward atmospheric motion over the region. At the interannual time-scale, fluctuations in MJO amplitude contribute to the March–May rainfall variability, and 44\% of the March–May seasonal rainfall variance in the 1979–95 period in East Africa is explained by this parameter. Years of high MJO amplitude are characterized by earlier onset of the rains, and higher seasonal amounts. Copyright © 2006 Royal Meteorological Society},
	language = {en},
	number = {621},
	urldate = {2023-09-13},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Pohl, Benjamin and Camberlin, Pierre},
	year = {2006},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1256/qj.05.223},
	keywords = {East African long rains, Extreme wet events, Rainfall variability},
	pages = {2541--2558},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/VP24UTGL/Pohl and Camberlin - 2006 - Influence of the Madden–Julian Oscillation on East.pdf:application/pdf;Snapshot:/Users/bobbyantonio/Zotero/storage/B9L6NFQV/qj.05.html:text/html},
}

@article{nicholson_long-term_2015,
	title = {Long-term variability of the {East} {African} ‘short rains’ and its links to large-scale factors},
	volume = {35},
	issn = {1097-0088},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/joc.4259},
	doi = {10.1002/joc.4259},
	abstract = {This study utilizes a new 139-year rainfall record for East Africa to evaluate the relationship between the ‘short rains’ of October–November and four tropical indices. These indices include the zonal winds at the surface and 200 mb over the central equatorial Indian Ocean, Niño 3.4 and the Indian Ocean Zonal Mode (IOZM). The relationships with these indices are time dependent, as are the relationships among the indices. These change markedly on a decadal timescale, consistent with regime changes indicated by other authors, and the links to El Niño-Southern Oscillation (ENSO) and the IOZM appear to be weaker than those suggested by previous studies. The zonal winds show the strongest and most consistent relationships with October–November rainfall. However, the relationships are very different for wet and dry years, and the zonal winds play a stronger role in producing wet conditions. Further, several factors appear to act in tandem to produce extremely wet years, but appear to act largely independently in producing drought. The links to drought have been markedly weaker since 1982. These links were also very weak roughly between 1920 and 1960, when apparently the Walker cell over the Indian Ocean was very weak and the Pacific Walker cell particularly strong. At that time, ENSO appeared to drive most of the variability of October–November rainfall, interannual variability was weak, and the rainfall was below average during most of that period. When the zonal circulation in the Indian Ocean sector became well-developed c. 1961 and the Pacific cell weakened, both the rainfall and its interannual variability markedly increased. Overall, this study stresses the time dependence of the various relationships with East African October–November rainfall. This has strong implications for seasonal forecasting.},
	language = {en},
	number = {13},
	urldate = {2023-09-13},
	journal = {International Journal of Climatology},
	author = {Nicholson, Sharon E.},
	year = {2015},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/joc.4259},
	keywords = {East Africa, rainfall variability, Indian Ocean, African rainfall, ENSO, IOZM, short rains},
	pages = {3979--3990},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/AFRK3TQV/Nicholson - 2015 - Long-term variability of the East African ‘short r.pdf:application/pdf;Snapshot:/Users/bobbyantonio/Zotero/storage/4QDIJ989/joc.html:text/html},
}

@article{macleod_causal_2021,
	title = {Causal pathways linking different flavours of {ENSO} with the {Greater} {Horn} of {Africa} short rains},
	volume = {22},
	copyright = {© 2020 The Authors. Atmospheric Science Letters published by John Wiley \& Sons Ltd on behalf of Royal Meteorological Society.},
	issn = {1530-261X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/asl.1015},
	doi = {10.1002/asl.1015},
	abstract = {There is a strong association between canonical El Niño and a wet Greater Horn of Africa (GHA) short rains. However, the link with Modoki El Niño events appears to be significantly weaker. In order to understand this, we present an analysis of observational data and idealised climate model experiments. Idealised atmospheric simulations isolate the direct influence of Pacific heating on the GHA and reveal that neither the longitudinal position nor the observed weaker magnitude of Modoki Pacific heating anomalies can explain the difference in teleconnections. The direct effect of canonical or Modoki Pacific heating patterns on the GHA is similar and neither reproduces the structure of the full GHA teleconnection: they both generate a wet-dry dipole over the GHA instead of large-scale single-signed wet anomalies. Our results indicate that the strong canonical ENSO influence on GHA is indirect, mediated through its strong relationship with the Indian Ocean Dipole (IOD). By contrast, Modoki ENSO is uncorrelated with the IOD, resulting in weak teleconnection to GHA. Understanding these differences aids seasonal forecast interpretation, whilst their representation in models is likely a prerequisite for making accurate projections of changes in extremes over the GHA and beyond.},
	language = {en},
	number = {2},
	urldate = {2023-09-13},
	journal = {Atmospheric Science Letters},
	author = {MacLeod, David and Graham, Richard and O'Reilly, Chris and Otieno, George and Todd, Martin},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/asl.1015},
	keywords = {ENSO, Greater Horn of Africa, IOD, seasonal forecasting},
	pages = {e1015},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/SFNRJRU5/MacLeod et al. - 2021 - Causal pathways linking different flavours of ENSO.pdf:application/pdf;Snapshot:/Users/bobbyantonio/Zotero/storage/R23U4D3F/asl.html:text/html},
}

@article{pohl_intraseasonal_2011,
	title = {Intraseasonal and interannual zonal circulations over the {Equatorial} {Indian} {Ocean}},
	volume = {104},
	issn = {1434-4483},
	url = {https://doi.org/10.1007/s00704-010-0336-1},
	doi = {10.1007/s00704-010-0336-1},
	abstract = {El Niño Southern Oscillation (ENSO) and given phases of the Madden–Julian Oscillation (MJO) show similar regional signatures over the Equatorial Indian Ocean, consisting in an enhancement or reversing of the convective and dynamic zonal gradients between East Africa and the Maritime Continent of Indonesia. This study analyses how these two modes of variability add or cancel their effects at their respective timescales, through an investigation of the equatorial cellular circulations over the central Indian Ocean. Results show that (1) the wind shear between the lower and upper troposphere is related to marked regional rainfall anomalies and is embedded in larger-scale atmospheric configurations, involving the Southern Oscillation; (2) the intraseasonal (30–60 days) and interannual (4–5 years) timescales are the most energetic frequencies that modulate these circulations, confirming the implication of the MJO and ENSO; (3) extreme values of the Indian Ocean wind shear result from the combination of El Niño and the MJO phase enhancing atmospheric convection over Africa, or La Niña and the MJO phase associated with convective activity over the Maritime Continent. Consequences for regional rainfall anomalies over East Africa and Indonesia are then discussed.},
	language = {en},
	number = {1},
	urldate = {2023-09-13},
	journal = {Theoretical and Applied Climatology},
	author = {Pohl, Benjamin and Camberlin, Pierre},
	month = may,
	year = {2011},
	keywords = {Indian Ocean, Dipole Mode Index, Equatorial Indian Ocean, Outgoing Longwave Radiation, Zonal Wind Anomaly},
	pages = {175--191},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/GIY6PNGE/Pohl and Camberlin - 2011 - Intraseasonal and interannual zonal circulations o.pdf:application/pdf},
}

@article{finney_effect_2020,
	title = {The effect of westerlies on {East} {African} rainfall and the associated role of tropical cyclones and the {Madden}–{Julian} {Oscillation}},
	volume = {146},
	copyright = {© 2019 The Authors. Quarterly Journal of the Royal Meteorological Society published by John Wiley \& Sons Ltd on behalf of the Royal Meteorological Society.},
	issn = {1477-870X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/qj.3698},
	doi = {10.1002/qj.3698},
	abstract = {Variability of rainfall in East Africa has major impacts on lives and livelihoods. From floods to droughts, this variability is important on short daily time-scales to longer decadal time-scales, as is apparent from the devastating effects of droughts in East Africa over recent decades. Past studies have highlighted the Congo airmass in enhancing East African rainfall. Our detailed analysis of the feature shows that days with a westerly moisture flow, bringing the Congo airmass, enhance rainfall by up to 100\% above the daily mean, depending on the time of year. Conversely, there is a suppression of rainfall on days with a strong easterly flow. Days with a westerly moisture flux are in a minority in all seasons but we show that long rains with more westerly days are wetter, and that during the most-recent decade which has had more frequent droughts (associated with the “Eastern African climate paradox”), there has been few days with such westerlies. We also investigate the influence of the Madden–Julian Oscillation (MJO) and tropical cyclones, and their interaction with the westerly flow. We show that days of westerly moisture flux are more likely during phases 3 and 4 of the MJO and when there are one or more tropical cyclones present. In addition, tropical cyclones are more likely to form during these phases of the MJO, and more likely to be coincident with westerlies when forming to the east of Madagascar. Overall, our analysis brings together many different processes that have been discussed in the literature but not yet considered in complete combination. The results demonstrate the importance of the Congo airmass on daily to climate time-scales, and in doing so offers useful angles of investigation for future studies into prediction of East African rainfall.},
	language = {en},
	number = {727},
	urldate = {2023-09-12},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Finney, Declan L. and Marsham, John H. and Walker, Dean P. and Birch, Cathryn E. and Woodhams, Beth J. and Jackson, Lawrence S. and Hardy, Sam},
	year = {2020},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/qj.3698},
	keywords = {East Africa, rainfall, Congo airmass, long rains, Madden–Julian Oscillation, tropical cyclones},
	pages = {647--664},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/8CYFTYIC/Finney et al. - 2020 - The effect of westerlies on East African rainfall .pdf:application/pdf;Snapshot:/Users/bobbyantonio/Zotero/storage/UYBQSHFJ/qj.html:text/html},
}

@article{black_observational_2003,
	title = {An {Observational} {Study} of the {Relationship} between {Excessively} {Strong} {Short} {Rains} in {Coastal} {East} {Africa} and {Indian} {Ocean} {SST}},
	volume = {131},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/131/1/1520-0493_2003_131_0074_aosotr_2.0.co_2.xml},
	doi = {10.1175/1520-0493(2003)131<0074:AOSOTR>2.0.CO;2},
	abstract = {Abstract Composites of SST, wind, rainfall, and humidity have been constructed for years of high rainfall during September, October, and November (SON) in equatorial and southern-central East Africa. These show that extreme East African short rains are associated with large-scale SST anomalies in the Indian Ocean that closely resemble those that develop during Indian Ocean dipole or zonal mode (IOZM) events. This is corroborated by the observation that strong IOZM events produce enhanced East African rainfall. However, it is also shown that the relationship between the IOZM and East African rainfall is nonlinear, with only IOZM events that reverse the zonal SST gradient for several months (extreme events) triggering high rainfall. Comparison of the wind anomalies that develop during extreme IOZM events with those that develop during weaker (moderate) events shows that strong easterly anomalies in the northern-central Indian Ocean are a persistent feature of extreme, but not of moderate, IOZM years. It is suggested that these anomalies weaken the westerly flow that normally transports moisture away from the African continent, out over the Indian Ocean. Thus, during extreme IOZM years, rainfall is enhanced over East Africa and reduced in the central and eastern Indian Ocean basin. It is also shown that the IOZM cannot be viewed in isolation from the El Niño–Southern Oscillation (ENSO). Instead it is postulated that in some years, a strong ENSO forcing can predispose the Indian Ocean coupled system to an IOZM event and is therefore a contributory factor in extreme East African rainfall. The results of this study imply that the relationship between El Niño and the IOZM explains the previously described association between El Niño and high East African rainfall. Thus, understanding the way that ENSO drives Indian Ocean dynamics may aid the development of predictive scenarios for East African climate that could have significant economic implications.},
	language = {EN},
	number = {1},
	urldate = {2023-09-12},
	journal = {Monthly Weather Review},
	author = {Black, Emily and Slingo, Julia and Sperber, Kenneth R.},
	month = jan,
	year = {2003},
	note = {Publisher: American Meteorological Society
Section: Monthly Weather Review},
	pages = {74--94},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/XXAH8JJ5/Black et al. - 2003 - An Observational Study of the Relationship between.pdf:application/pdf},
}

@article{pinson_discrimination_nodate,
	title = {Discrimination ability of the {Energy} score},
	abstract = {Research on generating and veriﬁcation of multivariate probabilistic forecasts has gained increased interest over the last few years. Emphasis is placed here on the evaluation of forecast quality with the Energy score, which is based on a quadratic scoring rule. While this score may be seen as appealing since being proper, we show that its discrimination ability may be limited when focusing on the dependence structure of multivariate probabilistic forecasts. For the case of multivariate Gaussian process, a theoretical upper for such discrimination ability is derived and discussed. This limited discrimination ability may eventually get compromised by computational and sampling issues, as dimension increases.},
	language = {en},
	author = {Pinson, Pierre and Tastu, Julija},
	file = {Pinson and Tastu - Discrimination ability of the Energy score.pdf:/Users/bobbyantonio/Zotero/storage/R545RGRB/Pinson and Tastu - Discrimination ability of the Energy score.pdf:application/pdf},
}

@article{scheuerer_variogram-based_2015-1,
	title = {Variogram-{Based} {Proper} {Scoring} {Rules} for {Probabilistic} {Forecasts} of {Multivariate} {Quantities}},
	volume = {143},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/143/4/mwr-d-14-00269.1.xml},
	doi = {10.1175/MWR-D-14-00269.1},
	abstract = {Abstract Proper scoring rules provide a theoretically principled framework for the quantitative assessment of the predictive performance of probabilistic forecasts. While a wide selection of such scoring rules for univariate quantities exists, there are only few scoring rules for multivariate quantities, and many of them require that forecasts are given in the form of a probability density function. The energy score, a multivariate generalization of the continuous ranked probability score, is the only commonly used score that is applicable in the important case of ensemble forecasts, where the multivariate predictive distribution is represented by a finite sample. Unfortunately, its ability to detect incorrectly specified correlations between the components of the multivariate quantity is somewhat limited. In this paper the authors present an alternative class of proper scoring rules based on the geostatistical concept of variograms. The sensitivity of these variogram-based scoring rules to incorrectly predicted means, variances, and correlations is studied in a number of examples with simulated observations and forecasts; they are shown to be distinctly more discriminative with respect to the correlation structure. This conclusion is confirmed in a case study with postprocessed wind speed forecasts at five wind park locations in Colorado.},
	language = {EN},
	number = {4},
	urldate = {2023-09-11},
	journal = {Monthly Weather Review},
	author = {Scheuerer, Michael and Hamill, Thomas M.},
	month = apr,
	year = {2015},
	note = {Publisher: American Meteorological Society
Section: Monthly Weather Review},
	pages = {1321--1334},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/J5LAGMIJ/Scheuerer and Hamill - 2015 - Variogram-Based Proper Scoring Rules for Probabili.pdf:application/pdf},
}

@misc{ecmwf_operational_2023,
	title = {Operational configurations of the {ECMWF} {Integrated} {Forecasting} {System} ({IFS})},
	url = {https://confluence.ecmwf.int/pages/viewpage.action?pageId=324860211},
	urldate = {2023-01-09},
	journal = {Operational configurations of the ECMWF Integrated Forecasting System (IFS)},
	author = {{ECMWF}},
	month = feb,
	year = {2023},
	note = {https://confluence.ecmwf.int/pages/viewpage.action?pageId=324860211. Accessed 1st September},
}

@misc{ben-bouallegue_improving_2023,
	title = {Improving medium-range ensemble weather forecasts with hierarchical ensemble transformers},
	url = {http://arxiv.org/abs/2303.17195},
	doi = {10.48550/arXiv.2303.17195},
	abstract = {Statistical post-processing of global ensemble weather forecasts is revisited by leveraging recent developments in machine learning. Verification of past forecasts is exploited to learn systematic deficiencies of numerical weather predictions in order to boost post-processed forecast performance. Here, we introduce PoET, a post-processing approach based on hierarchical transformers. PoET has 2 major characteristics: 1) the post-processing is applied directly to the ensemble members rather than to a predictive distribution or a functional of it, and 2) the method is ensemble-size agnostic in the sense that the number of ensemble members in training and inference mode can differ. The PoET output is a set of calibrated members that has the same size as the original ensemble but with improved reliability. Performance assessments show that PoET can bring up to 20\% improvement in skill globally for 2m temperature and 2\% for precipitation forecasts and outperforms the simpler statistical member-by-member method, used here as a competitive benchmark. PoET is also applied to the ENS10 benchmark dataset for ensemble post-processing and provides better results when compared to other deep learning solutions that are evaluated for most parameters. Furthermore, because each ensemble member is calibrated separately, downstream applications should directly benefit from the improvement made on the ensemble forecast with post-processing.},
	urldate = {2023-08-30},
	publisher = {arXiv},
	author = {Ben-Bouallegue, Zied and Weyn, Jonathan A. and Clare, Mariana C. A. and Dramsch, Jesper and Dueben, Peter and Chantry, Matthew},
	month = aug,
	year = {2023},
	note = {arXiv:2303.17195},
	keywords = {Physics - Atmospheric and Oceanic Physics},
	file = {arXiv Fulltext PDF:/Users/bobbyantonio/Zotero/storage/3ZAXZ9C8/Ben-Bouallegue et al. - 2023 - Improving medium-range ensemble weather forecasts .pdf:application/pdf;arXiv.org Snapshot:/Users/bobbyantonio/Zotero/storage/N5R48ZHI/2303.html:text/html},
}

@misc{floodlist_somalia_2023,
	title = {Somalia – {Flooding} {Displaces} {Thousands}, {Prompts} {Urgent} {Humanitarian} {Response}},
	url = {https://floodlist.com/africa/somalia-floods-may-2023},
	urldate = {2023-08-04},
	author = {Floodlist},
	month = may,
	year = {2023},
	note = {https://floodlist.com/africa/somalia-floods-may-2023. Accessed May 2023.},
}

@article{dinku_validation_2007,
	title = {Validation of satellite rainfall products over {East} {Africa}'s complex topography},
	volume = {28},
	issn = {0143-1161},
	url = {https://doi.org/10.1080/01431160600954688},
	doi = {10.1080/01431160600954688},
	abstract = {An extensive evaluation of 10 different satellite rainfall products was performed using station network over a complex topography, where elevation varies from below sea level to 4620 m. Evaluation was for two groups of products. The first group had low spatial (2.5°) and temporal (monthly) resolution and included the Global Precipitation Climatology Project (GPCP), the National Oceanographic and Atmospheric Administration Climate Prediction Center (NOAA‐CPC) merged analysis (CMAP), and the Tropical Rainfall Measuring Mission (TRMM‐3B43). The second group comprised products with relatively high spatial (0.1° to 1°) and temporal (3‐hourly to 10‐daily) resolution. These included the NOAA‐CPC African rainfall estimation algorithm, GPCP one‐degree‐daily (1DD), TRMM‐3B42, Tropical Applications of Meteorology using SATellite and other data (TAMSAT) estimates, and the CPC morphing technique (CMORPH). These products were aggregated to a 10‐day total and remapped to spatial resolutions of 1°, 0.5° and 0.25°. TRMM‐3B43 and CMAP from the first group and CMORPH, TAMSAT and TRMM‐3B42 from the second group performed reasonably well.},
	number = {7},
	urldate = {2023-09-06},
	journal = {International Journal of Remote Sensing},
	author = {Dinku, T. and Ceccato, P. and Grover‐Kopec, E. and Lemma, M. and Connor, S. J. and Ropelewski, C. F.},
	month = apr,
	year = {2007},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/01431160600954688},
	pages = {1503--1526},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/HUZLMM9M/Dinku et al. - 2007 - Validation of satellite rainfall products over Eas.pdf:application/pdf},
}

@techreport{finney_scientific_2019,
	title = {Scientific {Understanding} of {East} {African} climate change from the {HyCRISTAL} project},
	url = {http://eprints.whiterose.ac.uk/151635/},
	abstract = {Integrating Hydro-Climate Science into Policy Decisions for Climate-Resilient Infrastructure and Livelihoods in East Africa (HyCRISTAL) is a Future Climate for Africa (FCFA) project funded to deliver new understanding of East African climate change and its impacts, and to demonstrate use of climate change information in long-term decision-making in the region. Here, we briefly summarise key findings from HyCRISTAL so far on climate change, as well as key findings from the pan-African FCFA project “IMPALA” relevant to East Africa, both in the context of previous literature on the topic.},
	urldate = {2023-08-01},
	institution = {University of Leeds},
	author = {Finney, D and Marsham, J and Rowell, D and Way, C and Evans, B and Cornforth, R and Houghton-Carr, H and Mittal, N and Allan, R and Anande, D and Anyah, R and Ascott, M and Black, E and Boorman, P and Booth, B and Bornemann, J and Burgin, L and Evans, J and Gudoshava, M and Kendon, E and Kisembe, J and Kondowe, A and Lapworth, D and Lopez-Gonzalez, G and Lwiza, K and Macdonald, D and Maidment, R and Misiani, H and Nakabugo, R and Sabiiti, G and Sangalugembe, C and Scanell, C and Segele, Z and Semazzi, F and Smith, K and Tadege, A and Tesfaye, K and Waniha, P and Wainwright, C and Wilby, R and Winterbourn, B and Xia, S},
	year = {2019},
	doi = {10.5518/100/19},
	file = {D Finney et al. - 2019 - Scientific Understanding of East African climate c.pdf:/Users/bobbyantonio/Zotero/storage/WQIJ2I2B/D Finney et al. - 2019 - Scientific Understanding of East African climate c.pdf:application/pdf},
}

@article{dezfuli_precipitation_2017,
	title = {Precipitation {Characteristics} in {West} and {East} {Africa} from {Satellite} and in {Situ} {Observations}},
	volume = {18},
	issn = {1525-7541, 1525-755X},
	url = {https://journals.ametsoc.org/view/journals/hydr/18/6/jhm-d-17-0068_1.xml},
	doi = {10.1175/JHM-D-17-0068.1},
	abstract = {Abstract Using in situ data, three precipitation classes are identified for rainy seasons of West and East Africa: weak convective rainfall (WCR), strong convective rainfall (SCR), and mesoscale convective systems (MCSs). Nearly 75\% of the total seasonal precipitation is produced by the SCR and MCSs, even though they represent only 8\% of the rain events. Rain events in East Africa tend to have a longer duration and lower intensity than in West Africa, reflecting different characteristics of the SCR and MCS events in these two regions. Surface heating seems to be the primary convection trigger for the SCR, particularly in East Africa, whereas the WCR requires a dynamical trigger such as low-level convergence. The data are used to evaluate the performance of the recently launched Integrated Multisatellite Retrievals for Global Precipitation Measurement (IMERG) project. The IMERG-based precipitation shows significant improvement over its predecessor, the Tropical Rainfall Measuring Mission (TRMM) Multisatellite Precipitation Analysis (TMPA), particularly in capturing the MCSs, due to its improved temporal resolution.},
	language = {EN},
	number = {6},
	urldate = {2023-09-04},
	journal = {Journal of Hydrometeorology},
	author = {Dezfuli, Amin K. and Ichoku, Charles M. and Mohr, Karen I. and Huffman, George J.},
	month = jun,
	year = {2017},
	note = {Publisher: American Meteorological Society
Section: Journal of Hydrometeorology},
	pages = {1799--1805},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/S7J8RI3Q/Dezfuli et al. - 2017 - Precipitation Characteristics in West and East Afr.pdf:application/pdf},
}

@article{kendon_enhanced_2019,
	title = {Enhanced future changes in wet and dry extremes over {Africa} at convection-permitting scale},
	volume = {10},
	copyright = {2019 Crown},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-019-09776-9},
	doi = {10.1038/s41467-019-09776-9},
	abstract = {African society is particularly vulnerable to climate change. The representation of convection in climate models has so far restricted our ability to accurately simulate African weather extremes, limiting climate change predictions. Here we show results from climate change experiments with a convection-permitting (4.5 km grid-spacing) model, for the first time over an Africa-wide domain (CP4A). The model realistically captures hourly rainfall characteristics, unlike coarser resolution models. CP4A shows greater future increases in extreme 3-hourly precipitation compared to a convection-parameterised 25 km model (R25). CP4A also shows future increases in dry spell length during the wet season over western and central Africa, weaker or not apparent in R25. These differences relate to the more realistic representation of convection in CP4A, and its response to increasing atmospheric moisture and stability. We conclude that, with the more accurate representation of convection, projected changes in both wet and dry extremes over Africa may be more severe.},
	language = {en},
	number = {1},
	urldate = {2023-09-04},
	journal = {Nature Communications},
	author = {Kendon, Elizabeth J. and Stratton, Rachel A. and Tucker, Simon and Marsham, John H. and Berthou, Ségolène and Rowell, David P. and Senior, Catherine A.},
	month = apr,
	year = {2019},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Hydrology, Climate and Earth system modelling, Projection and prediction},
	pages = {1794},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/HPQ8V5LA/Kendon et al. - 2019 - Enhanced future changes in wet and dry extremes ov.pdf:application/pdf},
}

@misc{keisler_forecasting_2022,
	title = {Forecasting {Global} {Weather} with {Graph} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2202.07575},
	doi = {10.48550/arXiv.2202.07575},
	abstract = {We present a data-driven approach for forecasting global weather using graph neural networks. The system learns to step forward the current 3D atmospheric state by six hours, and multiple steps are chained together to produce skillful forecasts going out several days into the future. The underlying model is trained on reanalysis data from ERA5 or forecast data from GFS. Test performance on metrics such as Z500 (geopotential height) and T850 (temperature) improves upon previous data-driven approaches and is comparable to operational, full-resolution, physical models from GFS and ECMWF, at least when evaluated on 1-degree scales and when using reanalysis initial conditions. We also show results from connecting this data-driven model to live, operational forecasts from GFS.},
	urldate = {2023-09-04},
	publisher = {arXiv},
	author = {Keisler, Ryan},
	month = feb,
	year = {2022},
	note = {arXiv:2202.07575 [physics]},
	keywords = {Computer Science - Machine Learning, Physics - Atmospheric and Oceanic Physics},
	file = {arXiv Fulltext PDF:/Users/bobbyantonio/Zotero/storage/GML6B3XA/Keisler - 2022 - Forecasting Global Weather with Graph Neural Netwo.pdf:application/pdf;arXiv.org Snapshot:/Users/bobbyantonio/Zotero/storage/BLEIUEGB/2202.html:text/html},
}

@misc{yang_improving_2023-1,
	title = {Improving {Seasonal} {Forecast} of {Summer} {Precipitation} in {Southeastern} {China} using {CycleGAN} {Deep} {Learning} {Bias} {Correction}},
	url = {https://essopenarchive.org/users/655873/articles/661468-improving-seasonal-forecast-of-summer-precipitation-in-southeastern-china-using-cyclegan-deep-learning-bias-correction?commit=6fe5aad26bce582dd78270aa8ad3b99a0acc0f37},
	abstract = {Accurate seasonal precipitation forecasts, especially for extreme events, are crucial to preventing meteorological hazards and its potential impacts on national development, social stability, and security. However, the intensity of summer precipitation is often signiﬁcantly underestimated in many current dynamical models. This study uses a deep learning method called CycleConsistent Generative Adversarial Networks (CycleGAN) to enhance the seasonal forecast skill of the Nanjing University of Information Science \& Technology Climate Forecast System (NUIST-CFS1.0) in predicting June-July-August precipitation in southeastern China. The results suggest that the CycleGAN-based model signiﬁcantly improves the accuracy in predicting the spatial-temporal distribution of summer precipitation than traditional quantile mapping (QM) method. Due to the use of unpaired day-to-day correction models, we can pay more attention to the frequency, intensity, and duration of extreme precipitation events in the climate dynamical model forecast. This study expands the potential applications of deep learning models to improving seasonal precipitation forecasts.},
	urldate = {2023-09-04},
	author = {Yang, Song and Ling, Fenghua and Bai, Lei and Luo, Jing-Jia},
	month = aug,
	year = {2023},
	note = {ESS Open Archive},
	file = {Yang et al. - 2023 - Improving Seasonal Forecast of Summer Precipitatio.pdf:/Users/bobbyantonio/Zotero/storage/Z2M9EMCV/Yang et al. - 2023 - Improving Seasonal Forecast of Summer Precipitatio.pdf:application/pdf},
}

@techreport{wilkinson_forecasting_2018,
	title = {Forecasting hazards, averting disasters: implementing forecast-based early action at scale},
	shorttitle = {Forecasting hazards, averting disasters},
	abstract = {This report examines current pilots in the emerging forecast-based early action programming and finance and offers suggestions for scale.},
	language = {en-gb},
	urldate = {2023-08-04},
	institution = {Overseas Development Institute},
	author = {Wilkinson, Emily and Weingärtner, Lena and Choularton, Richard and Bailey, Meghan and Todd, Martin and Kniveton, Dominic and Cabot Venton, Courtenay},
	month = mar,
	year = {2018},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/C3P9PGGR/Wilkinson and Nur - 2018 - Forecasting hazards, averting disasters implement.pdf:application/pdf},
}

@incollection{wilcox_chapter_2022,
	title = {Chapter 3 - {Estimating} {Measures} of {Location} and {Scale}},
	isbn = {978-0-12-820098-8},
	url = {https://www.sciencedirect.com/science/article/pii/B9780128200988000099},
	abstract = {Chapter 3 describes how to estimate the measures of location and scatter that were introduced in Chapter 2. Some related estimators are described and their relative merits are summarized. Included is a summary of some methods for estimating distributions, including kernel density estimators, which have practical value for reasons illustrated in subsequent chapters. Strategies for detecting outliers are introduced. Practical concerns about detecting outliers via the mean and variance are described and illustrated. Theoretically sound methods for estimating the standard errors of robust estimators are described, which are not intuitive based on standard training in an applied statistics course. R functions for estimating robust measures of location, and their standard errors, are described and illustrated.},
	booktitle = {Introduction to {Robust} {Estimation} and {Hypothesis} {Testing} ({Fifth} {Edition})},
	publisher = {Academic Press},
	author = {Wilcox, Rand R.},
	editor = {Wilcox, Rand R.},
	year = {2022},
	doi = {https://doi.org/10.1016/B978-0-12-820098-8.00009-9},
	keywords = {Bootstrap methods, Density estimators, Finite breakdown point, M-estimators, Outlier detection methods, Quantile estimators, Robust measures of scatter, Skipped estimators, Trimmed means, Winsorization},
	pages = {45--106},
}

@misc{stanczuk_wasserstein_2021,
	title = {Wasserstein {GANs} {Work} {Because} {They} {Fail} (to {Approximate} the {Wasserstein} {Distance})},
	url = {http://arxiv.org/abs/2103.01678},
	doi = {10.48550/arXiv.2103.01678},
	abstract = {Wasserstein GANs are based on the idea of minimising the Wasserstein distance between a real and a generated distribution. We provide an in-depth mathematical analysis of differences between the theoretical setup and the reality of training Wasserstein GANs. In this work, we gather both theoretical and empirical evidence that the WGAN loss is not a meaningful approximation of the Wasserstein distance. Moreover, we argue that the Wasserstein distance is not even a desirable loss function for deep generative models, and conclude that the success of Wasserstein GANs can in truth be attributed to a failure to approximate the Wasserstein distance.},
	urldate = {2023-07-06},
	publisher = {arXiv},
	author = {Stanczuk, Jan and Etmann, Christian and Kreusser, Lisa Maria and Schönlieb, Carola-Bibiane},
	month = oct,
	year = {2021},
	note = {arXiv:2103.01678},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/bobbyantonio/Zotero/storage/67U8KWCD/Stanczuk et al. - 2021 - Wasserstein GANs Work Because They Fail (to Approx.pdf:application/pdf;arXiv.org Snapshot:/Users/bobbyantonio/Zotero/storage/YRW9MU3G/2103.html:text/html},
}

@misc{reynolds_wgne_2018,
	title = {{WGNE} {Systematic} {Error} {Survey} {Results} {Summary}, 5th {WGNE} workshop on systematic errors in weather and climate models},
	shorttitle = {Systematic {Errors} in {Weather} and {Climate} {Models}},
	url = {https://journals.ametsoc.org/view/journals/bams/99/4/bams-d-17-0287.1.xml},
	language = {en},
	urldate = {2023-08-04},
	author = {Reynolds, Carolyn and Williams, Keith and Zadra, Ayrton},
	month = apr,
	year = {2018},
	file = {Zadra et al. - 2018 - Systematic Errors in Weather and Climate Models N.pdf:/Users/bobbyantonio/Zotero/storage/PS35REIE/Zadra et al. - 2018 - Systematic Errors in Weather and Climate Models N.pdf:application/pdf},
}

@misc{mirza_conditional_2014,
	title = {Conditional {Generative} {Adversarial} {Nets}},
	url = {http://arxiv.org/abs/1411.1784},
	abstract = {Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of generative adversarial nets, which can be constructed by simply feeding the data, y, we wish to condition on to both the generator and discriminator. We show that this model can generate MNIST digits conditioned on class labels. We also illustrate how this model could be used to learn a multi-modal model, and provide preliminary examples of an application to image tagging in which we demonstrate how this approach can generate descriptive tags which are not part of training labels.},
	author = {Mirza, Mehdi and Osindero, Simon},
	month = nov,
	year = {2014},
	note = {arXiv: 1411.1784},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/HEVAI564/1411.1784.pdf:application/pdf},
}

@misc{li_seeds_2023,
	title = {{SEEDS}: {Emulation} of {Weather} {Forecast} {Ensembles} with {Diffusion} {Models}},
	shorttitle = {{SEEDS}},
	url = {http://arxiv.org/abs/2306.14066},
	doi = {10.48550/arXiv.2306.14066},
	abstract = {Probabilistic forecasting is crucial to decision-making under uncertainty about future weather. The dominant approach is to use an ensemble of forecasts to represent and quantify uncertainty in operational numerical weather prediction. However, generating ensembles is computationally costly. In this paper, we propose to generate ensemble forecasts at scale by leveraging recent advances in generative artificial intelligence. Our approach learns a data-driven probabilistic diffusion model from the 5-member ensemble GEFS reforecast dataset. The model can then be sampled efficiently to produce realistic weather forecasts, conditioned on a few members of the operational GEFS forecasting system. The generated ensembles have similar predictive skill as the full GEFS 31-member ensemble, evaluated against ERA5 reanalysis, and emulate well the statistics of large physics-based ensembles. We also apply the same methodology to developing a diffusion model for generative post-processing: the model directly learns to correct biases present in the emulated forecasting system by leveraging reanalysis data as labels during training. Ensembles from this generative post-processing model show greater reliability and accuracy, particularly in extreme event classification. In general, they are more reliable and forecast the probability of extreme weather more accurately than the GEFS operational ensemble. Our models achieve these results at less than 1/10th of the computational cost incurred by the operational GEFS system.},
	urldate = {2023-06-30},
	publisher = {arXiv},
	author = {Li, Lizao and Carver, Rob and Lopez-Gomez, Ignacio and Sha, Fei and Anderson, John},
	month = jun,
	year = {2023},
	note = {arXiv:2306.14066},
	keywords = {Computer Science - Machine Learning, Physics - Atmospheric and Oceanic Physics},
	file = {arXiv Fulltext PDF:/Users/bobbyantonio/Zotero/storage/NJQ7AC36/Li et al. - 2023 - SEEDS Emulation of Weather Forecast Ensembles wit.pdf:application/pdf;arXiv.org Snapshot:/Users/bobbyantonio/Zotero/storage/TFVUQ2HI/2306.html:text/html},
}

@misc{horat_deep_2023,
	title = {Deep learning for post-processing global probabilistic forecasts on sub-seasonal time scales},
	url = {http://arxiv.org/abs/2306.15956},
	doi = {10.48550/arXiv.2306.15956},
	abstract = {Sub-seasonal weather forecasts are becoming increasingly important for a range of socio-economic activities. However, the predictive ability of physical weather models is very limited on these time scales. We propose several post-processing methods based on convolutional neural networks to improve sub-seasonal forecasts by correcting systematic errors of numerical weather prediction models. Our post-processing models operate directly on spatial input fields and are therefore able to retain spatial relationships and to generate spatially homogeneous predictions. They produce global probabilistic tercile forecasts for biweekly aggregates of temperature and precipitation for weeks 3-4 and 5-6. In a case study based on a public forecasting challenge organized by the World Meteorological Organization, our post-processing models outperform recalibrated forecasts from the European Centre for Medium-Range Weather Forecasts (ECMWF), and achieve improvements over climatological forecasts for all considered variables and lead times. We compare several model architectures and training modes and demonstrate that all approaches lead to skillful and well-calibrated probabilistic forecasts. The good calibration of the post-processed forecasts emphasizes that our post-processing models reliably quantify the forecast uncertainty based on deterministic input information in form of the ECMWF ensemble mean forecast fields only.},
	urldate = {2023-09-01},
	publisher = {arXiv},
	author = {Horat, Nina and Lerch, Sebastian},
	month = jun,
	year = {2023},
	note = {arXiv:2306.15956},
	keywords = {Physics - Atmospheric and Oceanic Physics},
	file = {arXiv Fulltext PDF:/Users/bobbyantonio/Zotero/storage/K6J9PX7T/Horat and Lerch - 2023 - Deep learning for post-processing global probabili.pdf:application/pdf;arXiv.org Snapshot:/Users/bobbyantonio/Zotero/storage/PYVKZ62Q/2306.html:text/html},
}

@misc{dziugaite_training_2015,
	title = {Training generative neural networks via {Maximum} {Mean} {Discrepancy} optimization},
	url = {http://arxiv.org/abs/1505.03906},
	abstract = {We consider training a deep neural network to generate samples from an unknown distribution given i.i.d. data. We frame learning as an optimization minimizing a two-sample test statistic---informally speaking, a good generator network produces samples that cause a two-sample test to fail to reject the null hypothesis. As our two-sample test statistic, we use an unbiased estimate of the maximum mean discrepancy, which is the centerpiece of the nonparametric kernel two-sample test proposed by Gretton et al. (2012). We compare to the adversarial nets framework introduced by Goodfellow et al. (2014), in which learning is a two-player game between a generator network and an adversarial discriminator network, both trained to outwit the other. From this perspective, the MMD statistic plays the role of the discriminator. In addition to empirical comparisons, we prove bounds on the generalization error incurred by optimizing the empirical MMD.},
	urldate = {2023-07-20},
	publisher = {arXiv},
	author = {Dziugaite, Gintare Karolina and Roy, Daniel M. and Ghahramani, Zoubin},
	month = may,
	year = {2015},
	note = {arXiv:1505.03906},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 10 pages, to appear in Uncertainty in Artificial Intelligence (UAI) 2015},
	file = {arXiv.org Snapshot:/Users/bobbyantonio/Zotero/storage/4LS76IXL/1505.html:text/html;Full Text PDF:/Users/bobbyantonio/Zotero/storage/9Q6JIUHB/Dziugaite et al. - 2015 - Training generative neural networks via Maximum Me.pdf:application/pdf},
}

@misc{duncan_generative_2022,
	title = {Generative {Modeling} of {High}-resolution {Global} {Precipitation} {Forecasts}},
	abstract = {Forecasting global precipitation patterns and, in particular, extreme precipitation events is of critical importance to preparing for and adapting to climate change. Making accurate high-resolution precipitation forecasts using traditional physical models remains a major challenge in operational weather forecasting as they incur substantial computational costs and struggle to achieve sufficient forecast skill. Recently, deep-learning-based models have shown great promise in closing the gap with numerical weather prediction (NWP) models in terms of precipitation forecast skill, opening up exciting new avenues for precipitation modeling. However, it is challenging for these deep learning models to fully resolve the fine-scale structures of precipitation phenomena and adequately characterize the extremes of the long-tailed precipitation distribution. In this work, we present several improvements to the architecture and training process of a current state-of-the art deep learning precipitation model (FourCastNet) using a novel generative adversarial network (GAN) to better capture fine scales and extremes. Our improvements achieve superior performance in capturing the extreme percentiles of global precipitation, while comparable to state-of-the-art NWP models in terms of forecast skill at 1-2 day lead times. Together, these improvements set a new state-of-the-art in global precipitation forecasting.},
	author = {Duncan, James and Subramanian, Shashank and Harrington, Peter},
	year = {2022},
	note = {arXiv:2210.12504},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/RG5Z7X3H/gen_modelling_highres_precip.pdf:application/pdf},
}

@misc{bi_pangu-weather_2022,
	title = {Pangu-{Weather}: {A} {3D} {High}-{Resolution} {Model} for {Fast} and {Accurate} {Global} {Weather} {Forecast}},
	url = {http://arxiv.org/abs/2211.02556},
	abstract = {In this paper, we present Pangu-Weather, a deep learning based system for fast and accurate global weather forecast. For this purpose, we establish a data-driven environment by downloading \$43\$ years of hourly global weather data from the 5th generation of ECMWF reanalysis (ERA5) data and train a few deep neural networks with about \$256\$ million parameters in total. The spatial resolution of forecast is \$0.25{\textasciicircum}{\textbackslash}circ{\textbackslash}times0.25{\textasciicircum}{\textbackslash}circ\$, comparable to the ECMWF Integrated Forecast Systems (IFS). More importantly, for the first time, an AI-based method outperforms state-of-the-art numerical weather prediction (NWP) methods in terms of accuracy (latitude-weighted RMSE and ACC) of all factors (e.g., geopotential, specific humidity, wind speed, temperature, etc.) and in all time ranges (from one hour to one week). There are two key strategies to improve the prediction accuracy: (i) designing a 3D Earth Specific Transformer (3DEST) architecture that formulates the height (pressure level) information into cubic data, and (ii) applying a hierarchical temporal aggregation algorithm to alleviate cumulative forecast errors. In deterministic forecast, Pangu-Weather shows great advantages for short to medium-range forecast (i.e., forecast time ranges from one hour to one week). Pangu-Weather supports a wide range of downstream forecast scenarios, including extreme weather forecast (e.g., tropical cyclone tracking) and large-member ensemble forecast in real-time. Pangu-Weather not only ends the debate on whether AI-based methods can surpass conventional NWP methods, but also reveals novel directions for improving deep learning weather forecast systems.},
	author = {Bi, Kaifeng and Xie, Lingxi and Zhang, Hengheng and Chen, Xin and Gu, Xiaotao and Tian, Qi},
	month = nov,
	year = {2022},
	note = {arXiv: 2211.02556},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/3USUS5XI/2211.02556v1.pdf:application/pdf},
}

@inproceedings{arjovsky_towards_2016,
	title = {Towards {Principled} {Methods} for {Training} {Generative} {Adversarial} {Networks}},
	url = {https://openreview.net/forum?id=Hk4_qw5xe},
	abstract = {The goal of this paper is not to introduce a single algorithm or method, but to make theoretical steps towards fully understanding the training dynamics of gen- erative adversarial networks. In order to substantiate our theoretical analysis, we perform targeted experiments to verify our assumptions, illustrate our claims, and quantify the phenomena. This paper is divided into three sections. The first sec- tion introduces the problem at hand. The second section is dedicated to studying and proving rigorously the problems including instability and saturation that arize when training generative adversarial networks. The third section examines a prac- tical and theoretically grounded direction towards solving these problems, while introducing new tools to study them.},
	language = {en},
	urldate = {2023-07-05},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Learning} {Representations}},
	author = {Arjovsky, Martin and Bottou, Leon},
	month = nov,
	year = {2016},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/WHY6PYIH/Arjovsky and Bottou - 2016 - Towards Principled Methods for Training Generative.pdf:application/pdf},
}

@techreport{ifrc_world_2014,
	title = {World {Disasters} {Report}, {Focus} on culture and risk},
	url = {https://www.ifrc.org/document/world-disasters-report-2014},
	language = {en},
	urldate = {2023-07-27},
	institution = {International Federation of Red Cross and Red Crescent Societies},
	author = {IFRC},
	year = {2014},
	file = {Snapshot:/Users/bobbyantonio/Zotero/storage/BAE5UDAQ/world-disasters-report-2014.html:text/html},
}

@article{palmer_drivers_2023,
	title = {Drivers and impacts of {Eastern} {African} rainfall variability},
	volume = {4},
	copyright = {2023 Springer Nature Limited},
	issn = {2662-138X},
	url = {https://www.nature.com/articles/s43017-023-00397-x},
	doi = {10.1038/s43017-023-00397-x},
	abstract = {Eastern Africa exhibits bimodal rainfall consisting of long rains (March–May) and short rains (October–December), changes in which have profound socioeconomic and environmental impacts. In this Review, we examine the drivers and corresponding impacts of Eastern African rainfall variability. Remote teleconnections, namely the El Niño–Southern Oscillation and the Indian Ocean Dipole, exert a dominant influence on interannual variability. From the mid-1980s to 2010, the long rains have tended toward a drier state (trends of −0.65 to −2.95 mm season−1 year−1), with some recovery thereafter, while the short rains have become wetter since the mid 1980s (1.44 to 2.36 mm season−1 year−1). These trends, overlain by substantial year-to-year variations, affect the severity and frequency of extreme flooding and droughts, the stability of food and energy systems, the susceptibility to water-borne and vector-borne diseases, and ecosystem stability. Climate model projections of rainfall changes differ, but there is some consensus that the short rains will deliver more rainfall than the long rains by 2030–2040, with implications for sustaining agricultural yields and triggering climate-related public health emergencies. Mitigating the impacts of future Eastern African climate requires continued investments in agriculture, clean water, medical and emergency infrastructures, and development and adoption of adaptation strategies, as well as targeted early-warning systems driven by improved meteorological observations.},
	language = {en},
	number = {4},
	urldate = {2023-09-01},
	journal = {Nature Reviews Earth \& Environment},
	author = {Palmer, Paul I. and Wainwright, Caroline M. and Dong, Bo and Maidment, Ross I. and Wheeler, Kevin G. and Gedney, Nicola and Hickman, Jonathan E. and Madani, Nima and Folwell, Sonja S. and Abdo, Gamal and Allan, Richard P. and Black, Emily C. L. and Feng, Liang and Gudoshava, Masilin and Haines, Keith and Huntingford, Chris and Kilavi, Mary and Lunt, Mark F. and Shaaban, Ahmed and Turner, Andrew G.},
	month = apr,
	year = {2023},
	note = {Number: 4
Publisher: Nature Publishing Group},
	keywords = {Climate and Earth system modelling, Atmospheric dynamics, Carbon cycle, Climate-change impacts},
	pages = {254--270},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/73G89CZE/Palmer et al. - 2023 - Drivers and impacts of Eastern African rainfall va.pdf:application/pdf},
}

@article{hamill_interpretation_2001,
	title = {Interpretation of {Rank} {Histograms} for {Verifying} {Ensemble} {Forecasts}},
	volume = {129},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/129/3/1520-0493_2001_129_0550_iorhfv_2.0.co_2.xml},
	doi = {10.1175/1520-0493(2001)129<0550:IORHFV>2.0.CO;2},
	abstract = {Abstract Rank histograms are a tool for evaluating ensemble forecasts. They are useful for determining the reliability of ensemble forecasts and for diagnosing errors in its mean and spread. Rank histograms are generated by repeatedly tallying the rank of the verification (usually an observation) relative to values from an ensemble sorted from lowest to highest. However, an uncritical use of the rank histogram can lead to misinterpretations of the qualities of that ensemble. For example, a flat rank histogram, usually taken as a sign of reliability, can still be generated from unreliable ensembles. Similarly, a U-shaped rank histogram, commonly understood as indicating a lack of variability in the ensemble, can also be a sign of conditional bias. It is also shown that flat rank histograms can be generated for some model variables if the variance of the ensemble is correctly specified, yet if covariances between model grid points are improperly specified, rank histograms for combinations of model variables may not be flat. Further, if imperfect observations are used for verification, the observational errors should be accounted for, otherwise the shape of the rank histogram may mislead the user about the characteristics of the ensemble. If a statistical hypothesis test is to be performed to determine whether the differences from uniformity of rank are statistically significant, then samples used to populate the rank histogram must be located far enough away from each other in time and space to be considered independent.},
	language = {EN},
	number = {3},
	urldate = {2023-09-01},
	journal = {Monthly Weather Review},
	author = {Hamill, Thomas M.},
	month = mar,
	year = {2001},
	note = {Publisher: American Meteorological Society
Section: Monthly Weather Review},
	pages = {550--560},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/IQRCQX5E/Hamill - 2001 - Interpretation of Rank Histograms for Verifying En.pdf:application/pdf},
}

@article{woodcock_evaluation_1976,
	title = {The {Evaluation} of {Yes}/{No} {Forecasts} for {Scientific} and {Administrative} {Purposes}},
	volume = {104},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/104/10/1520-0493_1976_104_1209_teoyff_2_0_co_2.xml},
	doi = {10.1175/1520-0493(1976)104<1209:TEOYFF>2.0.CO;2},
	abstract = {Abstract The basis upon which skill scores for evaluating yes/no categorical forecasts for scientific and administrative purposes depends is, discussed and many of the common discriminants (formulas from which skill scores are derived) are reviewed and compared. The common process of subjecting forecasts to a trial consisting of a mixture of event and non-event occasions is outlined. Those discriminants which prove to be measures of a forecasting technique's skill are shown, with the exception of Hanssen and Kuipers’ (1965) discriminant, to give skill scores which depend upon the mixture of events and non-events in the trial. All these discriminants give incompatible rankings of forecasts because they are based on different standards of skill. It is shown that this discrepancy is resolved by ensuring that the trials under which forecasts are compared have equal numbers of event and non-event occasions; under these conditions, rankings become compatible. Hanssen and Kuipers' discriminant is shown to give the best estimate on an “unequal“ trial to that expected if equalization were to be enforced. Hence, it is argued that Hanssen and Kuipers' discriminant is universally acceptable for evaluating yes/no forecasts for scientific and administrative purposes. Finally, the variance of Hanssen and Kuipers’ discriminant is given to enable the statistical significance of the difference between two scores to be assessed and thereby make comparisons between techniques more meaningful.},
	language = {EN},
	number = {10},
	urldate = {2023-08-29},
	journal = {Monthly Weather Review},
	author = {Woodcock, Frank},
	month = oct,
	year = {1976},
	note = {Publisher: American Meteorological Society
Section: Monthly Weather Review},
	pages = {1209--1214},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/C446H2Y9/Woodcock - 1976 - The Evaluation of YesNo Forecasts for Scientific .pdf:application/pdf},
}

@misc{harder_generating_2022,
	title = {Generating physically-consistent high-resolution climate data with hard-constrained neural networks},
	url = {http://arxiv.org/abs/2208.05424},
	abstract = {The availability of reliable, high-resolution climate and weather data is important to inform long-term decisions on climate adaptation and mitigation and to guide rapid responses to extreme events. Forecasting models are limited by computational costs and therefore often predict quantities at a coarse spatial resolution. Statistical downscaling can provide an efficient method of upsampling low-resolution data. In this field, deep learning has been applied successfully, often using methods from the super-resolution domain in computer vision. Despite often achieving visually compelling results, such models often violate conservation laws when predicting physical variables. In order to conserve important physical quantities, we develop methods that guarantee physical constraints are satisfied by a deep downscaling model while also increasing their performance according to traditional metrics. We introduce two ways of constraining the network: A renormalization layer added to the end of the neural network and a successive approach that scales with increasing upsampling factors. We show the applicability of our methods across different popular architectures and upsampling factors using ERA5 reanalysis data.},
	author = {Harder, Paula and Yang, Qidong and Ramesh, Venkatesh and Sattigeri, Prasanna and Hernandez-Garcia, Alex and Watson, Campbell and Szwarcman, Daniela and Rolnick, David},
	month = aug,
	year = {2022},
	note = {arXiv: 2208.05424},
	keywords = {★},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/FLS8MSSP/2208.05424.pdf:application/pdf},
}

@misc{lam_graphcast_2022,
	title = {{GraphCast}: {Learning} skillful medium-range global weather forecasting},
	abstract = {We introduce a machine-learning (ML)-based weather simulator--called "GraphCast"--which outperforms the most accurate deterministic operational medium-range weather forecasting system in the world, as well as all previous ML baselines. GraphCast is an autoregressive model, based on graph neural networks and a novel high-resolution multi-scale mesh representation, which we trained on historical weather data from the European Centre for Medium-Range Weather Forecasts (ECMWF)'s ERA5 reanalysis archive. It can make 10-day forecasts, at 6-hour time intervals, of five surface variables and six atmospheric variables, each at 37 vertical pressure levels, on a 0.25-degree latitude-longitude grid, which corresponds to roughly 25 x 25 kilometer resolution at the equator. Our results show GraphCast is more accurate than ECMWF's deterministic operational forecasting system, HRES, on 90.0\% of the 2760 variable and lead time combinations we evaluated. GraphCast also outperforms the most accurate previous ML-based weather forecasting model on 99.2\% of the 252 targets it reported. GraphCast can generate a 10-day forecast (35 gigabytes of data) in under 60 seconds on Cloud TPU v4 hardware. Unlike traditional forecasting methods, ML-based forecasting scales well with data: by training on bigger, higher quality, and more recent data, the skill of the forecasts can improve. Together these results represent a key step forward in complementing and improving weather modeling with ML, open new opportunities for fast, accurate forecasting, and help realize the promise of ML-based simulation in the physical sciences.},
	author = {Lam, Remi and Sanchez-Gonzalez, Alvaro and Willson, Matthew and Wirnsberger, Peter and Fortunato, Meire and Pritzel, Alexander and Ravuri, Suman and Ewalds, Timo and Alet, Ferran and Eaton-Rosen, Zach and Hu, Weihua and Merose, Alexander and Hoyer, Stephan and Holland, George and Stott, Jacklynn and Vinyals, Oriol and Mohamed, Shakir and Battaglia, Peter},
	month = dec,
	year = {2022},
	note = {arXiv: 2212.12794},
	file = {Lam et al. - 2022 - GraphCast Learning skillful medium-range global w.pdf:/Users/bobbyantonio/Zotero/storage/5XXFZQ9V/Lam et al. - 2022 - GraphCast Learning skillful medium-range global w.pdf:application/pdf},
}

@misc{mouatadid_adaptive_2022,
	title = {Adaptive {Bias} {Correction} for {Improved} {Subseasonal} {Forecasting}},
	url = {http://arxiv.org/abs/2209.10666},
	abstract = {Subseasonal forecasting \${\textbackslash}unicode\{x2013\}\$ predicting temperature and precipitation 2 to 6 weeks \${\textbackslash}unicode\{x2013\}\$ ahead is critical for effective water allocation, wildfire management, and drought and flood mitigation. Recent international research efforts have advanced the subseasonal capabilities of operational dynamical models, yet temperature and precipitation prediction skills remains poor, partly due to stubborn errors in representing atmospheric dynamics and physics inside dynamical models. To counter these errors, we introduce an adaptive bias correction (ABC) method that combines state-of-the-art dynamical forecasts with observations using machine learning. When applied to the leading subseasonal model from the European Centre for Medium-Range Weather Forecasts (ECMWF), ABC improves temperature forecasting skill by 60-90\% and precipitation forecasting skill by 40-69\% in the contiguous U.S. We couple these performance improvements with a practical workflow, based on Cohort Shapley, for explaining ABC skill gains and identifying higher-skill windows of opportunity based on specific climate conditions.},
	author = {Mouatadid, Soukayna and Orenstein, Paulo and Flaspohler, Genevieve and Cohen, Judah and Oprescu, Miruna and Fraenkel, Ernest and Mackey, Lester},
	month = sep,
	year = {2022},
	note = {arXiv: 2209.10666},
	keywords = {★},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/TSNUJNCW/2209.10666.pdf:application/pdf},
}

@misc{singh_urban_2022,
	title = {Urban precipitation downscaling using deep learning: a smart city application over {Austin}, {Texas}, {USA}},
	url = {http://arxiv.org/abs/2209.06848},
	abstract = {Urban downscaling is a link to transfer the knowledge from coarser climate information to city scale assessments. These high-resolution assessments need multiyear climatology of past data and future projections, which are complex and computationally expensive to generate using traditional numerical weather prediction models. The city of Austin, Texas, USA has seen tremendous growth in the past decade. Systematic planning for the future requires the availability of fine resolution city-scale datasets. In this study, we demonstrate a novel approach generating a general purpose operator using deep learning to perform urban downscaling. The algorithm employs an iterative super-resolution convolutional neural network (Iterative SRCNN) over the city of Austin, Texas, USA. We show the development of a high-resolution gridded precipitation product (300 m) from a coarse (10 km) satellite-based product (JAXA GsMAP). High resolution gridded datasets of precipitation offer insights into the spatial distribution of heavy to low precipitation events in the past. The algorithm shows improvement in the mean peak-signal-to-noise-ratio and mutual information to generate high resolution gridded product of size 300 m X 300 m relative to the cubic interpolation baseline. Our results have implications for developing high-resolution gridded-precipitation urban datasets and the future planning of smart cities for other cities and other climatic variables.},
	author = {Singh, Manmeet and Acharya, Nachiketa and Jamshidi, Sajad and Jiao, Junfeng and Yang, Zong-Liang and Coudert, Marc and Baumer, Zach and Niyogi, Dev},
	month = aug,
	year = {2022},
	note = {arXiv: 2209.06848},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/2IZTHRS4/2209.06848.pdf:application/pdf},
}

@misc{gascon_post-processing_2023,
	title = {Post-processing output from ensembles with and without parametrised convection, to create accurate, blended, high-fidelity rainfall forecasts},
	url = {http://arxiv.org/abs/2301.04485},
	abstract = {Flash flooding is a significant societal problem, but related precipitation forecasts are often poor. To address this, one can try to use output from convection-parametrising (global) ensembles, post-processed to forecast at point-scale, or convection-resolving limited area ensembles. In this study, we combine both. First, we apply the "ecPoint-rainfall" post-processing to the ECMWF global ensemble. Then, we use 2.2km COSMO LAM ensemble output (centred on Italy), and also post-process it using a scale-selective neighbourhood approach to compensate for insufficient members. The two components then undergo lead-time-weighted blending, to create the final probabilistic 6h rainfall forecasts. Product creation for forecasters constituted the "Italy Flash Flood use case" within the EU-funded MISTRAL project and it will be a real-time open-access product. One year of verification shows that ecPoint is the most skilful ensemble product. The post-processed COSMO ensemble adds most value to summer convective events in the evening, when the global model has an underprediction bias. In two heavy rainfall case studies we observed underestimation of the largest point totals in the raw ECMWF ensemble, and overestimation in the raw COSMO ensemble. However, ecPoint increase the value and highlighted best the most affected areas, whilst post-processing of COSMO diminished extremes by eradicating unreliable detail. The final merged products looked best from a user perspective and seemed to be the most skilful of all. Although our LAM post-processing does not implicitly include bias correction (a topic for further work) our study nonetheless provides a unique blueprint for successfully combining ensemble rainfall forecasts from global and LAM systems around the world. It also has important implications for forecast products as global ensembles move ever closer to having convection-permitting resolution.},
	author = {Gascón, Estíbaliz and Montani, Andrea and Hewson, Tim D.},
	month = jan,
	year = {2023},
	note = {arXiv: 2301.04485},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/64M4CTMM/2301.04485.pdf:application/pdf},
}

@misc{leinonen_latent_2023,
	title = {Latent diffusion models for generative precipitation nowcasting with accurate uncertainty quantification},
	url = {http://arxiv.org/abs/2304.12891},
	abstract = {Diffusion models have been widely adopted in image generation, producing higher-quality and more diverse samples than generative adversarial networks (GANs). We introduce a latent diffusion model (LDM) for precipitation nowcasting - short-term forecasting based on the latest observational data. The LDM is more stable and requires less computation to train than GANs, albeit with more computationally expensive generation. We benchmark it against the GAN-based Deep Generative Models of Rainfall (DGMR) and a statistical model, PySTEPS. The LDM produces more accurate precipitation predictions, while the comparisons are more mixed when predicting whether the precipitation exceeds predefined thresholds. The clearest advantage of the LDM is that it generates more diverse predictions than DGMR or PySTEPS. Rank distribution tests indicate that the distribution of samples from the LDM accurately reflects the uncertainty of the predictions. Thus, LDMs are promising for any applications where uncertainty quantification is important, such as weather and climate.},
	author = {Leinonen, Jussi and Hamann, Ulrich and Nerini, Daniele and Germann, Urs and Franch, Gabriele},
	month = apr,
	year = {2023},
	note = {arXiv: 2304.12891},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/BYN235CL/2304.12891.pdf:application/pdf},
}

@misc{nguyen_climax_2023,
	title = {{ClimaX}: {A} foundation model for weather and climate},
	url = {http://arxiv.org/abs/2301.10343},
	abstract = {Most state-of-the-art approaches for weather and climate modeling are based on physics-informed numerical models of the atmosphere. These approaches aim to model the non-linear dynamics and complex interactions between multiple variables, which are challenging to approximate. Additionally, many such numerical models are computationally intensive, especially when modeling the atmospheric phenomenon at a fine-grained spatial and temporal resolution. Recent data-driven approaches based on machine learning instead aim to directly solve a downstream forecasting or projection task by learning a data-driven functional mapping using deep neural networks. However, these networks are trained using curated and homogeneous climate datasets for specific spatiotemporal tasks, and thus lack the generality of numerical models. We develop and demonstrate ClimaX, a flexible and generalizable deep learning model for weather and climate science that can be trained using heterogeneous datasets spanning different variables, spatio-temporal coverage, and physical groundings. ClimaX extends the Transformer architecture with novel encoding and aggregation blocks that allow effective use of available compute while maintaining general utility. ClimaX is pre-trained with a self-supervised learning objective on climate datasets derived from CMIP6. The pre-trained ClimaX can then be fine-tuned to address a breadth of climate and weather tasks, including those that involve atmospheric variables and spatio-temporal scales unseen during pretraining. Compared to existing data-driven baselines, we show that this generality in ClimaX results in superior performance on benchmarks for weather forecasting and climate projections, even when pretrained at lower resolutions and compute budgets.},
	author = {Nguyen, Tung and Brandstetter, Johannes and Kapoor, Ashish and Gupta, Jayesh K. and Grover, Aditya},
	month = jan,
	year = {2023},
	note = {arXiv: 2301.10343},
	keywords = {★},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/YITSNAV6/2301.10343.pdf:application/pdf},
}

@misc{ramavajjala_verification_2023,
	title = {Verification against in-situ observations for {Data}-{Driven} {Weather} {Prediction}},
	url = {http://arxiv.org/abs/2305.00048},
	abstract = {Data-driven weather prediction models (DDWPs) have made rapid strides in recent years, demonstrating an ability to approximate Numerical Weather Prediction (NWP) models to a high degree of accuracy. The fast, accurate, and low-cost DDWP forecasts make their use in operational forecasting an attractive proposition, however, there remains work to be done in rigorously evaluating DDWPs in a true operational setting. Typically trained and evaluated using ERA5 reanalysis data, DDWPs have been tested only in a simulation, which cannot represent the real world with complete accuracy even if it is of a very high quality. The safe use of DDWPs in operational forecasting requires more thorough "real-world" verification, as well as a careful examination of how DDWPs are currently trained and evaluated. It is worth asking, for instance, how well do the reanalysis datasets, used for training, simulate the real world? With an eye towards climate justice and the uneven availability of weather data: is the simulation equally good for all regions of the world, and would DDWPs exacerbate biases present in the training data? Does a good performance in simulation correspond to good performance in operational settings? In addition to approximating the physics of NWP models, how can ML be uniquely deployed to provide more accurate weather forecasts? As a first step towards answering such questions, we present a robust dataset of in-situ observations derived from the NOAA MADIS program to serve as a benchmark to validate DDWPs in an operational setting. By providing a large corpus of quality-controlled, in-situ observations, this dataset provides a meaningful real-world task that all NWPs and DDWPs can be tested against. We hope that this data can be used not only to rigorously and fairly compare operational weather models but also to spur future research in new directions.},
	author = {Ramavajjala, Vivek and Mitra, Peetak P.},
	month = apr,
	year = {2023},
	note = {arXiv: 2305.00048},
	keywords = {★},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/VVP34YIB/2305.00048.pdf:application/pdf},
}

@misc{chammas_accelerating_2023,
	title = {Accelerating large-eddy simulations of clouds with {Tensor} {Processing} {Units}},
	url = {http://arxiv.org/abs/2301.04698},
	abstract = {Clouds, especially low clouds, are crucial for regulating Earth's energy balance and mediating the response of the climate system to changes in greenhouse gas concentrations. Despite their importance for climate, they remain relatively poorly understood and are inaccurately represented in climate models. A principal reason is that the high computational expense of simulating them with large-eddy simulations (LES) has inhibited broad and systematic numerical experimentation and the generation of large datasets for training parametrization schemes for climate models. Here we demonstrate LES of low clouds on Tensor Processing Units (TPUs), application-specific integrated circuits that were originally developed for machine learning applications. We show that TPUs in conjunction with tailored software implementations can be used to simulate computationally challenging stratocumulus clouds in conditions observed during the Dynamics and Chemistry of Marine Stratocumulus (DYCOMS) field study. The TPU-based LES code successfully reproduces clouds during DYCOMS and opens up the large computational resources available on TPUs to cloud simulations. The code enables unprecedented weak and strong scaling of LES, making it possible, for example, to simulate stratocumulus with \$10{\textbackslash}times\$ speedup over real-time evolution in domains with a \$34.7{\textasciitilde}{\textbackslash}mathrm\{km\} {\textbackslash}times 53.8{\textasciitilde}{\textbackslash}mathrm\{km\}\$ horizontal cross section. The results open up new avenues for computational experiments and for substantially enlarging the sample of LES available to train parameterizations of low clouds.},
	urldate = {2023-08-21},
	publisher = {arXiv},
	author = {Chammas, Sheide and Wang, Qing and Schneider, Tapio and Ihme, Matthias and Chen, Yi-fan and Anderson, John},
	month = aug,
	year = {2023},
	note = {arXiv:2301.04698 [physics]},
	keywords = {Physics - Atmospheric and Oceanic Physics, Physics - Computational Physics, J.2, Mathematics - Numerical Analysis, Physics - Fluid Dynamics, Physics - Geophysics},
}

@misc{addison_machine_2022,
	title = {Machine learning emulation of a local-scale {UK} climate model},
	url = {http://arxiv.org/abs/2211.16116},
	abstract = {Climate change is causing the intensification of rainfall extremes. Precipitation projections with high spatial resolution are important for society to prepare for these changes, e.g. to model flooding impacts. Physics-based simulations for creating such projections are very computationally expensive. This work demonstrates the effectiveness of diffusion models, a form of deep generative models, for generating much more cheaply realistic high resolution rainfall samples for the UK conditioned on data from a low resolution simulation. We show for the first time a machine learning model that is able to produce realistic samples of high-resolution rainfall based on a physical model that resolves atmospheric convection, a key process behind extreme rainfall. By adding self-learnt, location-specific information to low resolution relative vorticity, quantiles and time-mean of the samples match well their counterparts from the high-resolution simulation.},
	author = {Addison, Henry and Kendon, Elizabeth and Ravuri, Suman and Aitchison, Laurence and Watson, Peter AG},
	month = nov,
	year = {2022},
	note = {arXiv: 2211.16116},
	file = {PDF:/Users/bobbyantonio/Zotero/storage/S9C3FG87/2211.16116.pdf:application/pdf},
}

@article{macleod_are_2021,
	title = {Are {Kenya} {Meteorological} {Department} heavy rainfall advisories useful for forecast-based early action and early preparedness for flooding?},
	volume = {21},
	issn = {1561-8633},
	url = {https://nhess.copernicus.org/articles/21/261/2021/},
	doi = {10.5194/nhess-21-261-2021},
	abstract = {Preparedness saves lives. Forecasts can help improve preparedness by triggering early actions as part of pre-defined protocols under the Forecast-based Financing (FbF) approach; however it is essential to understand the skill of a forecast before using it as a trigger. In order to support the development of early-action protocols over Kenya, we evaluate the 33 heavy rainfall advisories (HRAs) issued by the Kenya Meteorological Department (KMD) during 2015–2019.

 The majority of HRAs warn counties which subsequently receive heavy rainfall within the forecast window. We also find a significant improvement in the advisory ability to anticipate flood events over time, with particularly high levels of skill in recent years. For instance actions with a 2-week lifetime based on advisories issued in 2015 and 2016 would have failed to anticipate nearly all recorded flood events in that period, whilst actions in 2019 would have anticipated over 70 \% of the instances of flooding at the county level. When compared against the most significant flood events over the period which led to significant loss of life, all three such periods during 2018 and 2019 were preceded by HRAs, and in these cases the advisories accurately warned the specific counties for which significant impacts were recorded. By contrast none of the four significant flooding events in 2015–2017 were preceded by advisories. This step change in skill may be due to developing forecaster experience with synoptic patterns associated with extremes as well as access to new dynamical prediction tools that specifically address extreme event probability; for example, KMD access to the UK Met Office Global Hazard Map was introduced at the end of 2017.

 Overall we find that KMD HRAs effectively warn of heavy rainfall and flooding and can be a vital source of information for early preparedness. However a lack of spatial detail on flood impacts and broad probability ranges limit their utility for systematic FbF approaches. We conclude with suggestions for making the HRAs more useful for FbF and outline the developing approach to flood forecasting in Kenya.},
	language = {English},
	number = {1},
	urldate = {2023-08-18},
	journal = {Natural Hazards and Earth System Sciences},
	author = {MacLeod, David and Kilavi, Mary and Mwangi, Emmah and Ambani, Maurine and Osunga, Michael and Robbins, Joanne and Graham, Richard and Rowhani, Pedram and Todd, Martin C.},
	month = jan,
	year = {2021},
	note = {Publisher: Copernicus GmbH},
	pages = {261--277},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/JZFR5G6X/MacLeod et al. - 2021 - Are Kenya Meteorological Department heavy rainfall.pdf:application/pdf},
}

@article{pendergrass_what_2018,
	title = {What precipitation is extreme?},
	volume = {360},
	url = {https://www.science.org/doi/10.1126/science.aat1871},
	doi = {10.1126/science.aat1871},
	number = {6393},
	urldate = {2023-08-15},
	journal = {Science},
	author = {Pendergrass, Angeline G.},
	month = jun,
	year = {2018},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {1072--1073},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/Q4UC2EKU/Pendergrass - 2018 - What precipitation is extreme.pdf:application/pdf},
}

@article{hession_spatial_2011,
	title = {A spatial regression analysis of the influence of topography on monthly rainfall in {East} {Africa}},
	volume = {31},
	copyright = {Copyright © 2010 Royal Meteorological Society},
	issn = {1097-0088},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/joc.2174},
	doi = {10.1002/joc.2174},
	abstract = {Precipitation in Kenya is highly variable and dominated by a variety of physical processes. Statistical studies of climate patterns have historically focused on application of ordinary least squares (OLS) regression to test hypotheses related to multiple predictive variables, perhaps in an attempt to better understand the physical mechanisms that drive precipitation, or on use of spatially explicit models, typically kriging- or spline-based analyses, for the purpose of improving predictions. Each of these approaches may be individually useful; however, they all possess limitations. OLS approaches have yielded biased results in the presence of spatially autocorrelated data. Kriging- and spline-based studies often focus on providing improved predictions rather than understanding. Here we use spatial regression, a method not commonly used in analysis of climate data, to assess the role of predictive variables while explicitly incorporating spatial autocorrelation in parameter estimation and hypothesis testing. This approach can yield a better understanding of relationships between precipitation and multiple predictive variables with improved statistical rigour. Using spatial regression, we show that topographic variables such as elevation and slope strongly influence rainfall during the ‘long rains’ and ‘short rains’, which are vital for Kenyan agriculture. Outside these seasons, we find that smaller (mesoscale) variations in elevation are statistically significant. Further, we demonstrate the shortcomings of automated selection procedures such as stepwise regression through the identification of spurious results due to confounding. Copyright © 2010 Royal Meteorological Society},
	language = {en},
	number = {10},
	urldate = {2023-08-10},
	journal = {International Journal of Climatology},
	author = {Hession, S. L. and Moore, N.},
	year = {2011},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/joc.2174},
	keywords = {precipitation, East Africa, Kenya, topography, geostatistics, spatial regression},
	pages = {1440--1456},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/VR5F9Q7U/Hession and Moore - 2011 - A spatial regression analysis of the influence of .pdf:application/pdf;Snapshot:/Users/bobbyantonio/Zotero/storage/BLQJAB33/joc.html:text/html},
}

@misc{yang_fourier_2023,
	title = {Fourier {Neural} {Operators} for {Arbitrary} {Resolution} {Climate} {Data} {Downscaling}},
	url = {http://arxiv.org/abs/2305.14452},
	abstract = {Climate simulations are essential in guiding our understanding of climate change and responding to its effects. However, it is computationally expensive to resolve complex climate processes at high spatial resolution. As one way to speed up climate simulations, neural networks have been used to downscale climate variables from fast-running low-resolution simulations, but high-resolution training data are often unobtainable or scarce, greatly limiting accuracy. In this work, we propose a downscaling method based on the Fourier neural operator. It trains with data of a small upsampling factor and then can zero-shot downscale its input to arbitrary unseen high resolution. Evaluated both on ERA5 climate model data and on the Navier-Stokes equation solution data, our downscaling model significantly outperforms state-of-the-art convolutional and generative adversarial downscaling models, both in standard single-resolution downscaling and in zero-shot generalization to higher upsampling factors. Furthermore, we show that our method also outperforms state-of-the-art data-driven partial differential equation solvers on Navier-Stokes equations. Overall, our work bridges the gap between simulation of a physical process and interpolation of low-resolution output, showing that it is possible to combine both approaches and significantly improve upon each other.},
	urldate = {2023-08-09},
	publisher = {arXiv},
	author = {Yang, Qidong and Hernandez-Garcia, Alex and Harder, Paula and Ramesh, Venkatesh and Sattegeri, Prasanna and Szwarcman, Daniela and Watson, Campbell D. and Rolnick, David},
	month = may,
	year = {2023},
	note = {arXiv:2305.14452 [physics]},
	keywords = {Computer Science - Machine Learning, Physics - Atmospheric and Oceanic Physics},
	annote = {Comment: Presented at the ICLR 2023 workshop on "Tackling Climate Change with Machine Learning"},
	file = {arXiv.org Snapshot:/Users/bobbyantonio/Zotero/storage/FS7VSQH8/2305.html:text/html;Full Text PDF:/Users/bobbyantonio/Zotero/storage/SNNYKV66/Yang et al. - 2023 - Fourier Neural Operators for Arbitrary Resolution .pdf:application/pdf},
}

@article{nicholson_turkana_2016,
	title = {The {Turkana} low-level jet: mean climatology and association with regional aridity},
	volume = {36},
	copyright = {© 2015 Royal Meteorological Society},
	issn = {1097-0088},
	shorttitle = {The {Turkana} low-level jet},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/joc.4515},
	doi = {10.1002/joc.4515},
	abstract = {This article develops the first climatology of the low-level jet that prevails in the Turkana Channel of northern Kenya. ERA-Interim data are utilized, giving the analysis a resolution of 0.75° of latitude/longitude and a temporal resolution of 6 h. The jet is found to be a semi-permanent feature, its occurrence ranging from 69\% of the days in May to 90\% of the days in October. It is strongest during the June–September dry season. Typical core speeds in a 0.75 × 0.75 grid point are 10–15 m s−1. The Turkana Jet is clearly a nocturnal feature, being strongest at 0000 UTC or 0600 UTC and usually barely discernible at 1200 UTC. There are distinct patterns of divergence and vertical motion associated with the jet and these differ between the entrance, core, and exit regions. The jet appears to modulate rainfall, especially during the nocturnal hours, with strong jets suppressing rainfall. It also appears to be a factor in the prevailing aridity in the northeast Kenya, southern Somalia, and southeastern Ethiopia and the absence of a summer rainy season in this region.},
	language = {en},
	number = {6},
	urldate = {2023-08-08},
	journal = {International Journal of Climatology},
	author = {Nicholson, Sharon},
	year = {2016},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/joc.4515},
	keywords = {Africa, East Africa, aridity, low-level jets, Turkana channel},
	pages = {2598--2614},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/UUDJW879/Nicholson - 2016 - The Turkana low-level jet mean climatology and as.pdf:application/pdf;Snapshot:/Users/bobbyantonio/Zotero/storage/VBQRGT2P/joc.html:text/html},
}

@article{hoerling_detection_2006,
	title = {Detection and {Attribution} of {Twentieth}-{Century} {Northern} and {Southern} {African} {Rainfall} {Change}},
	volume = {19},
	issn = {0894-8755, 1520-0442},
	url = {https://journals.ametsoc.org/view/journals/clim/19/16/jcli3842.1.xml},
	doi = {10.1175/JCLI3842.1},
	abstract = {Abstract The spatial patterns, time history, and seasonality of African rainfall trends since 1950 are found to be deducible from the atmosphere’s response to the known variations of global sea surface temperatures (SSTs). The robustness of the oceanic impact is confirmed through the diagnosis of 80 separate 50-yr climate simulations across a suite of atmospheric general circulation models. Drying over the Sahel during boreal summer is shown to be a response to warming of the South Atlantic relative to North Atlantic SST, with the ensuing anomalous interhemispheric SST contrast favoring a more southern position of the Atlantic intertropical convergence zone. Southern African drying during austral summer is shown to be a response to Indian Ocean warming, with enhanced atmospheric convection over those warm waters driving subsidence drying over Africa. The ensemble of greenhouse-gas-forced experiments, conducted as part of the Fourth Assessment Report of the Intergovernmental Panel on Climate Change, fails to simulate the pattern or amplitude of the twentieth-century African drying, indicating that the drought conditions were likely of natural origin. For the period 2000–49, the ensemble mean of the forced experiments yields a wet signal over the Sahel and a dry signal over southern Africa. These rainfall changes are physically consistent with a projected warming of the North Atlantic Ocean compared with the South Atlantic Ocean, and a further warming of the Indian Ocean. However, considerable spread exists among the individual members of the multimodel ensemble.},
	language = {EN},
	number = {16},
	urldate = {2023-08-08},
	journal = {Journal of Climate},
	author = {Hoerling, Martin and Hurrell, James and Eischeid, Jon and Phillips, Adam},
	month = aug,
	year = {2006},
	note = {Publisher: American Meteorological Society
Section: Journal of Climate},
	pages = {3989--4008},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/NDNPERY4/Hoerling et al. - 2006 - Detection and Attribution of Twentieth-Century Nor.pdf:application/pdf},
}

@article{yang_east_2014,
	title = {The {East} {African} {Long} {Rains} in {Observations} and {Models}},
	volume = {27},
	issn = {0894-8755, 1520-0442},
	url = {https://journals.ametsoc.org/view/journals/clim/27/19/jcli-d-13-00447.1.xml},
	doi = {10.1175/JCLI-D-13-00447.1},
	abstract = {Abstract Decadal variability of the East African precipitation during the season of March–May (long rains) is examined and the performance of a series of models in simulating the observed features is assessed. Observational results show that the drying trend of the long rains is associated with decadal natural variability associated with sea surface temperature (SST) variations over the Pacific Ocean. Empirical orthogonal function (EOF), linear regression, and composite analyses all show the spatial pattern of the associated SST field to be La Niña like. The SST-forced International Research Institute for Climate and Society (IRI) forecast models are able to capture the East African precipitation climatology, the decadal variability of the long rains, and the associated SST anomaly pattern but are not consistent with observations from the 1970s. The multimodel mean of the SST-forced models from the Coupled Model Intercomparison Project phase 5 (CMIP5) Atmospheric Model Intercomparison Project (AMIP) experiment captures the climatology and the drying trend in recent decades. The fully coupled models from the CMIP5 historical experiment, however, have systematic errors in simulating the East African precipitation climatology by underestimating the long rains while overestimating the short rains. The multimodel mean of the historical simulations of the long rains anomalies, which is the best estimate of the radiatively forced change, shows a weak wetting trend associated with anthropogenic forcing. The SST anomaly pattern associated with the long rains has large discrepancies with the observations. The results herein suggest caution in projections of East African precipitation from CMIP5 or the relationship between the East African precipitation and the SST spatial pattern found in paleoclimate studies with coupled climate models.},
	language = {EN},
	number = {19},
	urldate = {2023-08-08},
	journal = {Journal of Climate},
	author = {Yang, Wenchang and Seager, Richard and Cane, Mark A. and Lyon, Bradfield},
	month = oct,
	year = {2014},
	note = {Publisher: American Meteorological Society
Section: Journal of Climate},
	pages = {7185--7202},
	file = {Full Text:/Users/bobbyantonio/Zotero/storage/LHSGL3EB/Yang et al. - 2014 - The East African Long Rains in Observations and Mo.pdf:application/pdf},
}

@article{rowell_reconciling_2015,
	title = {Reconciling {Past} and {Future} {Rainfall} {Trends} over {East} {Africa}},
	volume = {28},
	issn = {0894-8755, 1520-0442},
	url = {https://journals.ametsoc.org/view/journals/clim/28/24/jcli-d-15-0140.1.xml},
	doi = {10.1175/JCLI-D-15-0140.1},
	abstract = {Abstract The “long rains” season of East Africa has recently experienced a series of devastating droughts, whereas the majority of climate models predict increasing rainfall for the coming decades. This has been termed the East African climate paradox and has implications for developing viable adaptation policies. A logical framework is adopted that leads to six key hypotheses that could explain this paradox. The first hypothesis that the recent observed trend is due to poor quality data is promptly rejected. An initial judgment on the second hypothesis that the projected trend is founded on poor modeling is beyond the scope of a single study. Analysis of a natural variability hypothesis suggests this is unlikely to have been the dominant driver of recent droughts, although it may have contributed. The next two hypotheses explore whether the balance between competing forcings could be changing. Regarding the possibility that the past trend could be due to changing anthropogenic aerosol emissions, the results of sensitivity experiments are highly model dependent, but some show a significant impact on the patterns of tropical SST trends, aspects of which likely caused the recent long rains droughts. Further experiments suggest land-use changes are unlikely to have caused the recent droughts. The last hypothesis that the response to CO2 emissions is nonlinear explains no more than 10\% of the contrast between recent and projected trends. In conclusion, it is recommended that research priorities now focus on providing a process-based expert judgment of the reliability of East Africa projections, improving the modeling of aerosol impacts on rainfall, and better understanding the relevant natural variability.},
	language = {EN},
	number = {24},
	urldate = {2023-08-08},
	journal = {Journal of Climate},
	author = {Rowell, David P. and Booth, Ben B. B. and Nicholson, Sharon E. and Good, Peter},
	month = dec,
	year = {2015},
	note = {Publisher: American Meteorological Society
Section: Journal of Climate},
	pages = {9768--9788},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/XKCZ9H58/Rowell et al. - 2015 - Reconciling Past and Future Rainfall Trends over E.pdf:application/pdf},
}

@article{camberlin_east_2002,
	title = {The {East} {African} {March}–{May} {Rainy} {Season}: {Associated} {Atmospheric} {Dynamics} and {Predictability} over the 1968–97 {Period}},
	volume = {15},
	issn = {0894-8755, 1520-0442},
	shorttitle = {The {East} {African} {March}–{May} {Rainy} {Season}},
	url = {https://journals.ametsoc.org/view/journals/clim/15/9/1520-0442_2002_015_1002_teammr_2.0.co_2.xml},
	doi = {10.1175/1520-0442(2002)015<1002:TEAMMR>2.0.CO;2},
	abstract = {Abstract This paper focuses on the East African March–May “long rains.” Particularly, it investigates the atmospheric patterns associated to the March–May rainfall anomalies, then proposes a seasonal prediction model. In a preliminary step, in order to define a regional rainfall index, a new form of extended principal component analysis is performed, aimed at capturing both the spatial and intraseasonal rainfall coherence. What emerges is that although the long rains exhibit a low temporal coherence, calling for a separation between the months of March–April and May in teleconnection studies, they show a relatively strong spatial consistency over the Kenya–Uganda inland region. From composite analyses performed using NCEP–NCAR reanalyzed atmospheric data, three major signals appear for that region. Two are during March–April involving ENSO and the latitudinal location of the ITCZ, and ENSO interactions with the northern extratropical dynamics (by way of cool surges toward the Tropics and upper-ridge–trough systems). The third signal is the Asian monsoon in May. As shown using a rainfall index for Ethiopia, the interactions with the midlatitudes get stronger when considering rainfall farther to the north. The predictability study identifies four February indexes, involving several scales and several atmospheric and oceanic parameters, to serve as predictors in linear multiple regression (LMR) and linear discriminant analysis (LDA) models. The predictors, selected by a stepwise procedure, depict both regional (energy gradient and zonal wind) and remote dynamics (ENSO and 500-hPa geopotential height over the Near East): they are consistent with the signals shown in the synchronous composites. The robustness of the LMR and LDA models is demonstrated by the high linear error in probability space (LEPS) scores (44\% for continuous variables and 51\% for categorical variables) obtained on cross-validated results.},
	language = {EN},
	number = {9},
	urldate = {2023-08-08},
	journal = {Journal of Climate},
	author = {Camberlin, P. and Philippon, N.},
	month = may,
	year = {2002},
	note = {Publisher: American Meteorological Society
Section: Journal of Climate},
	pages = {1002--1019},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/V6HYC3NZ/Camberlin and Philippon - 2002 - The East African March–May Rainy Season Associate.pdf:application/pdf},
}

@article{schwarzwald_understanding_2023,
	title = {Understanding {CMIP6} biases in the representation of the {Greater} {Horn} of {Africa} long and short rains},
	volume = {61},
	issn = {1432-0894},
	url = {https://doi.org/10.1007/s00382-022-06622-5},
	doi = {10.1007/s00382-022-06622-5},
	abstract = {The societies of the Greater Horn of Africa (GHA) are vulnerable to variability in two distinct rainy seasons, the March–May ‘long’ rains and the October–December ‘short’ rains. Recent trends in both rainy seasons, possibly related to patterns of low-frequency variability, have increased interest in future climate projections from General Circulation Models (GCMs). However, previous generations of GCMs historically have poorly simulated the regional hydroclimate. This study conducts a process-based evaluation of simulations of the long and short rains in CMIP6, the latest generation of GCMs. Key biases in CMIP5 remain or are worsened, including long rains that are too short and weak and short rains that are too long and strong. Model biases are driven by a complex set of related oceanic and atmospheric factors, including simulations of the Walker Circulation. Biased wet short rains in models are connected with Indian Ocean zonal sea surface temperature (SST) gradients that are too warm in the west and convection that is too deep. Models connect equatorial African winds with the strength of the short rains, though in observations a robust connection is primarily found in the long rains. Model mean state biases in the timing of the western Indian Ocean SST seasonal cycle are associated with certain rainfall timing biases, though both biases may be due to a common source. Simulations driven by historical SSTs (AMIP runs) often have larger biases than fully coupled runs. A path towards using biases to better understand uncertainty in projections of GHA rainfall is suggested.},
	language = {en},
	number = {3},
	urldate = {2023-08-08},
	journal = {Climate Dynamics},
	author = {Schwarzwald, Kevin and Goddard, Lisa and Seager, Richard and Ting, Mingfang and Marvel, Kate},
	month = aug,
	year = {2023},
	keywords = {Climate models, East Africa, Indian Ocean Dipole, Precipitation variability, Walker Circulation},
	pages = {1229--1255},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/2JMXDN3K/Schwarzwald et al. - 2023 - Understanding CMIP6 biases in the representation o.pdf:application/pdf},
}

@article{liebmann_understanding_2014,
	title = {Understanding {Recent} {Eastern} {Horn} of {Africa} {Rainfall} {Variability} and {Change}},
	volume = {27},
	issn = {0894-8755, 1520-0442},
	url = {https://journals.ametsoc.org/view/journals/clim/27/23/jcli-d-13-00714.1.xml},
	doi = {10.1175/JCLI-D-13-00714.1},
	abstract = {Abstract Observations and sea surface temperature (SST)-forced ECHAM5 simulations are examined to study the seasonal cycle of eastern Africa rainfall and its SST sensitivity during 1979–2012, focusing on interannual variability and trends. The eastern Horn is drier than the rest of equatorial Africa, with two distinct wet seasons, and whereas the October–December wet season has become wetter, the March–May season has become drier. The climatological rainfall in simulations driven by observed SSTs captures this bimodal regime. The simulated trends also qualitatively reproduce the opposite-sign changes in the two rainy seasons, suggesting that SST forcing has played an important role in the observed changes. The consistency between the sign of 1979–2012 trends and interannual SST–precipitation correlations is exploited to identify the most likely locations of SST forcing of precipitation trends in the model, and conceivably also in nature. Results indicate that the observed March–May drying since 1979 is due to sensitivity to an increased zonal gradient in SST between Indonesia and the central Pacific. In contrast, the October–December precipitation increase is mostly due to western Indian Ocean warming. The recent upward trend in the October–December wet season is rather weak, however, and its statistical significance is compromised by strong year-to-year fluctuations. October–December eastern Horn rain variability is strongly associated with El Niño–Southern Oscillation and Indian Ocean dipole phenomena on interannual scales, in both model and observations. The interannual October–December correlation between the ensemble-average and observed Horn rainfall 0.87. By comparison, interannual March–May Horn precipitation is only weakly constrained by SST anomalies.},
	language = {EN},
	number = {23},
	urldate = {2023-08-08},
	journal = {Journal of Climate},
	author = {Liebmann, Brant and Hoerling, Martin P. and Funk, Chris and Bladé, Ileana and Dole, Randall M. and Allured, Dave and Quan, Xiaowei and Pegion, Philip and Eischeid, Jon K.},
	month = dec,
	year = {2014},
	note = {Publisher: American Meteorological Society
Section: Journal of Climate},
	pages = {8630--8645},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/53SDDMNQ/Liebmann et al. - 2014 - Understanding Recent Eastern Horn of Africa Rainfa.pdf:application/pdf},
}

@article{ayugi_comparison_2021,
	title = {Comparison of {CMIP6} and {CMIP5} models in simulating mean and extreme precipitation over {East} {Africa}},
	volume = {41},
	copyright = {© 2021 Royal Meteorological Society},
	issn = {1097-0088},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/joc.7207},
	doi = {10.1002/joc.7207},
	abstract = {This study examines the improvement in Coupled Model Intercomparison Project Phase Six (CMIP6) models against the predecessor CMIP5 in simulating mean and extreme precipitation over the East Africa region. The study compares the climatology of the precipitation indices simulated by the CMIP models with the CHIRPS data set using robust statistical techniques for 1981–2005. The results display the varying performance of the general circulation models (GCMs) in the simulation of annual and seasonal precipitation climatology over the study domain. CMIP6 multi-model ensemble mean (hereafter MME) shows improved performance in the local annual mean cycle simulation with a better representation of the rainfall within the two peaks, especially the MAM rainfall relative to their predecessor. Moreover, simulation of extreme indices is well captured in CMIP6 models relative to CMIP5. The CMIP6-MME performed better than the CMIP5-MME with lesser biases in simulating Simple Daily Intensity Index (SDII), consecutive dry days (CDD), and very heavy precipitation days {\textgreater}20 mm (R20mm) over East Africa. Remarkably, most CMIP6 models are unable to simulate extremely wet days (R95p). Some CMIP6 models (e.g., NorESM2-MM and CNRM-CM6-1) depict robust performance in reproducing the observed indices across all analyses. OND season shows wet biases for some indices (i.e., R95p, PRCPTOT), except for SDII, CDD, and R20mm in CMIP6 models. Consistent with other studies, the mean ensemble performance for both CMIP5/6 shows better performance as compared with individual models due to the cancellation of some systematic errors in the individual models. Generally, CMIP6 depicts improved performance in the simulation of MAM rainfall compared with CMIP5 models. However, the new model generation is still marred by uncertainty, thereby depicting unsatisfactory performance over the East Africa domain. This calls for further investigation into the sources of persistent systematic biases and a methodology for identifying individual models with robust features that can accurately simulate observed patterns for future usage.},
	language = {en},
	number = {15},
	urldate = {2023-08-08},
	journal = {International Journal of Climatology},
	author = {Ayugi, Brian and Zhihong, Jiang and Zhu, Huanhuan and Ngoma, Hamida and Babaousmail, Hassen and Rizwan, Karim and Dike, Victor},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/joc.7207},
	keywords = {evaluation, precipitation, East Africa, climate extremes, CMIP5/6},
	pages = {6474--6496},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/BDTNCB7J/Ayugi et al. - 2021 - Comparison of CMIP6 and CMIP5 models in simulating.pdf:application/pdf;Snapshot:/Users/bobbyantonio/Zotero/storage/XEJLHBFZ/joc.html:text/html},
}

@article{roberts_climate_2018,
	title = {Climate model configurations of the {ECMWF} {Integrated} {Forecasting} {System} ({ECMWF}-{IFS} cycle 43r1) for {HighResMIP}},
	volume = {11},
	issn = {1991-959X},
	url = {https://gmd.copernicus.org/articles/11/3681/2018/},
	doi = {10.5194/gmd-11-3681-2018},
	abstract = {This paper presents atmosphere-only and coupled climate model configurations of the European Centre for Medium-Range Weather Forecasts Integrated Forecasting System (ECMWF-IFS) for different combinations of ocean and atmosphere resolution. These configurations are used to perform multi-decadal ensemble experiments following the protocols of the High Resolution Model Intercomparison Project (HighResMIP) and phase 6 of the Coupled Model Intercomparison Project (CMIP6). These experiments are used to evaluate the sensitivity of major biases in the atmosphere, ocean, and cryosphere to changes in atmosphere and ocean resolution. All configurations successfully reproduce the observed long-term trends in global mean surface temperature. Furthermore, following an adjustment to account for drift in the subsurface ocean, coupled configurations of ECMWF-IFS realistically reproduce observation-based estimates of ocean heat content change since 1950. Climatological surface biases in ECMWF-IFS are relatively insensitive to an increase in atmospheric resolution from ∼ 50 to ∼ 25\&thinsp;km. However, increasing the horizontal resolution of the atmosphere while maintaining the same vertical resolution enhances the magnitude of a cold bias in the lower stratosphere. In coupled configurations, there is a strong sensitivity to an increase in ocean model resolution from 1 to 0.25°. However, this sensitivity to ocean resolution takes many years to fully manifest and is less apparent in the first year of integration. This result has implications for the ECMWF coupled model development strategy that typically relies on the analysis of biases in short ( \&lt; 1 year) ensemble (re)forecast data sets. The impacts of increased ocean resolution are particularly evident in the North Atlantic and Arctic, where they are associated with an improved Atlantic meridional overturning circulation, increased meridional ocean heat transport, and more realistic sea-ice cover. In the tropical Pacific, increased ocean resolution is associated with improvements to the magnitude and asymmetry of El Niño–Southern Oscillation (ENSO) variability and better representation of non-linear sea surface temperature (SST)–radiation feedbacks during warm events. However, increased ocean model resolution also increases the magnitude of a warm bias in the Southern Ocean. Finally, there is tentative evidence that both ocean coupling and increased atmospheric resolution can improve teleconnections between tropical Pacific rainfall and geopotential height anomalies in the North Atlantic.},
	language = {English},
	number = {9},
	urldate = {2023-10-02},
	journal = {Geoscientific Model Development},
	author = {Roberts, Christopher D. and Senan, Retish and Molteni, Franco and Boussetta, Souhail and Mayer, Michael and Keeley, Sarah P. E.},
	month = sep,
	year = {2018},
	note = {Publisher: Copernicus GmbH},
	pages = {3681--3712},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/6ZZPQ7BU/Roberts et al. - 2018 - Climate model configurations of the ECMWF Integrat.pdf:application/pdf},
}

@article{hasselmann_stochastic_1976,
	title = {Stochastic climate models {Part} {I}. {Theory}},
	volume = {28},
	copyright = {1976 Blackwell Munksgaard},
	issn = {2153-3490},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2153-3490.1976.tb00696.x},
	doi = {10.1111/j.2153-3490.1976.tb00696.x},
	abstract = {A stochastic model of climate variability is considered in which slow changes of climate are explained as the integral response to continuous random excitation by short period “weather” disturbances. The coupled ocean-atmosphere-cryosphere-land system is divided into a rapidly varying “weather” system (essentially the atmosphere) and a slowly responding “climate” system (the ocean, cryosphere, land vegetation, etc.). In the usual Statistical Dynamical Model (SDM) only the average transport effects of the rapidly varying weather components are parameterised in the climate system. The resultant prognostic equations are deterministic, and climate variability can normally arise only through variable external conditions. The essential feature of stochastic climate models is that the non-averaged “weather” components are also retained. They appear formally as random forcing terms. The climate system, acting as an integrator of this short-period excitation, exhibits the same random-walk response characteristics as large particles interacting with an ensemble of much smaller particles in the analogous Brownian motion problem. The model predicts “red” variance spectra, in qualitative agreement with observations. The evolution of the climate probability distribution is described by a Fokker-Planck equation, in which the effect of the random weather excitation is represented by diffusion terms. Without stabilising feedback, the model predicts a continuous increase in climate variability, in analogy with the continuous, unbounded dispersion of particles in Brownian motion (or in a homogeneous turbulent fluid). Stabilising feedback yields a statistically stationary climate probability distribution. Feedback also results in a finite degree of climate predictability, but for a stationary climate the predictability is limited to maximal skill parameters of order 0.5.},
	language = {en},
	number = {6},
	urldate = {2023-10-03},
	journal = {Tellus},
	author = {Hasselmann, K.},
	year = {1976},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.2153-3490.1976.tb00696.x},
	pages = {473--485},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/2BSQXLXS/Hasselmann - 1976 - Stochastic climate models Part I. Theory.pdf:application/pdf;Snapshot:/Users/bobbyantonio/Zotero/storage/FR9C5BAT/j.2153-3490.1976.tb00696.html:text/html},
}

@article{neelin_enso_1998,
	title = {{ENSO} theory},
	volume = {103},
	copyright = {Copyright 1998 by the American Geophysical Union.},
	issn = {2156-2202},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/97JC03424},
	doi = {10.1029/97JC03424},
	abstract = {Beginning from the hypothesis by Bjerknes [1969] that ocean-atmosphere interaction was essential to the El Niño-Southern Oscillation (ENSO) phenomenon, the Tropical Ocean-Global Atmosphere (TOGA) decade has not only confirmed this but has supplied detailed theory for mechanisms setting the underlying period and possible mechanisms responsible for the irregularity of ENSO. Essentials of the theory of ocean dynamical adjustment are reviewed from an ENSO perspective. Approaches to simple atmospheric modeling greatly aided development of theory for ENSO atmospheric feedbacks but are critically reviewed for current stumbling blocks for applications beyond ENSO. ENSO theory has benefitted from an unusually complete hierarchy of coupled models of various levels of complexity. Most of the progress during the ENSO decade came from models of intermediate complexity, which are sufficiently detailed to compare to observations and to use in prediction but are less complex than coupled general circulation models. ENSO theory in simple models lagged behind ENSO simulation in intermediate models but has provided a useful role in uniting seemingly diverse viewpoints. The process of boiling ENSO theory down to a single consensus model of all aspects of the phenomenon is still a rapidly progressing area, and theoretical limits to ENSO predictability are still in debate, but a thorough foundation for the discussion has been established in the TOGA decade.},
	language = {en},
	number = {C7},
	urldate = {2023-10-03},
	journal = {Journal of Geophysical Research: Oceans},
	author = {Neelin, J. David and Battisti, David S. and Hirst, Anthony C. and Jin, Fei-Fei and Wakata, Yoshinobu and Yamagata, Toshio and Zebiak, Stephen E.},
	year = {1998},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/97JC03424},
	pages = {14261--14290},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/X7G9B2U7/Neelin et al. - 1998 - ENSO theory.pdf:application/pdf;Snapshot:/Users/bobbyantonio/Zotero/storage/ZMLKXWD6/97JC03424.html:text/html},
}

@article{eisenman_westerly_2005,
	title = {Westerly {Wind} {Bursts}: {ENSO}’s {Tail} {Rather} than the {Dog}?},
	volume = {18},
	issn = {0894-8755, 1520-0442},
	shorttitle = {Westerly {Wind} {Bursts}},
	url = {https://journals.ametsoc.org/view/journals/clim/18/24/jcli3588.1.xml},
	doi = {10.1175/JCLI3588.1},
	abstract = {Abstract Westerly wind bursts (WWBs) in the equatorial Pacific occur during the development of most El Niño events and are believed to be a major factor in ENSO’s dynamics. Because of their short time scale, WWBs are normally considered part of a stochastic forcing of ENSO, completely external to the interannual ENSO variability. Recent observational studies, however, suggest that the occurrence and characteristics of WWBs may depend to some extent on the state of ENSO components, implying that WWBs, which force ENSO, are modulated by ENSO itself. Satellite and in situ observations are used here to show that WWBs are significantly more likely to occur when the warm pool is extended eastward. Based on these observations, WWBs are added to an intermediate complexity coupled ocean–atmosphere ENSO model. The representation of WWBs is idealized such that their occurrence is modulated by the warm pool extent. The resulting model run is compared with a run in which the WWBs are stochastically applied. The modulation of WWBs by ENSO results in an enhancement of the slow frequency component of the WWBs. This causes the amplitude of ENSO events forced by modulated WWBs to be twice as large as the amplitude of ENSO events forced by stochastic WWBs with the same amplitude and average frequency. Based on this result, it is suggested that the modulation of WWBs by the equatorial Pacific SST is a critical element of ENSO’s dynamics, and that WWBs should not be regarded as purely stochastic forcing. In the paradigm proposed here, WWBs are still an important aspect of ENSO’s dynamics, but they are treated as being partially stochastic and partially affected by the large-scale ENSO dynamics, rather than being completely external to ENSO. It is further shown that WWB modulation by the large-scale equatorial SST field is roughly equivalent to an increase in the ocean–atmosphere coupling strength, making the coupled equatorial Pacific effectively self-sustained.},
	language = {EN},
	number = {24},
	urldate = {2023-10-03},
	journal = {Journal of Climate},
	author = {Eisenman, Ian and Yu, Lisan and Tziperman, Eli},
	month = dec,
	year = {2005},
	note = {Publisher: American Meteorological Society
Section: Journal of Climate},
	pages = {5224--5238},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/NH26QXXL/Eisenman et al. - 2005 - Westerly Wind Bursts ENSO’s Tail Rather than the .pdf:application/pdf},
}

@article{acosta_balancing_2023,
	title = {Balancing {EC}-{Earth3} {Improving} the {Performance} of {EC}-{Earth} {CMIP6} {Configurations} by {Minimizing} the {Coupling} {Cost}},
	volume = {10},
	copyright = {© 2023 The Authors.},
	issn = {2333-5084},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2023EA002912},
	doi = {10.1029/2023EA002912},
	abstract = {Earth System Models (ESMs) are complex systems used in weather and climate studies generally built from different independent components responsible for simulating a specific realm (ocean, atmosphere, biosphere, etc.). To replicate the interactions between these processes, ESMs typically use coupling libraries that manage the synchronization and field exchanges between the individual components, which run in parallel as a Multi-Program, Multiple-Data application. As ESMs get more complex (increase in resolution, number of components, configurations, etc.), achieving the best performance when running in High-performance Computing platforms has become increasingly challenging and of major concern. One of the critical bottlenecks is the load-imbalance, where the fastest components will have to wait for the slower ones. Finding the optimal number of processing elements to assign to each of the multiple independent constituents to minimize the performance loss due to synchronizations and maximize the overall parallel efficiency is impossible without the right performance metrics, methodology, and tools. This paper presents the results of balancing multiple Coupled Model Intercomparison Project phase 6 configurations for the EC-Earth3 ESM. We will show that intuitive approaches can lead to suboptimal resource allocations and propose new setups up to 25\% fasters while reducing the computational cost by 72\%. We prove that new methods are needed to deal with the load-balance of ESMs and hope that our study will serve as a guide to optimize any other coupled system.},
	language = {en},
	number = {8},
	urldate = {2023-10-03},
	journal = {Earth and Space Science},
	author = {Acosta, M. C. and Palomas, S. and Tourigny, E.},
	year = {2023},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/2023EA002912},
	keywords = {CMIP6, EC-Earth, ESMs, HPC, performance},
	pages = {e2023EA002912},
	annote = {e2023EA002912 2023EA002912},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/W7PZ8S98/Acosta et al. - 2023 - Balancing EC-Earth3 Improving the Performance of E.pdf:application/pdf;Snapshot:/Users/bobbyantonio/Zotero/storage/P3AMR8P2/2023EA002912.html:text/html},
}

@article{franzke_stochastic_2022,
	title = {Stochastic {Methods} and {Complexity} {Science} in {Climate} {Research} and {Modeling}},
	volume = {10},
	issn = {2296-424X},
	url = {https://www.frontiersin.org/articles/10.3389/fphy.2022.931596},
	abstract = {The 2021 Nobel prize for physics was awarded to two climate scientists, Syukuro Manabe and Klaus Hasselmann, and the physicist Giorgio Parisi. While at first sight the work of Parisi seems not to be related to climate science, this is not the case. Giorgio Parisi developed and contributed to many complexity science methods which are nowadays widely used in climate science. Giorgi Parisi also was involved in the development of the “stochastic resonance” idea to explain paleoclimate variability, while Klaus Hasselmann developed stochastic climate models. Here we review and discuss their work from a complex and stochastic systems perspective in order to highlight those aspects of their work. For instance, fractal and multi-fractal analysis of climate data is now widely used and many weather prediction and climate models contain stochastic parameterizations, topics Parisi and Hasselmann have pioneered. Furthermore, Manabe’s work was key to understanding the effects of anthropogenic climate change by the development of key advances in the parameterization of convection and radiative forcing in climate models. We discuss also how their inventive research has shaped current climate research and is still influencing climate modeling and future research directions.},
	urldate = {2023-10-04},
	journal = {Frontiers in Physics},
	author = {Franzke, Christian L. E. and Blender, Richard and O’Kane, Terence J. and Lembo, Valerio},
	year = {2022},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/Y2PCH5Z7/Franzke et al. - 2022 - Stochastic Methods and Complexity Science in Clima.pdf:application/pdf},
}

@article{muzy_multifractal_1993,
	title = {Multifractal formalism for fractal signals: {The} structure-function approach versus the wavelet-transform modulus-maxima method},
	volume = {47},
	issn = {1063-651X, 1095-3787},
	shorttitle = {Multifractal formalism for fractal signals},
	url = {https://link.aps.org/doi/10.1103/PhysRevE.47.875},
	doi = {10.1103/PhysRevE.47.875},
	language = {en},
	number = {2},
	urldate = {2023-10-04},
	journal = {Physical Review E},
	author = {Muzy, J. F. and Bacry, E. and Arneodo, A.},
	month = feb,
	year = {1993},
	pages = {875--884},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/WBVJWWK8/Muzy et al. - 1993 - Multifractal formalism for fractal signals The st.pdf:application/pdf},
}

@misc{hakim_dynamical_2023,
	title = {Dynamical {Tests} of a {Deep}-{Learning} {Weather} {Prediction} {Model}},
	url = {http://arxiv.org/abs/2309.10867},
	abstract = {Global deep-learning weather prediction models have recently been shown to produce forecasts that rival those from physics-based models run at operational centers. It is unclear whether these models have encoded atmospheric dynamics, or simply pattern matching that produces the smallest forecast error. Answering this question is crucial to establishing the utility of these models as tools for basic science. Here we subject one such model, Pangu-weather, to a set of four classical dynamical experiments that do not resemble the model training data. Localized perturbations to the model output and the initial conditions are added to steady time-averaged conditions, to assess the propagation speed and structural evolution of signals away from the local source. Perturbing the model physics by adding a steady tropical heat source results in a classical Matsuno--Gill response near the heating, and planetary waves that radiate into the extratropics. A localized disturbance on the winter-averaged North Pacific jet stream produces realistic extratropical cyclones and fronts, including the spontaneous emergence of polar lows. Perturbing the 500hPa height field alone yields adjustment from a state of rest to one of wind--pressure balance over {\textasciitilde}6 hours. Localized subtropical low pressure systems produce Atlantic hurricanes, provided the initial amplitude exceeds about 5 hPa, and setting the initial humidity to zero eliminates hurricane development. We conclude that the model encodes realistic physics in all experiments, and suggest it can be used as a tool for rapidly testing ideas before using expensive physics-based models.},
	urldate = {2023-10-04},
	publisher = {arXiv},
	author = {Hakim, Gregory J. and Masanam, Sanjit},
	month = sep,
	year = {2023},
	note = {arXiv:2309.10867 [physics]},
	keywords = {Computer Science - Machine Learning, Physics - Atmospheric and Oceanic Physics},
	file = {arXiv.org Snapshot:/Users/bobbyantonio/Zotero/storage/PVQX2XPV/2309.html:text/html;Full Text PDF:/Users/bobbyantonio/Zotero/storage/J3ZYB64C/Hakim and Masanam - 2023 - Dynamical Tests of a Deep-Learning Weather Predict.pdf:application/pdf},
}

@article{madec_nemo_2023,
	title = {{NEMO} {Ocean} {Engine} {Reference} {Manual}},
	url = {https://zenodo.org/record/8167700},
	doi = {10.5281/zenodo.8167700},
	abstract = {The ocean engine of NEMO is a primitive equation model adapted to regional and global ocean circulation problems. It is intended to be a flexible tool for studying the ocean and its interactions with the others components of the earth climate system over a wide range of space and time scales. To cite this edition: Madec, G. and the NEMO System Team, 2023. NEMO Ocean Engine Reference Manual, Zenodo, https://doi.org/10.5281/zenodo.8167700},
	language = {eng},
	urldate = {2023-10-04},
	author = {Madec, Gurvan and Bell, Mike and Blaker, Adam and Bricaud, Clément and Bruciaferri, Diego and Castrillo, Miguel and Calvert, Daley and Chanut, Jérômeme and Clementi, Emanuela and Coward, Andrew and Epicoco, Italo and Éthé, Christian and Ganderton, Jonas and Harle, James and Hutchinson, Katherine and Iovino, Doroteaciro and Lea, Dan and Lovato, Tomas and Martin, Matt and Martin, Nicolas and Mele, Francesca and Martins, Diana and Masson, Sébastien and Mathiot, Pierre and Mele, Francesca and Mocavero, Silvia and Müller, Simon and Nurser, A. J. George and Paronuzzi, Stella and Peltier, Mathieu and Person, Renaud and Rousset, Clement and Rynders, Stefanie and Samson, Guillaume and Téchené, Sibylle and Vancoppenolle, Martin and Wilson, Chris},
	month = jul,
	year = {2023},
	note = {Publisher: Zenodo},
	keywords = {modelling, nemo-ocean, ocean, ocean-modelling},
	file = {Zenodo Full Text PDF:/Users/bobbyantonio/Zotero/storage/XKRJJ6PI/Madec et al. - 2023 - NEMO Ocean Engine Reference Manual.pdf:application/pdf},
}

@article{hasselmann_pips_1988,
	title = {{PIPs} and {POPs}: {The} reduction of complex dynamical systems using principal interaction and oscillation patterns},
	volume = {93},
	copyright = {Copyright 1988 by the American Geophysical Union.},
	issn = {2156-2202},
	shorttitle = {{PIPs} and {POPs}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/JD093iD09p11015},
	doi = {10.1029/JD093iD09p11015},
	abstract = {A general method is described for constructing simple dynamical models to approximate complex dynamical systems with many degrees of freedom. The technique can be applied to interpret sets of observed time series or numerical simulations with high-resolution models, or to relate observation and simulations. The method is based on a projection of the complete system on to a smaller number of “principal interaction patterns” (PIPs). The coefficients of the PIP expansion are assumed to be governed by a dynamic model containing a small number of adjustable parameters. The optimization of the dynamical model, which in the general case can be both nonlinear and time-dependent, is carried out simultaneously with the construction of the optimal set of interaction patterns. In the linear case the PIPs reduce to the eigenoscilations of a first-order linear vector process with stochastic forcing (principal oscillation patterns, or POPs). POPs are linearly related to the “principal prediction patterns” used in linear forecasting applications. The POP analysis can also be applied as a diagnostic tool to compress the extensive information contained in the high-dimensional cross-spectral covariance matrix representing the complete second-moment structure of the system.},
	language = {en},
	number = {D9},
	urldate = {2023-10-04},
	journal = {Journal of Geophysical Research: Atmospheres},
	author = {Hasselmann, K.},
	year = {1988},
	note = {\_eprint: https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/JD093iD09p11015},
	pages = {11015--11021},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/J66UPS7N/Hasselmann - 1988 - PIPs and POPs The reduction of complex dynamical .pdf:application/pdf;Snapshot:/Users/bobbyantonio/Zotero/storage/V72MZIDR/JD093iD09p11015.html:text/html},
}

@article{clement_atlantic_2015,
	title = {The {Atlantic} {Multidecadal} {Oscillation} without a role for ocean circulation},
	volume = {350},
	issn = {0036-8075, 1095-9203},
	url = {https://www.science.org/doi/10.1126/science.aab3980},
	doi = {10.1126/science.aab3980},
	abstract = {Ocean circulation changes not needed
            
              What causes the pattern of sea surface temperature change that is seen in the North Atlantic Ocean? This naturally occurring quasi-cyclical variation, known as the Atlantic Multidecadal Oscillation (AMO), affects weather and climate. Some have suggested that the AMO is a consequence of variable large-scale ocean circulation. Clement
              et al.
              suggest otherwise. They find that the pattern of AMO variability can be produced in a model that does not include ocean circulation changes, but only the effects of changes in air temperatures and winds.
            
            
              Science
              , this issue p.
              320
            
          , 
            The Atlantic Multidecadal Oscillation does not depend on variable whole-ocean circulation.
          , 
            The Atlantic Multidecadal Oscillation (AMO) is a major mode of climate variability with important societal impacts. Most previous explanations identify the driver of the AMO as the ocean circulation, specifically the Atlantic Meridional Overturning Circulation (AMOC). Here we show that the main features of the observed AMO are reproduced in models where the ocean heat transport is prescribed and thus cannot be the driver. Allowing the ocean circulation to interact with the atmosphere does not significantly alter the characteristics of the AMO in the current generation of climate models. These results suggest that the AMO is the response to stochastic forcing from the mid-latitude atmospheric circulation, with thermal coupling playing a role in the tropics. In this view, the AMOC and other ocean circulation changes would be largely a response to, not a cause of, the AMO.},
	language = {en},
	number = {6258},
	urldate = {2023-10-04},
	journal = {Science},
	author = {Clement, Amy and Bellomo, Katinka and Murphy, Lisa N. and Cane, Mark A. and Mauritsen, Thorsten and Rädel, Gaby and Stevens, Bjorn},
	month = oct,
	year = {2015},
	pages = {320--324},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/TSX5NQ8Z/Clement et al. - 2015 - The Atlantic Multidecadal Oscillation without a ro.pdf:application/pdf},
}

@incollection{imkeller_hasselmanns_2001,
	address = {Basel},
	title = {Hasselmann’s program revisited: the analysis of stochasticity in deterministic climate models},
	isbn = {978-3-0348-9504-0 978-3-0348-8287-3},
	shorttitle = {Hasselmann’s program revisited},
	url = {http://link.springer.com/10.1007/978-3-0348-8287-3_5},
	abstract = {In his seminal 1976 paper on {\textbackslash}Stochastic Climate Models", K. Hasselmann proposed to improve deterministic models for the {\textbackslash}climate" (slow variables) by incorporating the in uence of the {\textbackslash}weather" (fast variables) in the form of random noise.},
	language = {en},
	urldate = {2023-10-05},
	booktitle = {Stochastic {Climate} {Models}},
	publisher = {Birkhäuser Basel},
	author = {Arnold, Ludwig},
	editor = {Imkeller, Peter and Von Storch, Jin-Song},
	year = {2001},
	doi = {10.1007/978-3-0348-8287-3_5},
	pages = {141--157},
	file = {Arnold - 2001 - Hasselmann’s program revisited the analysis of st.pdf:/Users/bobbyantonio/Zotero/storage/HVAM56AX/Arnold - 2001 - Hasselmann’s program revisited the analysis of st.pdf:application/pdf},
}

@article{arcomano_hybrid_2023,
	title = {A {Hybrid} {Atmospheric} {Model} {Incorporating} {Machine} {Learning} {Can} {Capture} {Dynamical} {Processes} {Not} {Captured} by {Its} {Physics}-{Based} {Component}},
	volume = {50},
	copyright = {© 2023 The Authors.},
	issn = {1944-8007},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2022GL102649},
	doi = {10.1029/2022GL102649},
	abstract = {It is shown that a recently developed hybrid modeling approach that combines machine learning (ML) with an atmospheric global circulation model (AGCM) can serve as a basis for capturing atmospheric processes not captured by the AGCM. This power of the approach is illustrated by three examples from a decades-long climate simulation experiment. The first example demonstrates that the hybrid model can produce sudden stratospheric warming, a dynamical process of nature not resolved by the low resolution AGCM component of the hybrid model. The second and third example show that introducing 6-hr cumulative precipitation and sea surface temperature (SST) as ML-based prognostic variables improves the precipitation climatology and leads to a realistic ENSO signal in the SST and atmospheric surface pressure.},
	language = {en},
	number = {8},
	urldate = {2023-10-06},
	journal = {Geophysical Research Letters},
	author = {Arcomano, Troy and Szunyogh, Istvan and Wikner, Alexander and Hunt, Brian R. and Ott, Edward},
	year = {2023},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/2022GL102649},
	keywords = {machine learning, climate, numerical weather prediction},
	pages = {e2022GL102649},
	annote = {e2022GL102649 2022GL102649},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/S3H7383C/Arcomano et al. - 2023 - A Hybrid Atmospheric Model Incorporating Machine L.pdf:application/pdf;Snapshot:/Users/bobbyantonio/Zotero/storage/5HYFNKTV/2022GL102649.html:text/html},
}

@misc{mangeleer_robust_2023,
	title = {Robust {Ocean} {Subgrid}-{Scale} {Parameterizations} {Using} {Fourier} {Neural} {Operators}},
	url = {http://arxiv.org/abs/2310.02691},
	doi = {10.48550/arXiv.2310.02691},
	abstract = {In climate simulations, small-scale processes shape ocean dynamics but remain computationally expensive to resolve directly. For this reason, their contributions are commonly approximated using empirical parameterizations, which lead to significant errors in long-term projections. In this work, we develop parameterizations based on Fourier Neural Operators, showcasing their accuracy and generalizability in comparison to other approaches. Finally, we discuss the potential and limitations of neural networks operating in the frequency domain, paving the way for future investigation.},
	urldate = {2023-10-06},
	publisher = {arXiv},
	author = {Mangeleer, Victor and Louppe, Gilles},
	month = oct,
	year = {2023},
	note = {arXiv:2310.02691 [physics]},
	keywords = {Computer Science - Machine Learning, Physics - Atmospheric and Oceanic Physics},
	file = {arXiv Fulltext PDF:/Users/bobbyantonio/Zotero/storage/6RC68LWF/Mangeleer and Louppe - 2023 - Robust Ocean Subgrid-Scale Parameterizations Using.pdf:application/pdf;arXiv.org Snapshot:/Users/bobbyantonio/Zotero/storage/DBJIU8YU/2310.html:text/html},
}

@misc{mardani_generative_2023,
	title = {Generative {Residual} {Diffusion} {Modeling} for {Km}-scale {Atmospheric} {Downscaling}},
	url = {http://arxiv.org/abs/2309.15214},
	doi = {10.48550/arXiv.2309.15214},
	abstract = {The state of the art for physical hazard prediction from weather and climate requires expensive km-scale numerical simulations driven by coarser resolution global inputs. Here, a km-scale downscaling diffusion model is presented as a cost effective alternative. The model is trained from a regional high-resolution weather model over Taiwan, and conditioned on ERA5 reanalysis data. To address the downscaling uncertainties, large resolution ratios (25km to 2km), different physics involved at different scales and predict channels that are not in the input data, we employ a two-step approach ({\textbackslash}textit\{ResDiff\}) where a (UNet) regression predicts the mean in the first step and a diffusion model predicts the residual in the second step. {\textbackslash}textit\{ResDiff\} exhibits encouraging skill in bulk RMSE and CRPS scores. The predicted spectra and distributions from ResDiff faithfully recover important power law relationships regulating damaging wind and rain extremes. Case studies of coherent weather phenomena reveal appropriate multivariate relationships reminiscent of learnt physics. This includes the sharp wind and temperature variations that co-locate with intense rainfall in a cold front, and the extreme winds and rainfall bands that surround the eyewall of typhoons. Some evidence of simultaneous bias correction is found. A first attempt at downscaling directly from an operational global forecast model successfully retains many of these benefits. The implication is that a new era of fully end-to-end, global-to-regional machine learning weather prediction is likely near at hand.},
	urldate = {2023-10-06},
	publisher = {arXiv},
	author = {Mardani, Morteza and Brenowitz, Noah and Cohen, Yair and Pathak, Jaideep and Chen, Chieh-Yu and Liu, Cheng-Chin and Vahdat, Arash and Kashinath, Karthik and Kautz, Jan and Pritchard, Mike},
	month = sep,
	year = {2023},
	note = {arXiv:2309.15214 [physics]},
	keywords = {Computer Science - Machine Learning, Physics - Atmospheric and Oceanic Physics},
	file = {arXiv Fulltext PDF:/Users/bobbyantonio/Zotero/storage/D2FVKLYG/Mardani et al. - 2023 - Generative Residual Diffusion Modeling for Km-scal.pdf:application/pdf;arXiv.org Snapshot:/Users/bobbyantonio/Zotero/storage/DNQ3YQJE/2309.html:text/html},
}

@misc{kristian_mogensen_coupling_2012,
	type = {text},
	title = {Coupling of the {NEMO} and {IFS} models in a single executable},
	url = {https://www.ecmwf.int/en/elibrary/75709-coupling-nemo-and-ifs-models-single-executable},
	abstract = {A new way of coupling the Integrated Forecasting System (IFS) atmosphere model and the Nucleus for European Modelling of the Ocean (NEMO) ocean model based on an integrated single executable system with a common time step loop is presented. Details of the technical implementation are presented to give a fairly complete overview of how the IFS and the NEMO models interact in the single executable system. Initial technical performance testing is showing similar or better performance than the existing OASIS3 based system and potential for coupling at high resolution. Some potential improvements to the new system is discussed.},
	language = {eng},
	urldate = {2023-10-09},
	journal = {ECMWF},
	author = {Kristian Mogensen, Sarah Keeley},
	year = {2012},
	file = {Kristian Mogensen - 2012 - Coupling of the NEMO and IFS models in a single ex.pdf:/Users/bobbyantonio/Zotero/storage/82J767QY/Kristian Mogensen - 2012 - Coupling of the NEMO and IFS models in a single ex.pdf:application/pdf;Snapshot:/Users/bobbyantonio/Zotero/storage/C7855IU6/75709-coupling-nemo-and-ifs-models-single-executable.html:text/html},
}

@article{vallis_mechanisms_nodate,
	title = {Mechanisms of {Climate} {Variability} from {Years} to {Decades}},
	abstract = {This paper discusses and reviews some of the mechanisms that may be responsible for climate variability on yearly to decadal timescales. The discussion is organized around a set of mechanisms that primarily involve the atmosphere, the ocean, or the coupling between the two. We choose an example of each, try to explain what the underlying mechanism is, and set it in the context of climate variability as a whole. All of the mechanisms are in principle deterministic, although in at least one of them we do not care about the details of the process that give rise to the variability and in that case a stochastic description may be the most economical and insightful.},
	language = {en},
	author = {Vallis, Geoffrey K},
	file = {Vallis - Mechanisms of Climate Variability from Years to De.pdf:/Users/bobbyantonio/Zotero/storage/7YKVFXAN/Vallis - Mechanisms of Climate Variability from Years to De.pdf:application/pdf},
}

@incollection{chen_nino_2019,
	title = {El {Niño} and the {Southern} {Oscillation}: {Theory}},
	isbn = {978-0-12-409548-9},
	shorttitle = {El {Niño} and the {Southern} {Oscillation}},
	url = {https://www.sciencedirect.com/science/article/pii/B9780124095489117658},
	abstract = {The El Niño Southern Oscillation (ENSO) is the most prominent interannual climate variation on Earth with large ecological and societal impacts. The ENSO results from a strong dynamical coupling between the equatorial Pacific ocean and the overlying atmosphere. This article discusses the ENSO phenomenon and the theory for its existence. A hierarchy of ENSO models, from simple linear oscillators to intermediate models and from deterministic to stochastic ones, are summarized to describe the ENSO features. These models are also utilized to emphasize the triggers, inhibitors, and nonlinearities in the ENSO. In addition, the ENSO involves various remarkable multiscale and nonlinear features that greatly increase its overall spatial and temporal complexity. The theories of ENSO asymmetry, seasonality and diversity are also discussed in this article.},
	urldate = {2023-10-09},
	booktitle = {Reference {Module} in {Earth} {Systems} and {Environmental} {Sciences}},
	publisher = {Elsevier},
	author = {Chen, Nan and Thual, Sulian and Stuecker, Malte F.},
	month = jan,
	year = {2019},
	doi = {10.1016/B978-0-12-409548-9.11765-8},
	keywords = {ENSO, Bjerknes feedback, Central Pacific (CP) El Niño, Discharge-recharge oscillator model, ENSO asymmetry, ENSO diversity, Niño index, Seasonal synchronization, Wind bursts, Zebiak-Cane model, Zonal advection},
	file = {ScienceDirect Snapshot:/Users/bobbyantonio/Zotero/storage/UPXDP2MU/B9780124095489117658.html:text/html},
}

@article{penland_modelling_2008,
	title = {On modelling physical systems with stochastic models: diffusion versus {Lévy} processes},
	volume = {366},
	shorttitle = {On modelling physical systems with stochastic models},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2008.0051},
	doi = {10.1098/rsta.2008.0051},
	abstract = {Stochastic descriptions of multiscale interactions are more and more frequently found in numerical models of weather and climate. These descriptions are often made in terms of differential equations with random forcing components. In this article, we review the basic properties of stochastic differential equations driven by classical Gaussian white noise and compare with systems described by stable Lévy processes. We also discuss aspects of numerically generating these processes.},
	number = {1875},
	urldate = {2023-10-09},
	journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Penland, Cécile and Ewald, Brian D},
	month = may,
	year = {2008},
	note = {Publisher: Royal Society},
	keywords = {Gaussian processes, Lévy processes, numerical methods, stochastic differential equations},
	pages = {2455--2474},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/IU9IDVP7/Penland and Ewald - 2008 - On modelling physical systems with stochastic mode.pdf:application/pdf},
}

@article{evans_introduction_nodate,
	title = {{AN} {INTRODUCTION} {TO} {STOCHASTIC} {DIFFERENTIAL} {EQUATIONS} {VERSION} 1.2},
	language = {en},
	author = {Evans, Lawrence C},
	file = {Evans - AN INTRODUCTION TO STOCHASTIC DIFFERENTIAL EQUATIO.pdf:/Users/bobbyantonio/Zotero/storage/NZ7I5KSF/Evans - AN INTRODUCTION TO STOCHASTIC DIFFERENTIAL EQUATIO.pdf:application/pdf},
}

@book{sarkka_applied_2019,
	edition = {1},
	title = {Applied {Stochastic} {Differential} {Equations}},
	isbn = {978-1-108-18673-5 978-1-316-51008-7 978-1-316-64946-6},
	url = {https://www.cambridge.org/core/product/identifier/9781108186735/type/book},
	language = {en},
	urldate = {2023-10-10},
	publisher = {Cambridge University Press},
	author = {Särkkä, Simo and Solin, Arno},
	month = apr,
	year = {2019},
	doi = {10.1017/9781108186735},
	file = {Särkkä and Solin - 2019 - Applied Stochastic Differential Equations. 2 Some.pdf:/Users/bobbyantonio/Zotero/storage/365QQGGA/Särkkä and Solin - 2019 - Applied Stochastic Differential Equations. 2 Some.pdf:application/pdf;Särkkä and Solin - 2019 - Applied Stochastic Differential Equations. 3 Prag.pdf:/Users/bobbyantonio/Zotero/storage/4IJDLI3E/Särkkä and Solin - 2019 - Applied Stochastic Differential Equations. 3 Prag.pdf:application/pdf;Särkkä and Solin - 2019 - Applied Stochastic Differential Equations. 4 Itô .pdf:/Users/bobbyantonio/Zotero/storage/SHC9K74V/Särkkä and Solin - 2019 - Applied Stochastic Differential Equations. 4 Itô .pdf:application/pdf;Särkkä and Solin - 2019 - Applied Stochastic Differential Equations. 5 Prob.pdf:/Users/bobbyantonio/Zotero/storage/D3GPS3MY/Särkkä and Solin - 2019 - Applied Stochastic Differential Equations. 5 Prob.pdf:application/pdf;Särkkä and Solin - 2019 - Applied Stochastic Differential Equations. 6 Stat.pdf:/Users/bobbyantonio/Zotero/storage/ZEUCK3L3/Särkkä and Solin - 2019 - Applied Stochastic Differential Equations. 6 Stat.pdf:application/pdf},
}

@article{noauthor_technical_nodate,
	title = {Technical {Memorandum}},
	abstract = {This paper discusses the development and evaluation process followed at ECMWF to upgrade the Integrated Forecasting System (IFS), and illustrates how potential changes, developed and tested by individual scientists, are gradually merged and evaluated prior to their acceptance into the next version of the ECMWF IFS.},
	language = {en},
	file = {Technical Memorandum.pdf:/Users/bobbyantonio/Zotero/storage/SDUXF7G6/Technical Memorandum.pdf:application/pdf},
}

@article{cooper_potential_2017,
	title = {A potential method to accelerate spin up of turbulent ocean models},
	volume = {120},
	issn = {1463-5003},
	url = {https://www.sciencedirect.com/science/article/pii/S1463500317301531},
	doi = {10.1016/j.ocemod.2017.10.008},
	abstract = {We demonstrate a simple method to quickly spin up (equilibrate) the temperature field of a turbulent idealised primitive equation ocean gyre model. We make use of the assumption that both velocity fields and non-linear eddy advection terms equilibrate on a shorter timescale than tracer fields.},
	urldate = {2023-10-17},
	journal = {Ocean Modelling},
	author = {Cooper, Fenwick C.},
	month = dec,
	year = {2017},
	keywords = {Temperature, Equilibrate, Primitive equations, Spin-up, Tracer},
	pages = {79--82},
	file = {ScienceDirect Full Text PDF:/Users/bobbyantonio/Zotero/storage/S5ZPB7SY/Cooper - 2017 - A potential method to accelerate spin up of turbul.pdf:application/pdf;ScienceDirect Snapshot:/Users/bobbyantonio/Zotero/storage/9H4VWWX5/S1463500317301531.html:text/html},
}

@misc{ecmwf_ifs_2023,
	type = {text},
	title = {{IFS} {Documentation} {CY48R1} - {Part} {IV}: {Physical} {Processes}},
	shorttitle = {{IFS} {Documentation} {CY48R1} - {Part} {IV}},
	url = {https://www.ecmwf.int/en/elibrary/81370-ifs-documentation-cy48r1-part-iv-physical-processes},
	abstract = {Chapter 1 Overview Chapter 2 Radiation Chapter 3 Turbulent transport and interactions with the surface Chapter 4 Subgrid-scale orographic drag Chapter 5 Non-orographic gravity wave drag Chapter 6 Convection Chapter 7 Clouds and large-scale precipitation Chapter 8 Surface parametrization Chapter 9 Methane oxidation Chapter 10 Ozone chemistry parametrization Chapter 11 Climatological data Chapter 12 Basic physical constants and thermodynamic functions},
	language = {en},
	urldate = {2023-10-19},
	journal = {ECMWF},
	author = {ECMWF},
	year = {2023},
	file = {ECMWF - 2023 - IFS Documentation CY48R1 - Part IV Physical Proce.pdf:/Users/bobbyantonio/Zotero/storage/V2TZUE3L/ECMWF - 2023 - IFS Documentation CY48R1 - Part IV Physical Proce.pdf:application/pdf;Snapshot:/Users/bobbyantonio/Zotero/storage/KSCUE7X4/81370-ifs-documentation-cy48r1-part-iv-physical-processes.html:text/html},
}

@article{pelletier_two-sided_2021,
	title = {Two-sided turbulent surface-layer parameterizations for computing air–sea fluxes},
	volume = {147},
	copyright = {© 2021 Royal Meteorological Society},
	issn = {1477-870X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/qj.3991},
	doi = {10.1002/qj.3991},
	abstract = {Standard methods for determining air–sea fluxes typically rely on bulk algorithms set in the frame of Monin–Obukhov similarity theory (MOST), using ocean surface fields and atmosphere near-surface fields. In the context of coupled ocean–atmosphere simulations, the shallowest ocean vertical level is usually used as bulk input and, by default, the turbulent closure is one-sided: it extrapolates atmosphere near-surface solution profiles (for wind speed, temperature, and humidity) to the prescribed ocean surface values. Using near-surface ocean fields as surface ones is equivalent to considering that, in the ocean surface layer, solution profiles are constant instead of also being determined by turbulent closure. Here we introduce a method for extending existing turbulent parameterizations to a two-sided framework by explicitly including the ocean surface layer within the aforementioned parameterizations. The formalism we use for this method is derived from that of classical turbulent closures, so that our novelties can easily be implemented within existing formulations. Special care is taken to ensure the smoothness of the resulting solution profiles. Other physical phenomena, such as the penetration of radiative fluxes in the ocean and the formation of waves, are then included within our formalism, and their effects are assessed. We also investigate the impact of such two-sided bulk formulations on air–sea fluxes evaluated from a setting similar to those of coupled ocean–atmosphere simulations.},
	language = {en},
	number = {736},
	urldate = {2023-10-19},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Pelletier, Charles and Lemarié, Florian and Blayo, Eric and Bouin, Marie-Noëlle and Redelsperger, Jean-Luc},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/qj.3991},
	keywords = {numerical methods, air–sea fluxes, bulk formulae, ocean surface layer, ocean–atmosphere coupling, turbulent parameterizations},
	pages = {1726--1751},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/K5UBMKRI/Pelletier et al. - 2021 - Two-sided turbulent surface-layer parameterization.pdf:application/pdf;Snapshot:/Users/bobbyantonio/Zotero/storage/JQWH9CA9/qj.html:text/html},
}

@article{deardorff_parameterization_1972,
	title = {Parameterization of the {Planetary} {Boundary} layer for {Use} in {General} {Circulation} {Models}},
	volume = {100},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/100/2/1520-0493_1972_100_0093_potpbl_2_3_co_2.xml},
	doi = {10.1175/1520-0493(1972)100<0093:POTPBL>2.3.CO;2},
	abstract = {Abstract The surface stress and fluxes of heat and moisture are parameterized for use in numerical models of the general circulation of the atmosphere. The parameterization is designed to be consistent with recent advances in knowledge of both the planetary boundary layer and the surface layer. A key quantity throughout is the height, h, of the planetary boundary layer, which appears in the governing stability parameter, a bulk Richardson number. With upward heat flux, a time-dependent prediction equation is proposed for h that incorporates penetrative convection and vertical motion. Under stable conditions, h is assumed to depart from the neutral value and to become nearly proportional to the Monin-Obukhov length. The roughness length, Zo, is incorporated in the combination h/zo, and the parameterization is consistent with h/zo affecting only the wind component in the direction of the surface velocity. The direction of the surface wind and stress is derived in a manner consistent with the known value of the surface pressure gradient and theoretical studies of the decrease of stress with height. The parameterization has been tested numerically and appears to be efficient enough to use in existing general circulation models.},
	language = {EN},
	number = {2},
	urldate = {2023-10-19},
	journal = {Monthly Weather Review},
	author = {Deardorff, James W.},
	month = feb,
	year = {1972},
	note = {Publisher: American Meteorological Society
Section: Monthly Weather Review},
	pages = {93--106},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/6CKBIAQ4/Deardorff - 1972 - Parameterization of the Planetary Boundary layer f.pdf:application/pdf},
}

@misc{necker_fractions_2023,
	type = {preprint},
	title = {The fractions skill score for ensemble forecast verification},
	url = {https://www.authorea.com/users/650600/articles/659203-the-fractions-skill-score-for-ensemble-forecast-verification?commit=4bd54abb355e822fcb037ae51b827124fe7eb606},
	abstract = {The Fractions Skill Score (FSS) is a neighbourhood veriﬁcation method originally designed to verify deterministic forecasts of binary events. Previous studies employed diﬀerent approaches to computing an ensemble-based FSS for probabilistic forecast veriﬁcation. We show that the formulation of the ensemble-based FSS substantially aﬀects veriﬁcation results. Comparing four diﬀerent approaches, we determine how the ensemble-based FSS depends on ensemble size, neighbourhood size, and frequency of occurrence of the forecast event. Furthermore, we derive an empirical formula for the expected dependence of the FSS on ensemble size. Our results are based on high-resolution 1000-member ensemble precipitation forecasts over Germany for a high-impact weather period. The large ensemble enables us to study the inﬂuence of ensemble size on forecast skill in terms of a probabilistic skilful spatial scale. We demonstrate that only one form of ensemble-based FSS, which we refer to as probabilistic FSS, is well-behaved and exhibits a reasonable dependence on ensemble size.},
	language = {en},
	urldate = {2023-10-19},
	publisher = {Preprints},
	author = {Necker, Tobias and Wolfgruber, Ludwig and Kugler, Lukas and Weissmann, Martin and Dorninger, Manfred and Serafin, Stefano},
	month = aug,
	year = {2023},
	note = {Authorea},
	file = {Necker et al. - 2023 - The fractions skill score for ensemble forecast ve.pdf:/Users/bobbyantonio/Zotero/storage/KYDJS2WR/Necker et al. - 2023 - The fractions skill score for ensemble forecast ve.pdf:application/pdf},
}

@misc{pathak_fourcastnet_2022,
	title = {{FourCastNet}: {A} {Global} {Data}-driven {High}-resolution {Weather} {Model} using {Adaptive} {Fourier} {Neural} {Operators}},
	shorttitle = {{FourCastNet}},
	url = {http://arxiv.org/abs/2202.11214},
	doi = {10.48550/arXiv.2202.11214},
	abstract = {FourCastNet, short for Fourier Forecasting Neural Network, is a global data-driven weather forecasting model that provides accurate short to medium-range global predictions at \$0.25{\textasciicircum}\{{\textbackslash}circ\}\$ resolution. FourCastNet accurately forecasts high-resolution, fast-timescale variables such as the surface wind speed, precipitation, and atmospheric water vapor. It has important implications for planning wind energy resources, predicting extreme weather events such as tropical cyclones, extra-tropical cyclones, and atmospheric rivers. FourCastNet matches the forecasting accuracy of the ECMWF Integrated Forecasting System (IFS), a state-of-the-art Numerical Weather Prediction (NWP) model, at short lead times for large-scale variables, while outperforming IFS for variables with complex fine-scale structure, including precipitation. FourCastNet generates a week-long forecast in less than 2 seconds, orders of magnitude faster than IFS. The speed of FourCastNet enables the creation of rapid and inexpensive large-ensemble forecasts with thousands of ensemble-members for improving probabilistic forecasting. We discuss how data-driven deep learning models such as FourCastNet are a valuable addition to the meteorology toolkit to aid and augment NWP models.},
	urldate = {2023-10-19},
	publisher = {arXiv},
	author = {Pathak, Jaideep and Subramanian, Shashank and Harrington, Peter and Raja, Sanjeev and Chattopadhyay, Ashesh and Mardani, Morteza and Kurth, Thorsten and Hall, David and Li, Zongyi and Azizzadenesheli, Kamyar and Hassanzadeh, Pedram and Kashinath, Karthik and Anandkumar, Animashree},
	month = feb,
	year = {2022},
	note = {arXiv:2202.11214 [physics]},
	keywords = {Computer Science - Machine Learning, Physics - Atmospheric and Oceanic Physics},
	file = {arXiv Fulltext PDF:/Users/bobbyantonio/Zotero/storage/LY8MQLNB/Pathak et al. - 2022 - FourCastNet A Global Data-driven High-resolution .pdf:application/pdf;arXiv.org Snapshot:/Users/bobbyantonio/Zotero/storage/UX9CWR5X/2202.html:text/html},
}

@article{skok_precipitation_2023,
	title = {Precipitation attribution distance},
	volume = {295},
	issn = {01698095},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0169809523003952},
	doi = {10.1016/j.atmosres.2023.106998},
	abstract = {Precipitation is one of the most important meteorological parameters and is notoriously difficult to measure, predict, and also to verify. Distance measures are one of the five classes of spatial verification metrics that try to address the problems of traditionally used non-spatial methods (which only compare values at collocated grid points). Distance measures provide an estimate of spatial distance between the events in the two fields, which is relatively easy to interpret and understand. Our goal was to develop a new distance measure for precipitation that would not require thresholding and provide meaningful results that would not be too inconsistent with subjective forecast evaluation. At the same time, it would be computationally fast and numerically stable and could be used with fields provided on irregular grids. The new metric is called the Precipitation Attribution Distance or PAD and is based on a random nearest-neighbor attribution concept - it works by sequentially attributing randomly selected precipitation in one field to the closest precipitation in the other and is nonde­ terministic. We analyzed the new metric’s behavior in many idealized and real-world situations and compared it with the behavior of existing distance metrics.},
	language = {en},
	urldate = {2023-10-19},
	journal = {Atmospheric Research},
	author = {Skok, Gregor},
	month = nov,
	year = {2023},
	pages = {106998},
	file = {Skok - 2023 - Precipitation attribution distance.pdf:/Users/bobbyantonio/Zotero/storage/D9RMV3IV/Skok - 2023 - Precipitation attribution distance.pdf:application/pdf},
}

@article{gilleland_new_2017,
	title = {A {New} {Characterization} within the {Spatial} {Verification} {Framework} for {False} {Alarms}, {Misses}, and {Overall} {Patterns}},
	volume = {32},
	issn = {1520-0434, 0882-8156},
	url = {https://journals.ametsoc.org/view/journals/wefo/32/1/waf-d-16-0134_1.xml},
	doi = {10.1175/WAF-D-16-0134.1},
	abstract = {Abstract This paper proposes new diagnostic plots that take advantage of the lack of symmetry in the mean-error distance measure (MED) for binary images to yield a new concept of false alarms and misses appropriate to the spatial setting where the measure does not require perfect matching to be a hit or correct negative. Additionally, three previously proposed geometric indices that provide complementary information about forecast performance are used to produce useful diagnostic plots for forecast performance. The diagnostics are applied to previously analyzed case studies from the spatial forecast verification Intercomparison Project (ICP) to facilitate a comparison with more complicated methods. Relatively new test cases from the Mesoscale Verification Intercomparison over Complex Terrain (MesoVICT) project are also employed for future comparisons. It is found that the proposed techniques provide useful information about forecast model behavior by way of a succinct, easy-to-implement method that can be complementary to other measures of forecast performance.},
	language = {EN},
	number = {1},
	urldate = {2023-10-19},
	journal = {Weather and Forecasting},
	author = {Gilleland, Eric},
	month = feb,
	year = {2017},
	note = {Publisher: American Meteorological Society
Section: Weather and Forecasting},
	pages = {187--198},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/T5VPNH89/Gilleland - 2017 - A New Characterization within the Spatial Verifica.pdf:application/pdf},
}

@article{yang_improving_2023-2,
	title = {Improving {Seasonal} {Prediction} of {Summer} {Precipitation} in the {Middle}–{Lower} {Reaches} of the {Yangtze} {River} {Using} a {TU}-{Net} {Deep} {Learning} {Approach}},
	volume = {2},
	issn = {2769-7525},
	url = {https://journals.ametsoc.org/view/journals/aies/2/2/AIES-D-22-0078.1.xml},
	doi = {10.1175/AIES-D-22-0078.1},
	abstract = {Abstract The two-step U-Net model (TU-Net) contains a western North Pacific subtropical high (WNPSH) prediction model and a precipitation prediction model fed by the WNPSH predictions, oceanic heat content, and surface temperature. The data-driven forecast model provides improved 4-month lead predictions of the WNPSH and precipitation in the middle and lower reaches of the Yangtze River (MLYR), which has important implications for water resources management and precipitation-related disaster prevention in China. When compared with five state-of-the-art dynamical climate models including the Climate Forecast System of Nanjing University of Information Science and Technology (NUIST-CFS1.0) and four models participating in the North American Multi-Model Ensemble (NMME) project, the TU-Net produces comparable skills in forecasting 4-month lead geopotential height and winds at the 500- and 850-hPa levels. For the 4-month lead prediction of precipitation over the MLYR region, the TU-Net has the best correlation scores and mean latitude-weighted RMSE in each summer month and in boreal summer [June–August (JJA)], and pattern correlation coefficient scores are slightly lower than the dynamical models only in June and JJA. In addition, the results show that the constructed TU-Net is also superior to most of the dynamical models in predicting 2-m air temperature in the MLYR region at a 4-month lead. Thus, the deep learning-based TU-Net model can provide a rapid and inexpensive way to improve the seasonal prediction of summer precipitation and 2-m air temperature over the MLYR region. Significance Statement The purpose of this study is to examine the seasonal predictive skill of the western North Pacific subtropical high anomalies and summer rainfall anomalies over the middle and lower reaches of the Yangtze River region by means of deep learning methods. Our deep learning model provides a rapid and inexpensive way to improve the seasonal prediction of summer precipitation as well as 2-m air temperature. The work has important implications for water resources management and precipitation-related disaster prevention in China and can be extended in the future to predict other climate variables as well.},
	language = {EN},
	number = {2},
	urldate = {2023-10-19},
	journal = {Artificial Intelligence for the Earth Systems},
	author = {Yang, Shuxian and Ling, Fenghua and Li, Yue and Luo, Jing-Jia},
	month = jun,
	year = {2023},
	note = {Publisher: American Meteorological Society
Section: Artificial Intelligence for the Earth Systems},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/HWSWP6HK/Yang et al. - 2023 - Improving Seasonal Prediction of Summer Precipitat.pdf:application/pdf},
}

@techreport{yang_improving_2023-3,
	type = {preprint},
	title = {Improving {Seasonal} {Forecast} of {Summer} {Precipitation} in {Southeastern} {China} using {CycleGAN} {Deep} {Learning} {Bias} {Correction}},
	url = {https://essopenarchive.org/users/655873/articles/661468-improving-seasonal-forecast-of-summer-precipitation-in-southeastern-china-using-cyclegan-deep-learning-bias-correction?commit=6fe5aad26bce582dd78270aa8ad3b99a0acc0f37},
	abstract = {Accurate seasonal precipitation forecasts, especially for extreme
events, are crucial to preventing meteorological hazards and its
potential impacts on national development, social stability, and
security. However, the intensity of summer precipitation is often
significantly underestimated in many current dynamical models. This
study uses a deep learning method called Cycle-Consistent Generative
Adversarial Networks (CycleGAN) to enhance the seasonal forecast skill
of the Nanjing University of Information Science \& Technology Climate
Forecast System (NUIST-CFS1.0) in predicting June-July-August
precipitation in southeastern China. The results suggest that the
CycleGAN-based model significantly improves the accuracy in predicting
the spatial-temporal distribution of summer precipitation than
traditional quantile mapping (QM) method. Due to the use of unpaired
day-to-day correction models, we can pay more attention to the
frequency, intensity, and duration of extreme precipitation events in
the climate dynamical model forecast. This study expands the potential
applications of deep learning models to improving seasonal precipitation
forecasts.},
	urldate = {2023-10-19},
	institution = {Preprints},
	author = {Yang, Song and Ling, Fenghua and Bai, Lei and Luo, Jing-Jia},
	month = aug,
	year = {2023},
	doi = {10.22541/essoar.169290554.48887852/v1},
	file = {Submitted Version:/Users/bobbyantonio/Zotero/storage/G3LF9TBE/Yang et al. - 2023 - Improving Seasonal Forecast of Summer Precipitatio.pdf:application/pdf},
}

@article{lemarie_simplified_2021,
	title = {A simplified atmospheric boundary layer model for an improved representation of air–sea interactions in eddying oceanic models: implementation and first evaluation in {NEMO} (4.0)},
	volume = {14},
	issn = {1991-959X},
	shorttitle = {A simplified atmospheric boundary layer model for an improved representation of air–sea interactions in eddying oceanic models},
	url = {https://gmd.copernicus.org/articles/14/543/2021/},
	doi = {10.5194/gmd-14-543-2021},
	abstract = {A simplified model of the atmospheric boundary layer (ABL) of intermediate complexity between a bulk parameterization and a three-dimensional atmospheric model is developed and integrated to the Nucleus for European Modelling of the Ocean (NEMO) general circulation model. An objective in the derivation of such a simplified model, called ABL1d, is to reach an apt representation in ocean-only numerical simulations of some of the key processes associated with air–sea interactions at the characteristic scales of the oceanic mesoscale. In this paper we describe the formulation of the ABL1d model and the strategy to constrain this model with large-scale atmospheric data available from reanalysis or real-time forecasts. A particular emphasis is on the appropriate choice and calibration of a turbulent closure scheme for the atmospheric boundary layer. This is a key ingredient to properly represent the air–sea interaction processes of interest. We also provide a detailed description of the NEMO-ABL1d coupling infrastructure and its computational efficiency. The resulting simplified model is then tested for several boundary-layer regimes relevant to either ocean–atmosphere or sea-ice–atmosphere coupling. The coupled system is also tested with a realistic 0.25∘ resolution global configuration. The numerical results are evaluated using standard metrics from the literature to quantify the wind–sea-surface-temperature (a.k.a. thermal feedback effect), wind–current (a.k.a. current feedback effect), and ABL–sea-ice couplings. With respect to these metrics, our results show very good agreement with observations and fully coupled ocean–atmosphere models for a computational overhead of about 9 \% in terms of elapsed time compared to standard uncoupled simulations. This moderate overhead, largely due to I/O operations, leaves room for further improvement to relax the assumption of horizontal homogeneity behind ABL1d and thus to further improve the realism of the coupling while keeping the flexibility of ocean-only modeling.},
	language = {English},
	number = {1},
	urldate = {2023-10-19},
	journal = {Geoscientific Model Development},
	author = {Lemarié, Florian and Samson, Guillaume and Redelsperger, Jean-Luc and Giordani, Hervé and Brivoal, Théo and Madec, Gurvan},
	month = jan,
	year = {2021},
	note = {Publisher: Copernicus GmbH},
	pages = {543--572},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/EYSKAZZ5/Lemarié et al. - 2021 - A simplified atmospheric boundary layer model for .pdf:application/pdf},
}

@article{gilleland_computationally_2008,
	title = {Computationally {Efficient} {Spatial} {Forecast} {Verification} {Using} {Baddeley}’s {Delta} {Image} {Metric}},
	volume = {136},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/136/5/2007mwr2274.1.xml},
	doi = {10.1175/2007MWR2274.1},
	abstract = {Abstract An important focus of research in the forecast verification community is the development of alternative verification approaches for quantitative precipitation forecasts, as well as for other spatial forecasts. The need for information that is meaningful in an operational context and the importance of capturing the specific sources of forecast error at varying spatial scales are two primary motivating factors. In this paper, features of precipitation as identified by a convolution threshold technique are merged within fields and matched across fields in an automatic and computationally efficient manner using Baddeley’s metric for binary images. The method is carried out on 100 test cases, and 4 representative cases are shown in detail. Results of merging and matching objects are generally positive in that they are consistent with how a subjective observer might merge and match features. The results further suggest that the Baddeley metric may be useful as a computationally efficient summary metric giving information about location, shape, and size differences of individual features, which could be employed for other spatial forecast verification methods.},
	language = {EN},
	number = {5},
	urldate = {2023-10-20},
	journal = {Monthly Weather Review},
	author = {Gilleland, Eric and Lee, Thomas C. M. and Gotway, John Halley and Bullock, R. G. and Brown, Barbara G.},
	month = may,
	year = {2008},
	note = {Publisher: American Meteorological Society
Section: Monthly Weather Review},
	pages = {1747--1757},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/JIGD873W/Gilleland et al. - 2008 - Computationally Efficient Spatial Forecast Verific.pdf:application/pdf},
}

@article{micheas_cell_2007,
	title = {Cell identification and verification of {QPF} ensembles using shape analysis techniques},
	volume = {343},
	issn = {0022-1694},
	url = {https://www.sciencedirect.com/science/article/pii/S0022169407002909},
	doi = {10.1016/j.jhydrol.2007.05.036},
	abstract = {This paper introduces a new verification technique designed for, but not limited to, quantitative precipitation forecasts. It is tested on, and examples are given for, an intercomparison of very short-period nowcasting schemes. One of these nowcasters is a Bayesian scheme that is used in an extensive ensemble formulation, and the verification scheme is uniquely capable of treating both the ensemble members and the mean forecast. The verification scheme uses Procrustes shape analysis methods that are well established in statistics but have not, to date, been applied to meteorological forecast assessment. The Procrustes methodology allows for a decomposition of the forecast error into any number of components such as location (displacement), shape, size, orientation and intensity. Each error component can be afforded a separate weighting such that a cost or value of the forecast can be calculated that accounts for different error types. For example, a forecaster who is concerned with the location of a storm would place greater emphasis on correct location in the forecast than other attributes. This ability to apply weights makes the system particularly suited to real-time verification applications where confidence in the performance of the forecast translates into improved dissemination to users. In addition, the decomposition of the error into parts enables diagnosis of the error sources that can lead to model adjustment and improvement.},
	number = {3},
	urldate = {2023-10-20},
	journal = {Journal of Hydrology},
	author = {Micheas, Athanasios Christou and Fox, Neil I. and Lack, Steven A. and Wikle, Christopher K.},
	month = sep,
	year = {2007},
	pages = {105--116},
	file = {ScienceDirect Full Text PDF:/Users/bobbyantonio/Zotero/storage/8SVTTN2Q/Micheas et al. - 2007 - Cell identification and verification of QPF ensemb.pdf:application/pdf;ScienceDirect Snapshot:/Users/bobbyantonio/Zotero/storage/FVATMX6P/S0022169407002909.html:text/html},
}

@article{marzban_verification_2009,
	title = {Verification with {Variograms}},
	volume = {24},
	issn = {1520-0434, 0882-8156},
	url = {https://journals.ametsoc.org/view/journals/wefo/24/4/2009waf2222122_1.xml},
	doi = {10.1175/2009WAF2222122.1},
	abstract = {Abstract The verification of a gridded forecast field, for example, one produced by numerical weather prediction (NWP) models, cannot be performed on a gridpoint-by-gridpoint basis; that type of approach would ignore the spatial structures present in both forecast and observation fields, leading to misinformative or noninformative verification results. A variety of methods have been proposed to acknowledge the spatial structure of the fields. Here, a method is examined that compares the two fields in terms of their variograms. Two types of variograms are examined: one examines correlation on different spatial scales and is a measure of texture; the other type of variogram is additionally sensitive to the size and location of objects in a field and can assess size and location errors. Using these variograms, the forecasts of three NWP model formulations are compared with observations/analysis, on a dataset consisting of 30 days in spring 2005. It is found that within statistical uncertainty the three formulations are comparable with one another in terms of forecasting the spatial structure of observed reflectivity fields. None, however, produce the observed structure across all scales, and all tend to overforecast the spatial extent and also forecast a smoother precipitation (reflectivity) field. A finer comparison suggests that the University of Oklahoma 2-km resolution Advanced Research Weather Research and Forecasting (WRF-ARW) model and the National Center for Atmospheric Research (NCAR) 4-km resolution WRF-ARW slightly outperform the 4.5-km WRF-Nonhydrostatic Mesoscale Model (NMM), developed by the National Oceanic and Atmospheric Administration/National Centers for Environmental Prediction (NOAA/NCEP), in terms of producing forecasts whose spatial structures are closer to that of the observed field.},
	language = {EN},
	number = {4},
	urldate = {2023-10-20},
	journal = {Weather and Forecasting},
	author = {Marzban, Caren and Sandgathe, Scott},
	month = aug,
	year = {2009},
	note = {Publisher: American Meteorological Society
Section: Weather and Forecasting},
	pages = {1102--1120},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/4DBB6RIE/Marzban and Sandgathe - 2009 - Verification with Variograms.pdf:application/pdf},
}

@article{marzban_cluster_2008,
	title = {Cluster {Analysis} for {Object}-{Oriented} {Verification} of {Fields}: {A} {Variation}},
	volume = {136},
	issn = {1520-0493, 0027-0644},
	shorttitle = {Cluster {Analysis} for {Object}-{Oriented} {Verification} of {Fields}},
	url = {https://journals.ametsoc.org/view/journals/mwre/136/3/2007mwr1994.1.xml},
	doi = {10.1175/2007MWR1994.1},
	abstract = {Abstract In a recent paper, a statistical method referred to as cluster analysis was employed to identify clusters in forecast and observed fields. Further criteria were also proposed for matching the identified clusters in one field with those in the other. As such, the proposed methodology was designed to perform an automated form of what has been called object-oriented verification. Herein, a variation of that methodology is proposed that effectively avoids (or simplifies) the criteria for matching the objects. The basic idea is to perform cluster analysis on the combined set of observations and forecasts, rather than on the individual fields separately. This method will be referred to as combinative cluster analysis (CCA). CCA naturally lends itself to the computation of false alarms, hits, and misses, and therefore, to the critical success index (CSI). A desirable feature of the previous method—the ability to assess performance on different spatial scales—is maintained. The method is demonstrated on reflectivity data and corresponding forecasts for three dates using three mesoscale numerical weather prediction model formulations—the NCEP/NWS Nonhydrostatic Mesoscale Model (NMM) at 4-km resolution (nmm4), the University of Oklahoma’s Center for Analysis and Prediction of Storms (CAPS) Weather Research and Forecasting Model (WRF) at 2-km resolution (arw2), and the NCAR WRF at 4-km resolution (arw4). In the small demonstration sample herein, model forecast quality is efficiently differentiated when performance is assessed in terms of the CSI. In this sample, arw2 appears to outperform the other two model formulations across all scales when the cluster analysis is performed in the space of spatial coordinates and reflectivity. However, when the analysis is performed only on spatial data (i.e., when only the spatial placement of the reflectivity is assessed), the difference is not significant. This result has been verified both visually and using a standard gridpoint verification, and seems to provide a reasonable assessment of model performance. This demonstration of CCA indicates promise in quickly evaluating mesoscale model performance while avoiding the subjectivity and labor intensiveness of human evaluation or the pitfalls of non-object-oriented automated verification.},
	language = {EN},
	number = {3},
	urldate = {2023-10-20},
	journal = {Monthly Weather Review},
	author = {Marzban, Caren and Sandgathe, Scott},
	month = mar,
	year = {2008},
	note = {Publisher: American Meteorological Society
Section: Monthly Weather Review},
	pages = {1013--1025},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/RSQQQQUI/Marzban and Sandgathe - 2008 - Cluster Analysis for Object-Oriented Verification .pdf:application/pdf},
}

@article{marzban_cluster_2006,
	title = {Cluster {Analysis} for {Verification} of {Precipitation} {Fields}},
	volume = {21},
	issn = {1520-0434, 0882-8156},
	url = {https://journals.ametsoc.org/view/journals/wefo/21/5/waf948_1.xml},
	doi = {10.1175/WAF948.1},
	abstract = {Abstract A statistical method referred to as cluster analysis is employed to identify features in forecast and observation fields. These features qualify as natural candidates for events or objects in terms of which verification can be performed. The methodology is introduced and illustrated on synthetic and real quantitative precipitation data. First, it is shown that the method correctly identifies clusters that are in agreement with what most experts might interpret as features or objects in the field. Then, it is shown that the verification of the forecasts can be performed within an event-based framework, with the events identified as the clusters. The number of clusters in a field is interpreted as a measure of scale, and the final “product” of the methodology is an “error surface” representing the error in the forecasts as a function of the number of clusters in the forecast and observation fields. This allows for the examination of forecast error as a function of scale.},
	language = {EN},
	number = {5},
	urldate = {2023-10-20},
	journal = {Weather and Forecasting},
	author = {Marzban, Caren and Sandgathe, Scott},
	month = oct,
	year = {2006},
	note = {Publisher: American Meteorological Society
Section: Weather and Forecasting},
	pages = {824--838},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/IQ4A8QET/Marzban and Sandgathe - 2006 - Cluster Analysis for Verification of Precipitation.pdf:application/pdf},
}

@misc{baldwin_development_2003,
	title = {Development of an {Events}-{Oriented} {Verification} {System} {Using} data mining and {Image} {Processing} {Algorithms}},
	url = {https://ams.confex.com/ams/annual2003/techprogram/paper_57821.htm},
	urldate = {2023-10-20},
	author = {Baldwin, M. E. and Lakshmivarahan, S.},
	month = feb,
	year = {2003},
	note = {3rd Conference on Artificial Intelligence Applications to the Environmental Science},
	file = {4.6 Development of an Events-Oriented Verification System Using data mining and Image Processing Algorithms (2003 - annual2003_3ai):/Users/bobbyantonio/Zotero/storage/W67IEXBR/paper_57821.html:text/html;Baldwin and Lakshmivarahan - 2003 - Development of an Events-Oriented Verification Sys.pdf:/Users/bobbyantonio/Zotero/storage/PSGU6QND/Baldwin and Lakshmivarahan - 2003 - Development of an Events-Oriented Verification Sys.pdf:application/pdf},
}

@article{dorninger_setup_2018,
	title = {The {Setup} of the {MesoVICT} {Project}},
	volume = {99},
	issn = {0003-0007, 1520-0477},
	url = {https://journals.ametsoc.org/view/journals/bams/99/9/bams-d-17-0164.1.xml},
	doi = {10.1175/BAMS-D-17-0164.1},
	abstract = {Abstract Recent advancements in numerical weather prediction (NWP) and the enhancement of model resolution have created the need for more robust and informative verification methods. In response to these needs, a plethora of spatial verification approaches have been developed in the past two decades. A spatial verification method intercomparison was established in 2007 with the aim of gaining a better understanding of the abilities of the new spatial verification methods to diagnose different types of forecast errors. The project focused on prescribed errors for quantitative precipitation forecasts over the central United States. The intercomparison led to a classification of spatial verification methods and a cataloging of their diagnostic capabilities, providing useful guidance to end users, model developers, and verification scientists. A decade later, NWP systems have continued to increase in resolution, including advances in high-resolution ensembles. This article describes the setup of a second phase of the verification intercomparison, called the Mesoscale Verification Intercomparison over Complex Terrain (MesoVICT). MesoVICT focuses on the application, capability, and enhancement of spatial verification methods to deterministic and ensemble forecasts of precipitation, wind, and temperature over complex terrain. Importantly, this phase also explores the issue of analysis uncertainty through the use of an ensemble of meteorological analyses.},
	language = {EN},
	number = {9},
	urldate = {2023-10-20},
	journal = {Bulletin of the American Meteorological Society},
	author = {Dorninger, Manfred and Gilleland, Eric and Casati, Barbara and Mittermaier, Marion P. and Ebert, Elizabeth E. and Brown, Barbara G. and Wilson, Laurence J.},
	month = sep,
	year = {2018},
	note = {Publisher: American Meteorological Society
Section: Bulletin of the American Meteorological Society},
	pages = {1887--1906},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/AIBBSAZH/Dorninger et al. - 2018 - The Setup of the MesoVICT Project.pdf:application/pdf},
}

@misc{materia_artificial_2023,
	title = {Artificial {Intelligence} for {Prediction} of {Climate} {Extremes}: {State} of the art, challenges and future perspectives},
	shorttitle = {Artificial {Intelligence} for {Prediction} of {Climate} {Extremes}},
	url = {http://arxiv.org/abs/2310.01944},
	abstract = {Scientific and technological advances in numerical modelling have improved the quality of climate predictions over recent decades, but predictive skill remains limited in many aspects. Extreme events such as heat and cold waves, droughts, heavy rain and storms are particularly challenging to predict accurately due to their rarity and non-linear chaotic nature, and because of model limitations. However, recent studies have shown that predictive skill of extremes can be increased when using more sophisticated approaches, indicating that there might be systemic predictability that is not being leveraged. Recently, numerous studies have been devoted to the exploitation of Artificial Intelligence (AI) to study the predictability and make predictions of weather and climate. AI techniques have shown great potential to improve the prediction of extreme events and uncover their links to large-scale and local drivers. Machine and deep learning, causal discovery, explainable AI, are only some of the approaches that have been tested to both improve our understanding of the processes underlying predictability and enhance prediction skill of extreme events. Results are promising, especially for hybrid predictions that combine the AI, which can reveal and exploit unknown spatio-temporal connections from data, and climate models, that provide the theoretical foundation and interpretability of the physical world. On the other hand, challenges are multiple in many aspects, from data curation to model uncertainty and generalizability, to the reproducibility of methods and workflows. A few best practices are identified to increase trust in these novel techniques, and future perspectives are envisaged for further scientific development.},
	urldate = {2023-10-24},
	publisher = {arXiv},
	author = {Materia, Stefano and García, Lluís Palma and van Straaten, Chiem and O, Sungmin and Mamalakis, Antonios and Cavicchia, Leone and Coumou, Dim and De Luca, Paolo and Kretschmer, Marlene and Donat, Markus G.},
	month = oct,
	year = {2023},
	note = {arXiv:2310.01944 [physics]},
	keywords = {Physics - Atmospheric and Oceanic Physics},
	annote = {Comment: 20 pages, 4 figures, 2 tables},
	file = {arXiv.org Snapshot:/Users/bobbyantonio/Zotero/storage/EXMYZZUG/2310.html:text/html;Full Text PDF:/Users/bobbyantonio/Zotero/storage/RIJWAQCQ/Materia et al. - 2023 - Artificial Intelligence for Prediction of Climate .pdf:application/pdf},
}

@article{huffman_integrated_nodate,
	title = {Integrated multi-satellite retrievals for {GPM} ({IMERG}), {V06B}.},
	journal = {NASA's Precipitation Processing Center, accessed 1st October 2022, https://arthurhouhttps.pps.eosdis.nasa.gov/text/gpmallversions/V06/YYYY/MM/DD/imerg/},
	author = {Huffman, G and Bolvin, D and Braithwaite, D and Hsu, K and Joyce, R and Xie, P},
}

@article{vosper_deep_2023,
	title = {Deep {Learning} for {Downscaling} {Tropical} {Cyclone} {Rainfall} to {Hazard}-{Relevant} {Spatial} {Scales}},
	volume = {128},
	copyright = {© 2023. The Authors.},
	issn = {2169-8996},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2022JD038163},
	doi = {10.1029/2022JD038163},
	abstract = {Flooding, driven in part by intense rainfall, is the leading cause of mortality and damages from the most intense tropical cyclones (TCs). With rainfall from TCs set to increase under anthropogenic climate change, it is critical to accurately estimate extreme rainfall to better support short-term and long-term resilience efforts. While high-resolution climate models capture TC statistics better than low-resolution models, they are computationally expensive. This leads to a trade-off between capturing TC features accurately, and generating large enough simulation data sets to sufficiently sample high-impact, low-probability events. Downscaling can assist by predicting high-resolution features from relatively cheap, low-resolution models. Here, we develop and evaluate a set of three deep learning models for downscaling TC rainfall to hazard-relevant spatial scales. We use rainfall from the Multi-Source Weighted-Ensemble Precipitation observational product at a coarsened resolution of ∼100 km, and apply our downscaling model to reproduce the original resolution of ∼10 km. We find that the Wasserstein Generative Adversarial Network is able to capture realistic spatial structures and power spectra and performs the best overall, with mean biases within 5\% of observations. We also show that the model can perform well at extrapolating to the most extreme storms, which were not used in training.},
	language = {en},
	number = {10},
	urldate = {2023-10-27},
	journal = {Journal of Geophysical Research: Atmospheres},
	author = {Vosper, Emily and Watson, Peter and Harris, Lucy and McRae, Andrew and Santos-Rodriguez, Raul and Aitchison, Laurence and Mitchell, Dann},
	year = {2023},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/2022JD038163},
	keywords = {deep learning, downscaling, tropical cyclone, Generative Adversarial Network, superresolution, tropical cyclone rainfall},
	pages = {e2022JD038163},
	annote = {e2022JD038163 2022JD038163},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/SI55M6X8/Vosper et al. - 2023 - Deep Learning for Downscaling Tropical Cyclone Rai.pdf:application/pdf;Snapshot:/Users/bobbyantonio/Zotero/storage/TFIZQWIA/2022JD038163.html:text/html},
}

@article{noauthor_nemo_nodate,
	title = {{NEMO} ocean engine},
	url = {https://zenodo.org/records/6334656},
	doi = {10.5281/zenodo.6334656},
	abstract = {The ocean engine of NEMO is a primitive equation model adapted to regional and global ocean circulation problems. It is intended to be a flexible tool for studying the ocean and its interactions with the others components of the earth climate system over a wide range of space and time scales.},
	language = {en},
	urldate = {2023-10-31},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/GQ3F9BNK/NEMO ocean engine.pdf:application/pdf},
}

@article{tibshirani_discussion_1986,
	title = {Discussion: {Jackknife}, {Bootstrap} and {Other} {Resampling} {Methods} in {Regression} {Analysis}},
	volume = {14},
	issn = {0090-5364},
	shorttitle = {Discussion},
	url = {https://www.jstor.org/stable/2241470},
	number = {4},
	urldate = {2023-11-02},
	journal = {The Annals of Statistics},
	author = {Tibshirani, Robert},
	year = {1986},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {1335--1339},
	file = {JSTOR Full Text PDF:/Users/bobbyantonio/Zotero/storage/GW4NJ2ZY/Tibshirani - 1986 - Discussion Jackknife, Bootstrap and Other Resampl.pdf:application/pdf},
}

@article{efron_bootstrap_1986,
	title = {Bootstrap {Methods} for {Standard} {Errors}, {Confidence} {Intervals}, and {Other} {Measures} of {Statistical} {Accuracy}},
	volume = {1},
	issn = {0883-4237},
	url = {https://www.jstor.org/stable/2245500},
	abstract = {This is a review of bootstrap methods, concentrating on basic ideas and applications rather than theoretical considerations. It begins with an exposition of the bootstrap estimate of standard error for one-sample situations. Several examples, some involving quite complicated statistical procedures, are given. The bootstrap is then extended to other measures of statistical accuracy such as bias and prediction error, and to complicated data structures such as time series, censored data, and regression models. Several more examples are presented illustrating these ideas. The last third of the paper deals mainly with bootstrap confidence intervals.},
	number = {1},
	urldate = {2023-11-02},
	journal = {Statistical Science},
	author = {Efron, B. and Tibshirani, R.},
	year = {1986},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {54--75},
	file = {Full Text PDF:/Users/bobbyantonio/Zotero/storage/GWV3K6C3/Efron and Tibshirani - 1986 - Bootstrap Methods for Standard Errors, Confidence .pdf:application/pdf},
}
